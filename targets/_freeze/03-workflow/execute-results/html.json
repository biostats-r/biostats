{
  "hash": "8d5d09e64f504a7f62bde8551f6e55d2",
  "result": {
    "markdown": "---\neditor_options: \n  markdown: \n    wrap: sentence\n---\n\n\n# Getting started with targets\n\n::: callout-note\n## In this chapter, you will\n\n- learn the basic targets workflow\n- build your own targets pipeline\n\n:::\n\nIn this chapter we will go through the basic workflow of a `targets` pipeline and discuss its main elements, and how to run it.\nWe will use plant trait data from Svalbard.\nFollow the instructions below to download a the repo.\n\n::: callout-note\n## Exercise\n\nTo download the R project containing the data, the code and the qmd file, run:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"usethis\") # if you don't have it already.\nusethis::use_course(\"biostats-r/svalbardQuartoDemo\")\n```\n:::\n\n\nThen follow the instructions.\nThis will open the svalbardQuartoDemo Rstudio project.\n\n<!-- I added this back in, because people will have to understand what is going on in the script -->\nOpen the `svalbard_traits_targets.qmd` file and render it.\nCheck the htlm output and try to understand what each part of the code is doing. \n\n:::\n\n\n\n## Introduction to targets\n\nTargets is a **pipeline tool**, which coordinates the different steps in data science i R.\nIt takes care of dependencies in the code and keeps track of outdated objects.\n\nA targets **pipeline** consists of different steps, such as importing data, running an analysis or making a figure (@fig-simple-pipeline).\nEach step in the pipeline is a **target** and can for example be a data frame, a model or a figure.\nA target is basically an R object in memory.\nIt is created by a piece of code, often this is a **function**.\nA pipeline has a main script that puts all the pieces of code together and takes care of dependencies and keeping track of changes.\n\nThis concept should sound familiar to you after reading the previous chapter on abstraction.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Simple targets pipeline.](Pics/targets_pipeline.png){#fig-simple-pipeline fig-alt='Simple targets pipeline.' width=385}\n:::\n:::\n\n\n::: callout-tip\n## Definitions\n\n-   **pipeline tool** - coordinates different steps of data science\n-   **target** - an R object in memory\n-   **function** - self contained modules of code that accomplish a specific task\n:::\n\n\n\nLet's have a look at the targets pipeline.\n\n\n## The targets pipeline\n\n### The file structure\n\nA target workflow has a specific file structure including R code, functions, qmd files, data and a `_targets.R` file (@fig-file-structure).\nThe `_targets.R` file is mandatory and the most important file defining the targets pipeline.\nThis file lives at the root of the R project folder.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![File structure of an R Studio project with a target pipeline.](Pics/file_structure.png){#fig-file-structure fig-alt='The file structure of an R Studio project with a target pipeline.' width=351}\n:::\n:::\n\n\nAn R project has many other files and it is recommended to keep code and data files in separate folders to keep the repository tidy.\nIt is common to have one or several scripts that contain custom user-defined functions.\nThese scripts should be stored in one folder. \nIn this example we will call the folder `R`: `R/functions.R`.\n\nTo set up this file structure in an RStudio project, use the `use_targets()` function, which creates an initial `_targets.R` script with comments to help you populate the script.\nNote that it also creates a couple of other files, one of which is called `run.R`.\nThis is a helper script to run the pipeline and will be explained later.\n\n::: callout-note\n## Exercise\n\nGo to the Svalbard trait project and load the targets library `library(targets)`.\nThen start to set up a targets pipeline by using the `use_targets()` function.\n \n:::\n\n\n### The _target.R file\n\nThe `_targets.R` file is the **main script** and configures and defines the pipeline.\nThis file is mandatory and without it the targets pipeline will not work.\nWhen using the `use_targets()` function, it sets up the basic structure and comments to help fill out the rest (see below).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Created by use_targets().\n# Follow the comments below to fill in this target script.\n# Then follow the manual to check and run the pipeline:\n#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline # nolint\n\n# Load packages required to define the pipeline:\nlibrary(targets)\n# library(tarchetypes) # Load other packages as needed. # nolint\n\n# Set target options:\ntar_option_set(\n  packages = c(\"tibble\"), # packages that your targets need to run\n  format = \"rds\" # default storage format\n  # Set other options as needed.\n)\n\n# tar_make_clustermq() configuration (okay to leave alone):\noptions(clustermq.scheduler = \"multicore\")\n\n# tar_make_future() configuration (okay to leave alone):\n# Install packages {{future}}, {{future.callr}}, and {{future.batchtools}} to allow use_targets() to configure tar_make_future() options.\n\n# Run the R scripts in the R/ folder with your custom functions:\ntar_source()\n# source(\"other_functions.R\") # Source other scripts as needed. # nolint\n\n# Replace the target list below with your own:\nlist(\n  tar_target(\n    name = data,\n    command = tibble(x = rnorm(100), y = rnorm(100))\n#   format = \"feather\" # efficient storage of large data frames # nolint\n  ),\n  tar_target(\n    name = model,\n    command = coefficients(lm(y ~ x, data = data))\n  )\n)\n```\n:::\n\n\nHave a look at your `_targets.R` file.\n\n::: callout-note\n## Exercise\n\nOpen the `_targets.R` in your repo and have a look at your `_targets.R` file.\n \n:::\n\n\nThe `_targets.R` file has three main components.\nNote that the file also contains other options which are optional.\nLet's go through each component step by step.\n\n1. `tar_option_set()` **sets all options** such as load necessary packages or defining the output format.\nThe argument `package` should have a list of all the required packages that are needed to run the pipeline.\nNote that `targets` and `tarchetypes` need to be loaded first and outside this function, otherwise the pipeline will not work.\nIf your pipeline includes a quarto file, the packages that are only used in a quarto file can be loaded directly in there and do not need to be loaded in the `_targets.R` file.\nThe argument `format` let's you define default storage format. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages required to define the pipeline:\nlibrary(targets)\nlibrary(tarchetypes) # Load other packages as needed.\n\n# Set target options:\ntar_option_set(\n  packages = c(\"tibble\"), # packages that your targets need to run\n  format = \"rds\" # default storage format\n  # Set other options as needed.\n)\n```\n:::\n\n\n\n2. The function `tar_source()` will **source all the R scripts** in the `R/` folder.\n<!-- Unclear if it sources all .R script in the directory or if R is the default place it looks for? -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run the R scripts in the R/ folder with your custom functions:\ntar_source()\n# source(\"other_functions.R\") # Source other scripts as needed. # nolint\n```\n:::\n\n\n\n3. The last section makes **a list of targets** which is the pipeline.\nEach target is a step in the pipeline, for example importing data, run an analysis or make a figure and looks like a normal R object (e.g. tibble, vector, figure).\nEach target is declared by the `tar_target()` function and separated by a comma.\nThe `tar_target()` needs two arguments:\n`name` defines the target name and `command` the code to produce the target.\nThis can be a couple of lines of code or calling a function.\n\nHere is a target that uses the function `fit_model()` that was created in the previous chapter to run a linear regression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit model for plant height\nlist(\n  tar_target(name = model,\n             command = fit_model(data))\n  )\n```\n:::\n\n\n\nEach target should have a unique name can be called downstream in the pipeline.\nThe pipeline will figure out the order of which step depends on which other steps by iteslf.\n\nOnce the pipeline has run, the targets are stored in `_targets/objects/`.\nAll targets can be reproduced using `tar_load()` and the pipeline does not need rerunning each time before accessing the targets.\nThis is a huge advantage of the targets pipeline and can save a lot of time. \nTo access all the targets at once. use `tar_load_everything()`.\nIn `tar_load()` you can also use tidy select commands to load specific targets, e.g. `tar_load(starts_with(\"y\"))`\n\n::: callout-important\n## Targets names\nTargets names should be unique (no duplicates), should not start with a dot and the name should be meaningful (do not use my_variable).\n:::\n\n**Data files** are special targets, because they also need the argument `format` to declare that this target is a file.\nEach time the pipeline is run, targetes will check if the file has been changed and if this is the case automatically import the data again the next time the pipeline is run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = file,\n             command = \"data/PFTC4_Svalbard_2018_ITEX_Traits.csv\",\n             format = \"file\")\n  )\n```\n:::\n\n\n::: callout-tip\n## How many targets should I make?\nA target should do one thing only (e.g. make a figure) and if a functions gets too long, it can be split into nested sub-functions to make the code readable and easier to maintain.\nKeep the number of targets manageable, which means keep a balance between the amount of code that goes in one target and the number of targets.\n:::\n\n\n### Populate the _target.R file\n<!-- This whole chapter is mostly exercise. Is that ok or weird? I felt it is better like this than splitting up the previous chapter too much. -->\n\nThe next step is to populating the `_targets.R` file.\nWe need to set the options, make custom R functions, and define the pipeline.\n\nLet's get started.\n\nFirst, we need to add all R packages to the `tar_option_set()` function in the `_targets.R` file that are needed to run the pipeline.\n\n::: callout-note\n## Exercise\n\nOpen your `_targets.R` file.\nCheck the first code block in the `svalbard_trait.qmd` file in your repo to see which R packages that have been used.\n\nAdd both R packages to `tar_option_set()`.\n<!-- Instructions say add both, the example has only one. Ok or too difficult? -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set target options:\ntar_option_set(\n  packages = c(\"tidyverse\") # packages that your targets need to run\n)\n```\n:::\n\n\n:::\n\nThe next step is to make a function that runs a linear model.\n\n::: callout-note\n## Exercise\n\nCreate a new R file called `functions.R` and save it in a new folder called `R`.\n\nMake a function that runs a linear model.\n\nThe code for this exercise is in the previous chapter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_model <- function(data, response, predictor){\n  mod <- lm(response ~ predictor, data = data)\n  mod\n}\n```\n:::\n\n\n:::\n\nThe last step is to set up the **targets pipeline**.\nOur pipeline should have four steps:\n\n- define the data file\n\n- import the data and filter for the desired species and trait\n\n- use our custom function created above to run a linear model testing the effect of a warming treatment on plant height in *Bistorta vivipara*\n\n- make a figure that shows *Bistorta vivipara* height for control and warming treatment.\n\nLet's do this step by step.\n\n<!-- Here they need to replace the path. Is this too difficult? -->\n::: callout-note\n## Exercise\n\n**Define the data file**\n\nOpen the `_targets.R` file and go to the list of targets.\n\nUse `tar_targets()` to define each target.\nThe first argument is `name`, for example *file*.\nThe second argument is `command`, which in our case is the path to the data file.\nBecause this target is a file, we also need a third argument `format = \"file\"`.\n\nReplace path with the relative path to the data file in your repo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = file,\n             command = path,\n             format = \"file\")\n  )\n```\n:::\n\n\n:::\n\nThe next step is to import and filter the data.\n\n\n<!-- Here they need to filter for bistorta and plant height. ok or too difficult? -->\n::: callout-note\n## Exercise\n\n**Import and filter the data**\n\nIn the `_targets.R` file add a new target using `tar_targets()`, separated by a comma.\n\nThis time we can give it the `name` bistorta to keep it consistent with the `svalbard_trait.qmd` file.\nSecond for the `command` we need code to import and filter the data.\nAll the code you need is in the `svalbard_trait.qmd`.\n\nNote that in the previous target we have already defined the data file and it is now called *file*.\nBecause *file* is a target we can use it directly and do not have to use the path to the data file again.\n\nAdd code to filter for *Bistorta vivipapara* and the trait plant height.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = bistorta,\n             command = read_csv(file) |> \n               filter())\n  )\n```\n:::\n\n\n:::\n\nThe next step in the pipeline is to run the model.\n\n::: callout-note\n## Exercise\n\n**Run model**\n\nAdd a new target in the `_targets.R` file.\n\nUse mode_height for the `name`.\nThe `command` is the function `fit_model()` we created previously.\nThe function has three arguments: data, response and predictor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = mod_height,\n             command = fit_model(data = bistorta, \n                                 response = Value, \n                                 predictor = Treatment))\n  )\n```\n:::\n\n\n:::\n\nThe final step is to make a figure.\n\n::: callout-note\n## Exercise\n\n**Make figure**\n\nAdd a new target in the `_targets.R` file.\n\nUse fig_height for the `name`.\nThe `command` is code that produces a figure.\nWe can copy the code from the `svalbard_tratis.qmd` script.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = fig_height,\n             command = ggplot(bistorta, aes(x = Treatment, y = Value)) +\n               geom_boxplot(fill = c(\"grey80\", \"red\")) +\n               labs(x = \"Treatment\", y = \"Plant height (cm)\"))\n  )\n```\n:::\n\n\n:::\n\nWell done, you have just set up your first target pipeline.\nHave a treat ðŸ¥•!\n\n::: callout-tip\n## Do it step by step\n\nTargets plans can become huge and complex.\nStart small, create a few targets and functions and make the plan running.\nThen add new code in small steps and check regularly if the plan is still working\nThis will help to understand and solve errors (see trouble shooting section).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Vizualisation of complex target pipeline.](Pics/complex_network.png){#fig-complex-network fig-alt='Dependency graph that vizualises a complex target pipeline.' width=541}\n:::\n:::\n\n:::\n\n\n<!-- I moved the inspect and run pipeline forward, and moved output and adding qmd file to later. what do you think? -->\n### Inspect and run the pipeline\n\nWe are now ready to inspect the pipeline, check for errors and run it.\nUse `tar_manifest()` to check for errors.\nThis function lists useful information about each target, let you know if you are missing a R package and check for missing or duplicate targets (@fig-inspect).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Names and commands for each target in the pipeline.](Pics/inspect.png){#fig-inspect fig-alt='A table showing all the target names and commands to inspect the pipeline before running it for real.' width=636}\n:::\n:::\n\n\n\n::: callout-note\n## Exercise\n\nRun the `tar_manifest()` function to check if the pipeline is properly set up. If there are errors fix them.\n\n:::\n\n\nNow we are ready to run the pipeline.\nFor this open the `run.R` script and run the `tar_make()` function.\nThis function looks for the `_targets.R` in the working directory and runs the pipeline.\n\nWhen running the pipeline for the first time you will see a list of all the targets that are built (@fig-run-pipeline).\nThis is indicated by start target and build target.\nOnce the pipeline has run, it will always skip the targets that have not changed and are up to date and only run the once that need updating.\nIn the long run this will save a lot of computational time and is one of the big advantages of using targets pipelines.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![R output after running the pipeline.](Pics/pipeline.png){#fig-run-pipeline fig-alt='R output after running the pipeline.' width=282}\n:::\n:::\n\n\n\n::: callout-note\n## Exercise\n\nOpen the `run.R` script and run the pipeline.\nHopefully, everything will run smoothly ðŸ¤ž!\nIf not check out the Trouble shooting section below.\n\nRun the pipeline again and check if the targets that are already built are skipped.\n\nChange something in your pipeline and run it again and see what happens.\nYou can for example change the name of a target and see if it is updated when running the pipeline again.\n\n:::\n\n\n### Output files\n\nThe results and figures of an analysis are usually presented in a report or presentation or both.\nOne or several output files, such as a quarto document can be added to a targets pipeline.\nThe targets that have been produced in the pipeline can be loaded and used in the quarto document, for example a figure.\n\nTo add the quarto document to the pipeline, the manuscript has to be rendered.\nThis is done in `_targets.R` file in the list of targets using `tar_quarto()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# render ms\ntar_quarto(name = manuscript, path = \"traits_quarto_template.qmd\")\n```\n:::\n\n\n::: callout-note\n## Exercise\n\nWe have prepared a quarto template file.\nAdd this output file `traits_quarto_template.qmd` to the pipeline in the `_targets.R` using `tar_quarto()` as shown above.\n\n:::\n\n\nThe targets that are used in the quarto document need to be loaded into the current environment.\nFor this we can use `tar_load()` or `tar_read()`.\nThe first function is used when a target is used several times.\n`tar_read()` is useful if a target is only needed once, e.g. to show a figure.\n<!-- Not sure if this is correct, but I mean that it is not enough to load it, you also have to print it. -->\nOnce the target is loaded, it can be printed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# print model output\ntar_read(mod_height)\ntidy(mod_height)\n```\n:::\n\n\n\nAll R packages that are needed to run the quarto file need to be loaded in the .qmd file.\nIf you are using a R package exclusively in the quarto script, the package can be loaded only in the quarto file, and does not need to be added to the `_target.R` file.\n`targets` and `tarchetypes` always need to be loaded in both files.\n\n\nThe last step is to prepare the .qmd file, so that it displays the figure.\n\n\n::: callout-note\n## Exercise\n\n**Prepare the `traits_quarto_template.qmd` file**\n\nIn this output file, we want to show the figure displaying plant height in control vs. warmed plots.\nFor this, you need to load the target for the figure into the environment.\nBecause we will use the figure only once you can use `tar_read(fig_height)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntar_read(fig_height)\nfig_height\n```\n:::\n\n\nRender the file with the Render button on top of the script to check if the code is good.\nIf it runs smoothly, run the pipeline again and check the `traits_quarto_template.html` output file.\n\n:::\n\n\n<!-- what else should we add? -->\n## Trouble shooting\n\n### Vizualise the pipeline\n\nIf something goes wrong, a good place to start is to visualize your pipeline.\nThe `tar_visnetwork()` function shows the dependency graph of the pipeline.\nCircles are targets, triangles functions, and the colour indicates if the targets are up to date or not.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Vizualise the targets pipeline.](Pics/viz_workflow.png){#fig-vizualise fig-alt='Dependency graph that vizualises the target pipeline.' width=552}\n:::\n:::\n\n\n\n### Object not found\n\nA common error is to call a target that does not exist.\nWhen running the pipeline this error will appear (@fig-error-not-found).\nThis is usually if the name is spelled wrong or when using an old name.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Error message for missing object](Pics/error_not_found.png){#fig-error-not-found fig-alt='Error message for missing object.' width=546}\n:::\n:::\n\n\n### Duplicate target\n\nAnother common mistake is to use the same name for two different targets (@fig-error-duplicate).\nThis is common when copy pasting code.\nRename one of the objects and the problem is solved.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Error message for duplicate target.](Pics/error_duplicate.png){#fig-error-duplicate fig-alt='Error message for duplicate target.' width=579}\n:::\n:::\n\n\n::: callout-note\n## Exercise\n\nIf you have problems getting the target pipeline running, here is a working example that you can download or check online.\nNote that you need to have all the packages that are required for the targets pipeline to run installed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"usethis\") # if you don't have it already.\nusethis::use_course(\"biostats-r/targets_workflow_svalbard\")\n```\n:::\n\n\n:::\n\n## Resources\n\n- The [target manual](https://books.ropensci.org/targets/) contains everything you need to know\n<!-- did not find it on github -->\n- Here is a large and working [target plan]()\n- Here is a short introduction video {{< video https://vimeo.com/700982360 >}}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}