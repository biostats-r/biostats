---
output:
  html_document:
    css: custom-blockquote.css
---

```{r setup&variables, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# title: comparing two proportions - Wilcoxon signed-rank test
# author: jonathan
# revised: 13/1/2020 

WEB <- c("https://bioceed.uib.no/dropfolder/bioSTATS/Rmd/Basic/2-sample/wilcoxon.html")
GIT <- c("https://github.com/jonathansoule/biostats/blob/master/Basic/2-sample/wilcoxon.Rmd")
GFI <- c(7.9,	5.3, 3.7,	5.5, 4.5,	4.9, 4.6,	4.1, 6.5,	7.0, 7.2,	6.3, 6.5,	9.2, 12.7, 13.8, 18.3, 14.9, 15.0, 15.6)
date <- c(1:20)
GFI <- c(7.9,	5.3, 3.7,	5.5, 4.5,	4.9, 4.6,	4.1, 6.5,	7.0, 7.2,	6.3, 6.5,	9.2, 12.7, 13.8, 18.3, 14.9, 15.0, 15.6)
Yr <-  c(8.6, 6.4, 4.6, 6.3, 5.3, 5.5, 5.3, 4.8, 6.9, 7.5, 8.2, 7.1, 7.1, 9.8, 13.5, 14.2, 17.9, 15.3, 15.3, 16.1)
data.source <- rep(c("GFI", "Yr"), each = 20)
temperature <- c(GFI, Yr)
df <- data.frame(date, data.source, temperature)
library(ggplot2)
```
Wilcoxon signed-rank test may be used to compare the means of two *dependent* samples when the assumption of normal distribution may be a problem. This is a non-parametric test which is a good alternative to [Student’s paired t-test](http://biostats.w.uib.no/comparing-two-means-students-paired-t-test/){target="_blank"}.

The function to be used is the same as for [Mann-Whitney U test (Wilcoxon rank-sum test)](http://biostats.w.uib.no/comparing-two-means-mann-whitney-u-test/){target="_blank"} but with an extra argument which sets the test for dependent samples: `wilcox.test(x, y, paired = TRUE)` where `x` and `y` are the two paired samples and `paired = TRUE` the argument that turns the original test into a paired test.

Let’s take an example similar to the one used for [Student’s paired t-test](http://biostats.w.uib.no/comparing-two-means-students-paired-t-test/){target="_blank"}. Here, daily mean temperatures are recorded during the first 20 days of May 2019 at Florida, close to Bergen City Centre. Temperatures are retrieved *simultaneously* from 2 different sources,  [GFI](https://veret.gfi.uib.no/){target="_blank"} and [Yr](https://www.yr.no/){target="_blank"}; the data set thus consists of *pairs of measurements*. 

The first test below confirms that the samples do not originate from a normal distribution:
```{r normality, echo=FALSE}
shapiro.test(GFI)
shapiro.test(Yr)
```
<br /><br />
Now, let's visualize the data with a boxplot:
```{r boxplot, echo=FALSE}
ggplot(df, aes(data.source, temperature)) +
  geom_boxplot()
```
<br /><br />
Here, the medians are close to each other but not equal, and the spread is rather similar. Let's look at the data with a line plot.
```{r lineplot, echo=FALSE}
ggplot(df, aes(date, temperature, color = data.source)) +
  geom_line(size=1.25) +
  geom_point(size=2.5)
```
<br /><br />
It seems like there is a rather small, but constant gap between the lines. Is that enough to declare that the 2 samples are significantly different? Let's test it with Wilcoxon signed-rank test:

```{r wilcoxon, warning=FALSE}
wilcox.test(GFI, Yr, paired = TRUE)
```
So, the test results in a p-value *less* than 0.05, thus indicating that the null hypothesis (the sample means are not different) may be rejected. 

Note: If you wonder whether the argument `paired = TRUE` makes a difference or not, let's try the test without it:
```{r wilcoxon2, warning=FALSE}
wilcox.test(GFI, Yr)
```
This time, the p-value is *greater* than 0.05 and `H0` cannot be rejected anymore... So it is clearly important to know about the dependency of your samples; the conclusion of the test relies on that.

<br/><br/>

***
<!-- UNCOMMENT TO ACTIVATE
Get the Rmarkdown file corresponding to this page on [GitHub](`r GIT`){target="_blank"}.
-->
