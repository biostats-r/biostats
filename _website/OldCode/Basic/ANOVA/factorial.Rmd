---
output:
  html_document:
    css: custom-blockquote.css
---

```{r setup&variables, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# title: factorial design
# author: jonathan
# revised: 15/4/2020 

WEB <- c("https://bioceed.uib.no/dropfolder/bioSTATS/Rmd/Basic/ANOVA/factorial.html")
GIT <- c("https://github.com/jonathansoule/biostats/blob/master/Basic/ANOVA/factorial.Rmd")

library(ggplot2)

```

Whereas one-way ANOVA allows for comparison of three and more group means based on the different levels of a single factor, **factorial design** allows for comparison of groups based on **several independent variables and their various levels**. Thus, comparing observations (such as tree size, egg sizeâ¦) categorized by to two predictor variables (for example location and species) may be done via a **two-way ANOVA**; if three predictor variables are involved (for example location, species and year), then a **three-way ANOVA** may be usedâ¦ Further below, we will essentially talk about two-way ANOVA, but youâll quickly understand how the functions may be adapted to more factors.

Using factorial ANOVA, we get to assess **main effects**, in other words the impact of single factors (predictor variables) on a given response variable (plant size, egg number, individual bodyweightâ¦). We also get to see whether there exist **interactions** between factors, i.e. whether the effect of a specific factor is influenced by (one of the) other factors.

As for [one-way ANOVA](http://biostats.w.uib.no/one-way-anova/){target="_blank"}, the function to use is `lm()`, followed by `anova()`.

Letâs see that in an example similar to the one that we looked at in [one-way ANOVA](http://biostats.w.uib.no/one-way-anova/){target="_blank"}. Here, we check whether the average size of blue ground beetles (*Carabus intricatus*) differs depending on their location. We now introduce a new factor: measurements were performed in 2005 and in 2015 at the same 3 forests A, B and C. In each location, we measured the size (in millimeters) of 10 individuals (making it a balanced design). In total, 60 individuals were measured. The two factors are `location` and `year`.

Here is the code for creating the dataframe:

```{r dataframe}
# response variable
size <- c(25,22,28,24,26,24,22,21,23,25,26,30,25,24,21,27,28,23,25,24,20,22,24,23,22,24,20,19,21,22,24,27,26,24,25,27,22,28,25,24,27,29,26,27,25,27,28,24,24,26,21,23,25,20,25,23,25,19,22,21)

# predictor variables
location <- as.factor(c(rep("ForestA",10), rep("ForestB",10), rep("ForestC",10), rep("ForestA",10), rep("ForestB",10), rep("ForestC",10)))
year <- as.factor(c(rep("2005",30), rep("2015",30)))

# dataframe
my.dataframe <- data.frame(size,location,year)
```
<br/><br/>

We start by visualizing the data with boxplots. Since we have several factors, we'll group some of the boxes according to these factors.

```{r boxplot}
ggplot(my.dataframe, aes(x = location, y = size, fill = year)) +
  geom_boxplot()
```
<br/><br/>

### Assumptions

The assumptions are globally the same as for one-way ANOVA:

+ **independence of observations** (each individual is represented by 1 entry/measurement ONLY)
+ **normality of distribution** (to be tested for each group, for example with the [Shapiro-Wilk test](https://biostats.w.uib.no/test-for-normality-shapiro-wilks-test/){target="_blank"})
+ **homogeneity of variance** (to be tested with, for example, [Levene's test](https://biostats.w.uib.no/test-for-homogeneity-of-variances-levenes-test/){target="_blank"})
+ groups contain [**no outliers**](http://biostats.w.uib.no/finding-outliers/){target="_blank"}.

<br/><br/>

### Running the test

The syntax is `lm(response ~ predictor1 * predictor2, data = dataframe)` where `response` is the response variable, `predictor1` and `predictor2` are the predictor variables or factors (which categorize the observations) and `dataframe` the name of the dataframe that contains the data. 
We first need to fit the linear model with `lm()` and then we store it in the object `model`. We then compute and display the table for the analysis using `anova()`:
```{r lm}
model <- lm(size ~ location * year, data = my.dataframe)
anova(model)
```

The table above shows the F value and p-value for each of the main effects, `location` and `year`, as well as for the interaction `location:year`. It also conveniently indicates with stars where significance levels are reached. For instance, `size` is significantly affected by the factor `location`, and the p-value is very small (p<0.001, ***). There is no indication of an effect of `year`, nor an interaction between the two predictor variables.
<br/><br/>

Since there is no interaction, we may remove the interaction term from the model and run this syntax instead: `lm(response ~ predictor1 + predictor2, data = dataframe)`. The only difference is that a `+` replaces the `*`:
```{r lm2}
model2 <- lm(size ~ location + year, data = my.dataframe)
anova(model2)
```

Here again, `size` is significantly affected by the factor `location`, but not `year`. Note that the p-values are different from those we obtained for the first model. 
<br/><br/>

**But this does not tell us anything about the groups which means are significantly different.**

Indeed, this test tells you about main effects and interactions, but does not tell you which groups are significantly different from others. For that, we will need *post hoc* tests.  We can run [multiple comparisons in linear models [factorial design]](https://biostats.w.uib.no/post-hoc-tests-multiple-comparisons-in-linear-models-2/){target="_blank"}.

<br/><br/>

### Alternative

If you need an alternative test to the factorial ANOVA because, for example, you suspect violation of the assumption of normality of distribution, you may use a non-parametric test called [**Friedman rank sum test (or simply Friedman's test)**](http://biostats.w.uib.no/friedmans-test/){target="_blank"}.

<br/><br/>

***
<!-- UNCOMMENT TO ACTIVATE
Get the Rmarkdown file corresponding to this page on [GitHub](`r GIT`){target="_blank"}.
-->
