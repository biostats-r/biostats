---
output: html_document
---

```{r setup&variables, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# title: comparing two variances - Fisher's F test
# author: jonathan
# revised: 10/1/2020

WEB <- c("https://bioceed.uib.no/dropfolder/bioSTATS/Rmd/Basic/2-sample/comparing2variances.html")
GIT <- c("https://github.com/jonathansoule/biostats/blob/master/Basic/2-sample/comparing2variances.Rmd")

library(ggplot2)
data1 <- c(11.25, 10.00, 9.68, 10.52, 8.77, 9.92, 8.62, 10.21, 9.09, 10.36)
data2 <- c(10.52, 7.99, 9.20, 5.59, 14.64, 15.50, 16.96, 7.03, 9.36, 4.72)
sample <- rep(c("data1", "data2"), each = 10)
values <- c(data1, data2)
df <- data.frame(sample, values)
```

To compare the respective variances of two samples, you may use **Fisher’s *F* test**, also known as F-test of equality of variances. This test checks whether the variances of the two samples are equal, assuming that they do not deviate from *normality*. Note that this particular test is rather sensitive to the assumption of normal distribution. Thus you might want to [test for normality](https://biostats.w.uib.no/test-for-normality-shapiro-wilks-test/){target="_blank"} prior to performing Fisher’s F test.

In brief, Fisher’s F test calculates the ratio between the larger variance and the smaller variance. The ratio is then compared to a critical value which depends on the degrees of freedom and on the set value for **α** (usually 0.05). If the ratio is greater than the critical value, then the null hypothesis (`H0`, stating that the variances are equal) is rejected and you may declare that the variances are different.

The function in R that runs Fisher’s F test is `var.test(data1,data2)` where `data1` and `data2` are the vectors containing data from the two samples. Let’s use an example to illustrate the use of `var.test()`. First let’s visualize these two samples in a [boxplot](https://biostats.w.uib.no/7-boxplot/){target="_blank"}:
```{r boxplot, echo=FALSE}
ggplot(df, aes(sample, values)) +
  geom_boxplot()
```

The boxplot shows samples with means rather close to each other, but with dramatically different spreads. Let’s now look at their variance, here calculated with  [`var()`](https://biostats.w.uib.no/4-variance/){target="_blank"}):
```{r variance}
var(data1)
var(data2)
```

Unsurprisingly the variances differ a lot. But we need to run Fisher’s F test to get it confirmed. Since this test requires that normal distribution of the samples, let’s run the [Shapiro-Wilks normality](http://biostats.w.uib.no/test-for-normality-shapiro-wilks-test/){target="_blank"} test.

```{r normality}
shapiro.test(data1)
shapiro.test(data2)
```

In both cases, the p-value is high. The likelihood for these samples to *deviate from normality* is low. Thus, we can finally proceed with Fisher’s F test:
```{r Ftest}
var.test(data1, data2)
```
The F value (ratio of variances) is displayed, along with a p-value. Here the p-value is very low, thus the null hypothesis `H0` (stating that the variances are equal) is rejected.

Note that you may reverse the order of the samples in the function and consequently obtain a different F value:
```{r Ftest2}
var.test(data2, data1)
```
However, the p-value remains the same, and so does the conclusion: `H0` is rejected, the variances are significantly different.

Note: Fisher’s F test is not the only test for equal variance, but it is very commonly used. You could as well use Bartlett’s test or the Fligner-Killeen test of homogeneity of variances, but these are more often used for comparison of more than two groups (like in ANOVA). Bartlett’s test, like Fisher’s F test is rather sensitive to normality; thus, normality of distribution should be checked beforehand. However, Figner-Killeen test is non-parametric. It is thus a good alternative when normality is challenged. The corresponding functions in R are `bartlett.test()` and `fligner.test()`.
<br/><br/>

***
<!-- UNCOMMENT TO ACTIVATE
Get the Rmarkdown file corresponding to this page on [GitHub](`r GIT`){target="_blank"}.
-->
