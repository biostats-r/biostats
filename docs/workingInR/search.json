[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Working in R",
    "section": "",
    "text": "1 Introduction"
  },
  {
    "objectID": "index.html#what-is",
    "href": "index.html#what-is",
    "title": "Working in R",
    "section": "\n1.1 What is ?",
    "text": "1.1 What is ?\n is powerful statistical and graphical tool which is available for most platforms (Windows, Mac, Linux, etc.). R is both free and open source, which means that anyone can freely use it and access its source code, understand what it actually does with your data, create add-ons to fit a specific purpose, etc.\nR is not a conventional software where all tools are available via a graphical user interface (GUI) with menus and buttons. Instead, users run commands via a script, and read the output either in a console, or in a separate, dedicated window.\nR is also a programming language organized around objects that store data and functions that manipulate data. Throughout this website, you will learn this language and the art of writing meaningful code chunks that transform raw data into understandable results in the form of figures, tables, and reports.\n\n1.1.1 Why using R?\nR has been widely adopted by biologists and more generally by the life science community. The reasons include:\n\nR is free.\nR is efficient in terms of data processing, even with large data sets.\nR has a large, friendly online community ready to help and answer your questions.\nR is adaptable: you will most certainly find one or several packages (i.e. add-ons) for your discipline, or for solving the problems you face.\nR is transparent: the code behind functions and packages is accessible, meaning that you know exactly what R does to your raw data (you don’t have to assume it).\nR produces clean figures ready for publication in scientific journals.\nR allows for reproducible research: anyone running your code on your data will get the exact same result as you do.\nR code is easy to share and publish.\nR contributes to replicability: anyone can use your published code on another data set to replicate your findings (or not).\n\n\n\n\nContributors\n\nJonathan Soulé\nRichard Telford"
  },
  {
    "objectID": "0010_Getting_Started_with_RStudio.html#working-in-r-via-rstudio",
    "href": "0010_Getting_Started_with_RStudio.html#working-in-r-via-rstudio",
    "title": "\n2  Installing and configuring R and RStudio\n",
    "section": "\n2.1 Working in R via RStudio",
    "text": "2.1 Working in R via RStudio\nR comes with its own Graphical User Interface (GUI; Figure 2.1). Nearly everything in R happens either in the script editor (R editor - Figure 2.1, left window) where the user writes code, or in the console (R console - Figure 2.1, right window) which runs commands and prints results.\n\n\n\n\nFigure 2.1: R Graphical User Interface.\n\n\n\nIt is a minimalist GUI that does not offer much more than a short main menu and five buttons in total. This is the engine that will do all your analyses, but you will rarely, if ever, use it directly.\nInstead, you will use a more user-friendly interface, such as RStudio.\n\n2.1.1 What is RStudio?\nRStudio is an integrated development environment (IDE) for the R language written by posit (which used to be called RStudio). RStudio runs R “in the background”, and replaces R’s minimalist interface with its own (Figure 2.2). This means that you do not lose anything of R’s power, you simply work with it from a different perspective.\n\n\n\n\nFigure 2.2: RStudio Graphical User Interface.\n\n\n\nThis interface is more complex and organized. The script editor (top left) is more advanced and equipped with a syntax highlighter, which will prove useful when writing code. Many functions (console, file explorer, etc) are available and dispatched in panes and tabs. A significant benefit of using RStudio is the possibility to create and manage projects. Projects let you organize your tasks and load only the files and packages that you define as necessary for the workflow.\nWe will further describe RStudio’s interface in Section 2.3.1 and how to set up projects in Chapter 3. For now, let’s install everything we need, starting with R and RStudio."
  },
  {
    "objectID": "0010_Getting_Started_with_RStudio.html#sec-installing",
    "href": "0010_Getting_Started_with_RStudio.html#sec-installing",
    "title": "\n2  Installing and configuring R and RStudio\n",
    "section": "\n2.2 Installing R and RStudio",
    "text": "2.2 Installing R and RStudio\nThere are several ways to install R and RStudio, depending on the state of your computer.\n\n\nOn your own computer\nOn a UiB virtual computer\nOn a client computer\nRStudio in the cloud\n\n\n\nUse this option if\n\nYou have permission to install software on your computer (e.g. it is not a university-owned clien computer)\nYour computer is fast enough, and has enough hard disk space, to run R and RStudio (if not use the UiB virtual computer or posit.cloud)\n\nInstalling R\nGo to The Comprehensive R Archive Network. In the top section “Download and Install R”, click on the link that matches your platform and follow the instructions to install the version of R designed for your OS.\nInstall RStudio\nGo to RStudio’s website and download the free version of RStudio Desktop made for your OS. Install it on your computer.\nNTNU student\nNTNU students can access and download many programmes, including R and RStudio, through the apps.ntnu.no. GSo to apps.ntnu.no, search for R and RStudio and install both on your computer.\n\n\n\nUiB students and staff can access and download R and RStudio in a virtual computer, through the Third Party Portal (apps.uib.no).\nUse this option if\n\nYou are a UiB student or staff member\nYour own computer is too old and slow (or lacks hard disk space) to run R and RStudio\nYou don’t have permission to install software on your computer\n\nSimply go to apps.uib.no, search for R and RStudio and install both on your virtual computer. You will find information about how to log on and use the Third Party Portal for the first time here in Mitt UiB.\n\n\nUse this option if\n\nIf your computer is owned by your university, and you do not have permission to install software directly.\n\nIf you have a UiB or NTNU (and many other universities) owned computer you can install pre-approved software from a Software Center. If you have a client machine but do not have access to a Software Center, you need to ask your IT-department for help installing R and RStudio (you can use posit.cloud until your computer is fixed).\nThe version of R or RStudio in your software center can be old (e.g. R &lt; 4.2). If so, ask your IT-department to update them.\nUiB employees\nUiB employees working on a client computer should use the app “Software Center” (Windows 10) or “Managed Software Center” (Mac OS) to install R and RStudio. You will find help with programme installation here (Windows) and there (Mac OS).\nNTNU employees\nNTNU staff working on a client setup Windows computer should use the app “Software Center” that comes preinstalled to install R and RStudio. A description of how to find and use Software Center can be found here. Search for R and RStudio in “Applications”, and install both on your computer.\nAlternatively, go to apps.ntnu.no, search for R and RStudio and install both.\n\n\n\nposit.cloud is a web-service provided by posit which lets you run R and RStudio on their computer through a browser tab.\nUse this option if\n\nYour own computer is too old and slow (or lacks hard disk space) to run R and RStudio\nYou cannot run R and RStudio on the UiB virtual computer\nYou don’t have permission to install software on your computer\nYou want a zero hassle experience setting everything up\nYou don’t mind paying for the service if you use it throughout the course\n\nThere is a free plan, but you will probably need a paid plan (few dollars a month) if you want to use it throughout your course. posit.cloud is not suitable for large analyses as it has limited memory.\nTo set up an account, go to posit.cloud\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nInstall R and RStudio on your laptop (or set up one of the virtual computers).\nIf you already have these installed, check that the R version is 4.2 or newer (run R.version.string) and the RStudio version is 2023.03.0 or newer (run rstudioapi::versionInfo()$long_version)."
  },
  {
    "objectID": "0010_Getting_Started_with_RStudio.html#starting-with-rstudio",
    "href": "0010_Getting_Started_with_RStudio.html#starting-with-rstudio",
    "title": "\n2  Installing and configuring R and RStudio\n",
    "section": "\n2.3 Starting with RStudio",
    "text": "2.3 Starting with RStudio\nNow that both R and RStudio are installed on your computer, you are ready to start. Note that you do not (usually) need to do anything to link RStudio to R or vice versa. Everything should be ready to use.\n\n2.3.1 The interface\nWhen opening RStudio for the first time, the following main screen (Figure 2.3)) appears:\n\n\n\n\nFigure 2.3: Opening RStudio for the first time.\n\n\n\nThe interface is divided into 3 panes:\n\na large one to the left that contains the tabs Console, Terminal and Jobs,\na smaller one in the top right quadrant with the tabs Environment, History, Connections and Tutorial,\na last one in the bottom right quadrant with the tabs Files, Plots, Packages, Help and Viewer.\n\nIn the upcoming sections, we will see what these tabs are made for (NB: only the tabs in bold will be dealt with here).\n\n2.3.2 Scripts\nFirst, go to the main menu in File &gt; New File and choose R Script. This opens a new, empty tab called Untitled1 in the top left pane (Figure 2.4).\n\n\n\n\nFigure 2.4: The script Untitled1 shows up in the top left pane.\n\n\n\nThis tab displays a script. A script is a worksheet that looks a lot like a plain text file. This is where you will write your code, edit it, correct it if necessary. It may contain just a few lines, or hundreds of them. It may also contain comments (lines starting with the symbol #) which will help you keep track of your work.\nHere is a simple script:\n\n# this is my data\nsimple_data &lt;- c(4, 5, 9, 75, 2, 11, 8, 45, 61, 64, 54, 5, 4, 4, 16, 65, 4, 65, 1, 56, 16, 5, 49, 4, 65)\n\n# calculate the mean\nmean(simple_data)\n\n# calculate the standard deviation\nsd(simple_data)\n\nYou may open several scripts at the same time. Each of them will show up as a separate tab in the top left pane of RStudio. If the tab title is red and followed with a star *, this means that the script is not yet saved, or has been edited since the last time it was saved. Scripts may be saved at any time using .\nIn Chapter 4, we will talk more about working with scripts.\n\n2.3.3 Console and Terminal\nThe tabs Console and Terminal are located in the bottom left pane of RStudio, along with Jobs (Figure 2.5).\n\n\n\n\nFigure 2.5: The tabs Console and Terminal are located in the bottom left pane.\n\n\n\n\n2.3.3.1 The Console tab\nThe console is the R module that executes the commands. This is where you find the output/results of your commands providing that they can be display with symbols or characters (as opposed to graphics).\nA greater-than sign &gt; displays at the beginning of the line. This is the prompt. In the console, every command that you enter at the prompt appears in blue; the output of your commands is printed in black, and errors or warning messages appear in red (Figure 2.6).\n\n\n\n\nFigure 2.6: The console prints code, output and messages in different colors.”\n\n\n\nYou can actually write a simple command directly in the console and run it with Enter, but this is not good practice: one should always write code in the script and run it in the console (see Chapter 4). The exception is for code that you don’t want to run again, such as code to install a package.\nIf a plus sign + appears instead of &gt;, that means that your command is incomplete (you are possibly missing a bracket or a quote mark) and R is waiting for something more. You may either complete the code, or press esc to return to the prompt.\n\n2.3.3.2 The Terminal tab\nThe tab Terminal allows for manipulating files locally on your computer or remotely on a server, running Python scripts, etc (Figure 2.7).\n\n\n\n\nFigure 2.7: The Terminal tab allows for running commands outside of the R environment.\n\n\n\n\n2.3.4 Files, Plots and Packages\nThe tabs Files, Plots and Packages are located in the bottom right pane, along with Help and Viewer (Figure 2.8).\n\n\n\n\nFigure 2.8: The Files, Plots and Packages tabs are located in the bottom right pane.\n\n\n\n\n2.3.4.1 The Files tab\nThe tab Files is a file explorer that lets you navigate the folder structure of your project (for more info about projects, see Chapter 3).\nWhen RStudio starts up in a given project, the tab Files displays by default the content of the project folder. For a new project, the only content should be able to see is a single .Rproj file. NB: We will see in Chapter 3) what the benefits to work with a project are. This is also the folder where the scripts that you create are preferentially saved and stored. Feel free to add subfolders, data files and anything else that will be relevant for your work.\nAt the top of the pane, you will find the following menu:\n\n\n\n\nFigure 2.9: The menu in the Files tab\n\n\n\nVia this menu, you can rename and/or delete the files you have checked in the list beforehand; you can also create new folders, and copy or move items to other places via the dropdown menu of the button More.\n\n2.3.4.2 The Plots tab\nThe tab Plots is the place where graphic outputs that result from your code will be displayed.\nWhenever a code chunk leading to a plot is run in the console, the corresponding plot appears in that tab and its size will adapt automatically to the size of the pane. When changing the dimensions of the pane, plots will be automatically refreshed to fit the new frame.\nAt the top of the pane, you will find the following menu:\n\n\n\n\nFigure 2.10: The menu in the Plots tab\n\n\n\nVia this menu, you can explore all the plots that have been created (not only the latest one) with the arrows, zoom in and out, delete the current plot or all the plots. The button Export offers two options to save the currently displayed plot as a file. You may either save as image or save as pdf. In both cases, a dialog box pops up that lets you define the dimensions, target folder, file name, file type, etc.\n\n2.3.4.3 The Packages tab\nThe tab Packages provides you with a list of all the R packages that are currently installed on your computer (Figure 2.11).\n\n\n\n\nFigure 2.11: The Packages tab shows the packages installed on your computer.\n\n\n\nEach line corresponds to a specific package. The checkbox to the left indicates whether the package is currently loaded in RStudio or not, in which case any command referring to it will not perform properly. A short description of the package comes along, as well as the version of the package currently installed. Conveniently, the globe icon to the right brings you to the online information page, and the cross icon allows you to uninstall the package.\nOnly two items are found in the menu (Figure 2.12):\n\n\nInstall, which also you to install new packages from a remote repository or a file on your computer,\n\nUpdate, which searches for newer versions of the packages that are already on your computer.\n\n\n\n\n\nFigure 2.12: The Packages tab menu\n\n\n\n\n2.3.5 Environment and Tutorial\nThe tabs Environment and Tutorial are located in the top right pane, along with History and Connections (Figure 2.13).\n\n\n\n\nFigure 2.13: The Environment and Tutorial tabs are located in the top right pane.\n\n\n\n\n2.3.5.1 The Environment tab\nThe tab Environment lists all the R objects currently stored in memory in the current project along with a quick summary of their content.\nFigure 2.14 shows an example of the tab when four objects (one_2_three_4, one_two_three, result and results) have been stored in memory.\n\n\n\n\nFigure 2.14: The Environment tab shows the R objects stored in memory.\n\n\n\nYou can see that each object is displayed on its own line, along with a quick overview of its content and nature. You will learn about R objects and data in Chapter 9 and Chapter 10.\n\n2.3.5.2 The Tutorial tab\nThe tab Tutorial lists R tutorials which come pre-installed with packages and which may be run directly in this tab (Figure 2.15).\n\n\n\n\nFigure 2.15: The Tutorial tab is located in the top right pane.\n\n\n\nEach tutorial is displayed along with a short description, the package it originates from, and a button Start Tutorial ? (Figure 2.16).\n\n\n\n\nFigure 2.16: The Tutorial tab provides you with tutorials linked to R packages.\n\n\n\nAlong with the present website, we have written the package biostats.tutorials that will help you better learn stats and R. The installation procedure is described further below in Chapter 5. Once installed, our tutorials will be available in this tab."
  },
  {
    "objectID": "0010_Getting_Started_with_RStudio.html#sec-customise-rstudio",
    "href": "0010_Getting_Started_with_RStudio.html#sec-customise-rstudio",
    "title": "\n2  Installing and configuring R and RStudio\n",
    "section": "\n2.4 Customising RStudio",
    "text": "2.4 Customising RStudio\nR/RStudio does not require much configuring at start, even though the menus in Tools &gt; Global Options… let you change dozens of settings at any time. In fact, you should be ready to work right now. That said, there are a couple of things in RStudio that we recommend you customize.\n\n2.4.1 Taking care of .Rdata\n.Rdata is a file that R uses to store the workspace - objects, data, etc in the Environment - when you close RStudio so that you can resume working on an analysis when you restart RStudio. This sounds like a good idea, but it really isn’t, as the environment tends to fill up with objects and you no longer remember how you made them. This is bad for reproducibility. Much better to save the code needed to make the objects in a script (Chapter 4). Saving and loading the workspace also slows R down (a lot if you have many large objects).\nWe advise you to prevent RStudio from saving changes and restoring .Rdata to improve reproducibility.\nGo to\n\n\nTools\n\n\nGlobal Options…\n\n\nGeneral\n\n\nBasic\n\n\nto get to the menu shown in Figure 2.17. In the section Workspace (Figure 2.17, red box), uncheck the box, and select “Never” in the dropdown menu.\n\n\n\n\nFigure 2.17: Taking care of .Rdata\n\n\n\nOr, if you install the usethis package, you can do this in code with\n\nusethis::use_blank_slate()\n\n\n2.4.2 Soft-wrapping R scripts\nWhen the length of a code line exceeds the width of the editor, a horizontal scrollbar appears at the bottom of the editor, allowing you to navigate and review the whole line from its first to its last character. This setting makes things impractical as you will often have to scroll back and forth when reviewing multiple long lines. The obvious solution is to make sure you write short lines of code - a maximum of 80 characters is often recommended. However on a laptop, this can still be too long, so an alternative is to force RStudio to split the code onto the next line(s) of the editor – this is called soft-wrapping. We recommend that you activate soft-wrapping in RStudio.\nGo to\n\n\nTools\n\n\nGlobal Options…\n\n\nCode\n\n\nEditing\n\n\nto get to the menu shown in Figure 2.18 and check the box “Soft-wrap R source files” highlighted by the red box.\n\n\n\n\nFigure 2.18: Enabling soft-wrapping of R scripts and the native pipe operator\n\n\n\n\n2.4.3 Use the native pipe\nWhile you have the menu open to enable soft wrapping, also enable the native pipe operator keyboard shortcut, by checking the box highlighted by the blue box in Figure 2.18. You will learn more about pipes in Chapter 12.\n\n\n\n\n\n\nExercise\n\n\n\nConfigure RStudio so that\n\n.Rdata files are not restored when RStudio is started\n.Rdata files are not saved when you close RStudio\nSoft-wrap is set on\nThe native pipe keyboard shortcut is enabled"
  },
  {
    "objectID": "0010_Getting_Started_with_RStudio.html#rstudio-keyboard-short-cuts",
    "href": "0010_Getting_Started_with_RStudio.html#rstudio-keyboard-short-cuts",
    "title": "\n2  Installing and configuring R and RStudio\n",
    "section": "\n2.5 RStudio keyboard short-cuts",
    "text": "2.5 RStudio keyboard short-cuts\nYou have already been introduced to RStudio short-cuts to run code. There are many more - press . You certainly don’t need to learn them all. Here are some we find useful\n\nrun line \n\nFind/replace \n\nFind in files \n\nInsert assignment operator \n\nComment/uncomment selected lines \n\nHelp on selected function \n\n\nYou will be introduced to more short-cuts later.\n\n\n\n\n\n\nQuiz\n\n\n\nQuestion 1: Why should you set RStudio option to never restore .RData on start-up \n\nto make starting RStudio fasterto make your analysis more reproduciblereduce the probability of bugs in your codeall of the above\n\n\n\n\n\n\n\n\n\nFurther Reading\n\n\n\nYou may find the following links useful:\n\nR for Data Science\nUsing the RStudio IDE\nThe tidyverse\n\n\n\n\n\n\n\n\n\nWhat’s next\n\n\n\nYou will now learn the basics of the R language, make simple calculations, learn about data types, store and handle data in R objects.\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "0011_projects.html#opening-a-project",
    "href": "0011_projects.html#opening-a-project",
    "title": "3  RStudio projects",
    "section": "\n3.1 Opening a project",
    "text": "3.1 Opening a project\nOnce you have made a project, you need to make sure that you are using it when you start RStudio. You can check this by looking in the top right corner of RStudio: it will say “Project: (None)” if you are not in a project, and will show your project name if it is correct. There are several ways to open an RStudio project\n\nby clicking on the file in your file manager\nclick on the list o recently opened projects in the top right corner of RStudio and selecting your project\nfrom the menu\n\n\nFile\n\n\nOpen Project…"
  },
  {
    "objectID": "0011_projects.html#organising-files-in-a-project",
    "href": "0011_projects.html#organising-files-in-a-project",
    "title": "3  RStudio projects",
    "section": "\n3.2 Organising files in a project",
    "text": "3.2 Organising files in a project\nImagine how hard it would be to find what you wanted to wear if you kept all your clothes in a heap on the floor. It’s the same when you keep all your files in one directory (norsk: mappe), which might look something like this.\n\n\n.\n├── analyse.R\n├── final-lake-tilo-chemistry.csv\n├── final2_lake-tilo-diatoms.csv\n├── final_lake-tilo-diatoms.csv\n├── import.R\n├── manuscript.pdf\n├── manuscript.qmd\n├── my_project.Rproj\n└── references.bib\n\n\nMuch better to use sub-directories to organise the files.\n\n\n.\n├── R\n│   ├── 01_import.R\n│   └── 02_analyse.R\n├── data\n│   ├── 2022-3-24_lake-tilo-chemistry.csv\n│   ├── 2022-3-24_lake-tilo-diatoms.csv\n│   └── 2022-8-15_lake-tilo-diatoms.csv\n├── my_project.Rproj\n├── output\n│   └── manuscript.pdf\n└── quarto\n    ├── manuscript.qmd\n    └── references.bib\n\n\nIn this example, the data files are in the “data” directory. It is important to keep the raw data files separate from any processed data files (you might need a “raw-data” directory). The creation data of each file is included in the file name to make it easy to sort them (much better than “final” and “final2”). The R scripts are in the “R” directory (some people call this directory “code” as it can contain languages other than R). The scripts are numbered in the order that they are used. The quarto directory contains markdown and associated files. Any output files are kept in the “output” directory.\n\n\n\n\n\n\nExercise\n\n\n\nCreate directories in your project for data and R code. You can do this in the RStudio files tab, your computers file manager (or directly in R with fs::dir_create()).\n\n\n\n\n\n\n\n\nQuiz\n\n\n\nQuestion 1: Why should you use RStudio projects for your work? \n\nbecause Richard will hassle you until you dobecause they make R so much easier to work with\n\nQuestion 2: What do RStudio projects not help with: \n\norganising filescollaboratingmaking research more repoduciblemaking coffeesetting the working directoryworking with git and GitHub\n\nQuestion 3: How many RStudio projects should you have \n\nonetypically one per course or manuscript\n\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nRichard Telford"
  },
  {
    "objectID": "0012_scripts.html#what-is-a-script",
    "href": "0012_scripts.html#what-is-a-script",
    "title": "4  Working with a script",
    "section": "\n4.1 What is a script?",
    "text": "4.1 What is a script?\nYou can code directly in the RStudio console. This is useful for throwaway code that you never want to run again. If you want to be able to run the code again (and you probably do) you should put your code in a script (or equivalently a code chunk in a quarto document).\nPractically, a script is a plain text file where you write your code, whether it contains a handful of lines or dozens of them. It is an evolving document which not only helps you keep track of your code, but also your workflow.\nWith time, you will realize that a script is a lot of things at the same time:\n\nit is a whiteboard where you try coding for something and correct mistakes whenever you find out things do not work as expected,\nit contains your coding history, where all the steps from loading a data set to printing the final output are chronologically exposed,\nit is the key file that you may share with collaborators, etc,\nit is guarantee that your work is reproducible, meaning that you can run your code on your data set again and again, and obtain the same result, consistently.\n\nA simple script may look like this:\n\n# activate tidyverse\nlibrary(tidyverse)\n\n# load the data from external file\nVeronica_Vestland &lt;- read_delim(\"Veronica_Vestland.csv\", delim = \",\")\n\n# calculate the mean and standard deviation of Sepal.Length for each Location\nmean_sd_SL &lt;- Veronica_Vestland |&gt;\n           group_by(location) |&gt;\n           summarise(mean(Sepal.Length), sd(Sepal.Length))\n\n# print the result\nmean_sd_SL\n\n# draw boxplot Sepal.Length for each Location\nggplot(Veronica_Vestland,\n       aes(x = Location, y  = Sepal.Length, fill = Location)) +\n  geom_boxplot()\n\nYou will be able to write similar code to this very soon."
  },
  {
    "objectID": "0012_scripts.html#making-a-new-script",
    "href": "0012_scripts.html#making-a-new-script",
    "title": "4  Working with a script",
    "section": "\n4.2 Making a new script",
    "text": "4.2 Making a new script\nYou can make a new script with\n\n\nFile\n\n\nNew File\n\n\nR Script"
  },
  {
    "objectID": "0012_scripts.html#running-the-code",
    "href": "0012_scripts.html#running-the-code",
    "title": "4  Working with a script",
    "section": "\n4.3 Running the code",
    "text": "4.3 Running the code\nWriting code in a script does not do anything per se. To tell R to do something, you must place the cursor anywhere on a line of code and\n\npress the Run button above the script\ntype  to run that line\n\nThis will run the line of code and any syntactically connected to it. You can also select some code (perhaps a part of a line or several lines) and run it with either of the above methods.\nThe result of your command(s) will appear in the tab Console if the commands are intended to print something, and/or in the tab Plots if the commands generate a plot."
  },
  {
    "objectID": "0012_scripts.html#code-versus-comment",
    "href": "0012_scripts.html#code-versus-comment",
    "title": "4  Working with a script",
    "section": "\n4.4 Code versus comment",
    "text": "4.4 Code versus comment\nIn the script above, there are two types of lines: those that start with the symbol #, and those that do not.\nLet’s start with the lines that do not start with a #. They are the real code, the commands that manipulate the data. Right now these lines do not mean much to you, but in fact, each of them commands R to “do something specific” with your data. That “something specific” is defined by functions which are followed by parentheses – function(). In the R language, functions are verbs in your sentences, the data are their subject. For example, in the code above, library(tidyverse) commands R to activate the package tidyverse found in the package library.\nThe lines that start with a # are comments. They do not code for anything at all. When you run the script via a console, R simply ignores them. So use comments to keep track of what you do with the code. Write what the point of each real code line is, what you plan to do. That way, you will always remember what you originally intended to code for.\nThe symbol # is also convenient to prevent R from running a specific code line or chunk, without having to delete that line. Indeed if you place a # in front of any line, the console will consider it as a comment, and simply skip it.\nIn the following example, each line was originally written to activate a different package:\n\nlibrary(ggplot2)\nlibrary(tidyr)\n# library(tidyverse)\nlibrary(readr)\n\nHowever, the third line has been commented with a #. Consequently, only the packages ggplot2, tidyr, and readr are activated; tidyverse will be ignored. If you want to comment out or uncomment many lines of code at once, you can use the Rstudio shortcut ."
  },
  {
    "objectID": "0012_scripts.html#writing-readable-code",
    "href": "0012_scripts.html#writing-readable-code",
    "title": "4  Working with a script",
    "section": "\n4.5 Writing readable code",
    "text": "4.5 Writing readable code\nCode can be difficult to read when you try working on it again after a few weeks or months.\nHere are three tips for making it easier\n\nuse good comments\nuse good object names (Section 8.1.4)\ncodeishardtoreadifwithoutwhitespace\n\nIn the section First Steps in R, you will learn to write in the R language. We strongly advise you to work in scripts, and make extensive use of comments from the start. This is considered good coding practice, and will save you quite some time and energy."
  },
  {
    "objectID": "0012_scripts.html#special-characters",
    "href": "0012_scripts.html#special-characters",
    "title": "4  Working with a script",
    "section": "\n4.6 Special characters",
    "text": "4.6 Special characters\nR uses some special characters, including ~, {, [, and $ (see Chapter 25 for a more complete list). These characters are usually easy to find on a Windows computer. If you are using a Mac, make sure you can find these.\n\n\n\n\n\n\nQuiz\n\n\n\nQuestion 1: Your R console shows ‘+’ instead of the usual ‘&gt;’ prompt. What does this mean? \n\nR is broken and need to be re-installedthe current command is unfinished. Perhaps a bracket or quote mark is missing.R is now a calculator and is waiting for a number\n\n\n\nhint\n\nSee Section 2.3.3.1. Usually best to press escape.\n\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nRichard Telford"
  },
  {
    "objectID": "0013_packages.html#functions-packages",
    "href": "0013_packages.html#functions-packages",
    "title": "5  Installing packages",
    "section": "\n5.1 Functions & Packages",
    "text": "5.1 Functions & Packages\nEverything that does something in R is a function.\nAll functions arranged into packages.\nPackages are stored in libraries.\nSome R packages, for example, stats and utils, are automatically loaded when you start R. You can see the packages you have installed (and which are loaded) in the tab Packages (see Section 2.3.4.3).\nThere are also several recommended packages that are installed by default, for example the mgcv package for fitting generalised additive models."
  },
  {
    "objectID": "0013_packages.html#loading-packages",
    "href": "0013_packages.html#loading-packages",
    "title": "5  Installing packages",
    "section": "\n5.2 Loading packages",
    "text": "5.2 Loading packages\nIf you want to use the functions in a package, you need to load the package with the function library().\n\nlibrary(\"mgcv\")"
  },
  {
    "objectID": "0013_packages.html#installing-extra-packages",
    "href": "0013_packages.html#installing-extra-packages",
    "title": "5  Installing packages",
    "section": "\n5.3 Installing extra packages",
    "text": "5.3 Installing extra packages\nIn addition to the packages already installed, there are thousands of extra packages available for download that expand the computing possibilities of R by adding new functions, classes, documentation, data sets, etc.\nThe vast number of available packages is a little daunting, but many are very specialised, and won’t be useful for you. If you don’t know the name of the package you need for your analyses the task views can help. For example, the Environmetrics task view describes packages for the analysis of ecological and environmental data.\nMany packages can be downloaded from CRAN (R’s homepage), and others can be installed from GitHub. The next sections show you how to install packages from these locations.\nEvery time you install a new package, R imports all necessary files into a local library, but does not activate it. You will have to remember to activate the new package with library() every time your project require items or functions from that package.\n\nBooks vs R packages\n\n\n\n\n\n\n\nBook\nR Package\n\n\n\nHow to get\nOrder from your favourite bookshop\ninstall.packages(\"tidyr\")\n\n\nWhen it is kept\nBookshelf/library\nA Library\n\n\nHow to use it\nOpen book\nlibrary(tidyr)"
  },
  {
    "objectID": "0013_packages.html#packages-published-on-cran",
    "href": "0013_packages.html#packages-published-on-cran",
    "title": "5  Installing packages",
    "section": "\n5.4 Packages published on CRAN",
    "text": "5.4 Packages published on CRAN\nThere are lots of extra R packages available from CRAN.\nYou can install or update a package from CRAN with install.packages(). Simply type the name of the the package you want to install and add quotation marks \" \".\n\ninstall.packages(\"tidyr\")\n\nYou only need to do this once, until you need to install a new version of a package, so you should run this directly in the console and not keep it in your script or markdown document (otherwise it will install the package every time you run the code which will be slow).\nOnce you have installed the package, you can use library() to load it. You need to do this every time use use it.\n\n\n\n\n\n\nRtools\n\n\n\nIf you are using a Windows computer, when you install a package you may get the warning\n\nWARNING: Rtools is required to build R packages but is not currently installed.\n\nRtools is required to install packages from their source code when they have code (e.g. C or Fortran) that needs compiling. If you are installing packages with install.packages(), you are, by default, installing binary files from CRAN that just need to be unzipped, and so Rtools is not required."
  },
  {
    "objectID": "0013_packages.html#packages-published-on-github",
    "href": "0013_packages.html#packages-published-on-github",
    "title": "5  Installing packages",
    "section": "\n5.5 Packages published on GitHub",
    "text": "5.5 Packages published on GitHub\nNot all R packages are available on CRAN. Some packages are only available on GitHub.com. If you want to install a package published on GitHub, you may use the function remotes::install_github() (install remotes from CRAN first). You need the repo name from GitHub, this given as \"name_of_owner/name_of_repo\" Here also, you must add quotation marks \" \".\n\ninstall.packages(\"remotes\")\n#ggvegan for plotting ordinations is only on github\nremotes::install_github(repo = \"gavinsimpson/ggvegan\")"
  },
  {
    "objectID": "0013_packages.html#recommended-packages",
    "href": "0013_packages.html#recommended-packages",
    "title": "5  Installing packages",
    "section": "\n5.6 Recommended packages",
    "text": "5.6 Recommended packages\nThese packages are ones we recommend you install now:\n\nusethis\nremotes\ntidyverse\npalmerpenguins\nbiostats.tutorials\n\nThese packages will be used throughout the website. There are other packages we will install later.\n\n5.6.1 usethis and remotes\n\nThese are utility packages that we will use to download course material and packages from GitHub.\n\n5.6.2 The tidyverse\nThe tidyverse is an amazing toolbox which contains a growing, evolving collection of R packages for data science. The packages are developed on the same philosophy and are fully compatible with each other. Some of the tidyverse packages help you import data (readr), some let you make figures (ggplot2), others help you rearrange your data set (dplyr, tidyr), and much more. Have a look at the tidyverse webpages to explore the collection.\nInstall and activate the tidyverse with the following code:\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nThis will load the core tidyverse packages, which include readr, dplyr, and ggplot2 so you don’t need to load these separately.\n\n5.6.3 palmerpenguins\npalmerpenguins is a package that provides you with two real data sets. They contain measurements from three penguin species found in the Palmer archipelago, Antarctica. Several variables such as species, island, and body mass are included for over three hundred penguins. These data sets will be used in the upcoming sections of this website.\nInstall and activate the package with this code:\n\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\n\nType this following line in the console if you want to know more about palmerpenguins:\n\ncitation(\"palmerpenguins\")\n\n\n5.6.4 biostats.tutorials\nAlong with the present website, our team has developed a package with tutorials called biostats.tutorials. This package will help you learn and practice R functions and concepts. Several of the upcoming chapters refer to this package. Install biostats.tutorials with this code:\n\n#install.packages(\"remotes\")\nremotes::install_github(\"biostats-r/biostats.tutorials\")\n\nNow load the package with library(biostats.tutorials) and the tutorials should appear in the tab Tutorial (see Section 2.3.5.2). Exercises will tell you when to run a tutorial. Click the “Start Tutorial” button to start the tutorial (this may take a few seconds to start the first time).\n\n\n\n\n\n\nExercise\n\n\n\nInstall tidyverse, palmerpenguins and remotes from CRAN and biostats.tutorials from GitHub using the code above."
  },
  {
    "objectID": "0013_packages.html#debugging-failed-package-installation",
    "href": "0013_packages.html#debugging-failed-package-installation",
    "title": "5  Installing packages",
    "section": "\n5.7 Debugging failed package installation",
    "text": "5.7 Debugging failed package installation\nSometimes packages fail to install properly. This can be frustrating and difficult to debug.\nSome recommendations\n\nCheck exactly which package won’t install. It may be a dependency of the package you want that has problems installing. Try to install the package or dependency again and pay attention to any error message.\nRestart R (in Session menu in RStudio) and try again.\nFind your user library with .libPaths() and in the file manager delete the packages directory.\nGoogle any error message. Someone else may have had the same problem.\nTry installing the package directly in R (i.e not using RStudio)"
  },
  {
    "objectID": "0013_packages.html#name-conflicts",
    "href": "0013_packages.html#name-conflicts",
    "title": "5  Installing packages",
    "section": "\n5.8 Name conflicts",
    "text": "5.8 Name conflicts\n\n5.8.1 The problem\nSometimes two packages have functions with the same names. For example, both MASS and dplyr have a select function which does completely different things. If both packages are loaded at the same time there is a conflict and the function that was loaded last takes priority. This can cause big problems, with difficult to interpret error messages.\n\nlibrary(palmerpenguins) # load data\nlibrary(dplyr)\nlibrary(MASS) # R will report that select is being masked\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\npenguins |&gt; select(species)\n\nError in select(penguins, species): unused argument (species)\n\n\nIf you have code that worked one day and fails the next with a weird error messages, it might be because of a name conflict. If you start typing a function name into RStudio, it will show which package the function comes from.\nThere are three solutions.\n\n5.8.2 Loading order\nBe very careful about the order in which packages are loaded. If the example above had loaded MASS before dplyr the select function in MASS would have been masked and the code would have worked. This solution can is very fragile as it is easy to load packages in the wrong order.\n\n5.8.3 package::function\n\nUse the package::function notation to specify which package a function comes from. This is safe and can make code easier to understand by explicitly showing which packages the functions are from. The code above could be written safely as\n\npenguins |&gt; dplyr::select(species)\n\n# A tibble: 344 × 1\n  species\n  &lt;fct&gt;  \n1 Adelie \n2 Adelie \n3 Adelie \n# ℹ 341 more rows\n\n\nThis gets tedious fairly quickly, so is best used with packages that you only need a few functions from once or twice, not many functions you need repeatedly.\n\n5.8.4 conflicted package\nThe safest solution is to use the conflicted package. The conflicted package converts any conflicts between packages into errors. This might seem like a bad idea, but it is much easier to diagnose an error from conflicted than the weird error of a masked function.\n\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(conflicted)\n\npenguins |&gt; select(Species)\n\nError:\n! [conflicted] select found in 2 packages.\nEither pick the one you want with `::`:\n• MASS::select\n• dplyr::select\nOr declare a preference with `conflicts_prefer()`:\n• `conflicts_prefer(MASS::select)`\n• `conflicts_prefer(dplyr::select)`\n\n\nAs the error message suggests, we can resolve the error either by using the package::function notation, or use the function conflict_prefer to say which function we want to use by default.\n\nlibrary(dplyr)\nlibrary(MASS)\nlibrary(conflicted)\nconflict_prefer(\"select\", \"dplyr\")\n\n[conflicted] Will prefer dplyr::select over any other package.\n\npenguins |&gt; select(species)\n\n# A tibble: 344 × 1\n  species\n  &lt;fct&gt;  \n1 Adelie \n2 Adelie \n3 Adelie \n# ℹ 341 more rows\n\n\nIf there are many functions from a package that conflict, for example if you have loaded tidylog, you can use conflict_prefer_all().\n\nconflict_prefer_all(\"tidylog\")"
  },
  {
    "objectID": "0013_packages.html#packages-change-over-time",
    "href": "0013_packages.html#packages-change-over-time",
    "title": "5  Installing packages",
    "section": "\n5.9 Packages change over time",
    "text": "5.9 Packages change over time\nR packages often get updated. This is good as functions get added or improved and bugs get fixed. However, it also means that code written last year might give the same result (or even not work at all) next year with all the latest packages. This is a big problem for reproducibility.\nThe solution is to make sure you re-run your code with the same packages. That is not easy to do by hand. The renv package keeps track of all the packages you are using (and all the packages they depend on). I use renv for my analyses.\nThe workflow when working with renv is:\n\nCall renv::init() to initialise a private R library for the project\nWork in the project as normal, installing R packages as needed in the project\nCall renv::snapshot() to save the state of the project library\nContinue working on your project, installing and updating R packages as needed. Use renv::install() to install packages from CRAN or GitHub.\nIf the changes were successful, call renv::snapshot() again. If the updated packages introduced problems, call renv::restore() to revert to the previous state of the library."
  },
  {
    "objectID": "0013_packages.html#writing-your-own-functionpackages",
    "href": "0013_packages.html#writing-your-own-functionpackages",
    "title": "5  Installing packages",
    "section": "\n5.10 Writing your own function/packages",
    "text": "5.10 Writing your own function/packages\nIf you find that you need to run the same code several times, it can be useful to write a function.\nTo make a function, you need to use the reserved word function followed by brackets with zero or more arguments. After the brackets, braces encompass the body of the function.\nHere is a function that multiples two numbers together.\n\nmutliply &lt;- function(x, y = 1){ #The default value of y is 1\n  x * y\n}\n\nmultiply(x = 6, y = 7)\n\nOnce you have written a function, it can be useful to make your own package. This makes it easy to use in your own analysis and easy to share with other users. Information on how to make a package using the usethis and devtools packages can be found in the package writing book."
  },
  {
    "objectID": "0013_packages.html#citing-packages",
    "href": "0013_packages.html#citing-packages",
    "title": "5  Installing packages",
    "section": "\n5.11 Citing packages",
    "text": "5.11 Citing packages\nWhen you use a package it is important to cite it in a manuscript or thesis both to acknowledge the author’s work in making the package and to increase reproducibility. The correct citation can be seen with the function citation.\n\ncitation(\"lme4\")\n\nTo cite lme4 in publications use:\n\n  Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015).\n  Fitting Linear Mixed-Effects Models Using lme4. Journal of\n  Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Fitting Linear Mixed-Effects Models Using {lme4}},\n    author = {Douglas Bates and Martin M{\\\"a}chler and Ben Bolker and Steve Walker},\n    journal = {Journal of Statistical Software},\n    year = {2015},\n    volume = {67},\n    number = {1},\n    pages = {1--48},\n    doi = {10.18637/jss.v067.i01},\n  }\n\n\nIt is also important to cite the version used.\n\npackageVersion(\"lme4\")\n\n[1] '1.1.33'\n\n\nYou should also cite R. Again, the citation function can be used\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2023). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2023},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nThe R version can be obtained with R.version.string. This is a variable not a function so it does not take brackets.\n\nR.version.string\n\n[1] \"R version 4.3.1 (2023-06-16)\"\n\n\nIn quarto you can also use the insert citation tool to add a package to your bibliography.\n\n\n\n\n\n\nQuiz\n\n\n\nQuestion 1: You have installed the tidyverse package. Which command do you need to use to activate it? \n\ninstall.packages(\"tidyverse\")libraries(tidyverse)library(tidyverse⁠)package(tidyverse)Library(tidyverse)\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCheck your computer is ready for the next chapter with the checker package. This will check that your computer has the correct versions of R and RStudio installed, the required packages, and that the recommended RStudio options are set.\nFirst install the checker package.\n\ninstall.packages(\"checker\")\n\nNow run\n\nchecker::chk_requirements(\"https://raw.githubusercontent.com/biostats-r/biostats/main/checker/basic.yaml\")\n\nPlease address any issues checker finds before continuing to the next chapter.\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nRichard Telford"
  },
  {
    "objectID": "0021_R_calculator.html#basic-operations-in-r",
    "href": "0021_R_calculator.html#basic-operations-in-r",
    "title": "6  R as a calculator",
    "section": "\n6.1 Basic operations in R",
    "text": "6.1 Basic operations in R\n\n6.1.1 Arithmetic operations\nPerforming arithmetic operations is no big deal in R. Simply write any operation using the usual arithmetic operators +, -, * and / and run your code. No need to type =.\n\n5 + 3\n\n[1] 8\n\n9 * 2\n\n[1] 18\n\n14 / 3\n\n[1] 4.666667\n\n\nR allows you to add parentheses ( ) when you need to impose the order of operations. When it comes to raising a number to the power of another one, use the symbol ^ or **.\n\n(24 + 3) ^ (1 / 3)\n\n[1] 3\n\n\n\n\n\n\n\n\nExercise\n\n\n\nIn R, calculate:\n\n25 plus 49\n6 minus 19\n8 multiplied by 6\n7 divided by 2\n9 squared\nmultiply the sum of 9 and 2 by 3\n\n\n\n\n6.1.2 Comparisons\nYou can compare 2 elements using the following operators:\n\n\n&gt; greater than,\n\n&gt;= greater than or equal to,\n\n&lt; less than,\n\n&lt;= less than or equal to,\n\n== equal to,\n\n!= not equal to.\n\nWhen comparing two elements, R returns either TRUE or FALSE.\n\n9 == 3 * 3\n\n[1] TRUE\n\n5 &gt; 4\n\n[1] TRUE\n\n9^2 != 9 * (3 + 6)\n\n[1] FALSE\n\n\n\n\n\n\n\n\nExercise\n\n\n\nIn R,\n\nTest whether 22/7 is larger than pi\n\nTest if cats are greater than dogs. Why? (remember to use quote marks)\n\nHint\n\nPrøv katter og hunder også\n\n\n\n\n\n\n6.1.3 Operations with functions\nMore complex operations such as square root, logarithms and exponentiation shall be run using specific functions. These functions are sqrt(), log(), exp(), etc.\n\n\n\n\n\n\nExercise\n\n\n\nIn R, calculate\n\nThe square root of 29\nThe exponent of 29\nThe natural logarithm of 29\nThe base 10 logarithm of 29\n\nYou may need to look at the built-in help (Chapter 7) for some of these.\n\n\n\n\n\n\n\n\nWhat’s next\n\n\n\nHow to get help (Chapter 7)\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "0022_help.html#built-in-help",
    "href": "0022_help.html#built-in-help",
    "title": "7  Help!",
    "section": "\n7.1 Built-in help",
    "text": "7.1 Built-in help\nYou can get help for any function by putting a ? before the name of the function.\nSo to get help for the function log(), run\n\n?log\n\nor type fn-F1 (F1 works on some computers) to get help for the command under the cursor.\nThis will open the help file in the Help tab of RStudio (by default in the lower left quadrant. You can also search the help from the Help tab.\nMost help files have a similar structure (although some sections are optional).\n\n\nDescription briefly describes the function\n\nUsage shows the function and its arguments including any defaults\n\nArguments describes how the arguments to the functions should be used\n\nDetails Give more details about how to use the function\n\nValue Describes the output of the function\n\nExamples Gives examples of how to use the function. This is often one of the most useful parts of the help. You can run the examples by clicking on the “Run examples” link in the help file.\n\n\n\n\n\n\n\nExercise\n\n\n\nLook at the help file for length() and run the examples.\n\n\n\n7.1.1 Vignettes and demos\nVignettes are long-form documentation that can explain how to use a package. The best way to access them for the dplyr package is to run\n\nhelp(package = \"dplyr\")\n\nand then click on “User guides, package vignettes and other documentation.\nSome packages have demos that are like long example sections showing how to use some functions. You can access these with the demo() function."
  },
  {
    "objectID": "0022_help.html#on-line-sources-of-help",
    "href": "0022_help.html#on-line-sources-of-help",
    "title": "7  Help!",
    "section": "\n7.2 On-line sources of help",
    "text": "7.2 On-line sources of help\nThe help files are sometimes not the most user friendly.\nOne of the great things about R is how many sources of help there are.\n\nR questions on stackoverflow.com\n\nRstudio community\n\nThere are hundreds of thousands of answers between these sites, so it is likely that other people have had the same problem and asked the same question. Always search to see if find an answer before asking a question. For both these site, it is very important to provide a minimal reproducible example. That is example data (perhaps a built-in dataset) and code that can be run to show the problem. Code not relevant to the problem should be removed. The package reprex is useful for making reproducible example. Very often, making the reproducible example is enough to identify and fix the problem."
  },
  {
    "objectID": "0022_help.html#artificial-intellegence-help",
    "href": "0022_help.html#artificial-intellegence-help",
    "title": "7  Help!",
    "section": "\n7.3 Artificial Intellegence help",
    "text": "7.3 Artificial Intellegence help\nIn the last year or two, AI language models have been developed that can help coding in R. This is an area with rapid development, with new products appearing regularly. You ask the AI a question and the AI will reply.\nI asked chatGPT, a “How can chatGPT help me code in R?” and it replied\n\n\n\n\n\n\nChatGPT can assist you with coding in R by providing explanations, examples, and solutions to your programming questions. Here’s how it can help you:\n\nCode Snippets and Examples: You can ask for specific code examples in R for various tasks. Whether you need help with data manipulation, visualization, statistical analysis, or any other programming task in R, ChatGPT can provide you with relevant code snippets to get you started.\nSyntax and Function Explanations: If you’re unsure about the syntax of a particular R function or how to use it, you can ask ChatGPT to explain the function’s purpose and how to correctly use it in your code.\nDebugging Assistance: If you encounter errors or bugs in your R code, you can describe the issue to ChatGPT, and it can help you identify potential reasons for the problem and suggest ways to fix it.\nAlgorithm and Approach Suggestions: If you’re working on a specific task or problem and need advice on the best algorithms or approaches to use in R, ChatGPT can provide recommendations based on its programming knowledge.\nGuidance on Best Practices: ChatGPT can provide insights into coding best practices in R, such as efficient ways to write code, optimize performance, and structure your projects.\nData Analysis and Visualization: If you’re working on data analysis and visualization tasks, ChatGPT can guide you on using popular R packages like dplyr, ggplot2, and others to clean, analyze, and visualize your data effectively.\nUnderstanding Concepts: If you’re struggling to understand certain programming concepts in R, you can ask ChatGPT to explain those concepts in a clear and concise manner.\nLearning Resources: ChatGPT can suggest online tutorials, documentation, and resources to further enhance your understanding of R programming.”\n\n\n\n\nYou need a account to use chatGPT. This is free for GPT-3.5 or costs $20/month for the more powerful GPT-4.\nChatGPT-3.5 was trained on information available in September 2021. It has no information about anything that happened after that date, which includes the development of quarto and the current version of tidyverse.\nPhind uses a search engine and summarises what it finds in the output. This means that it knows about recent developments, it also gives the sources it used\nBe aware that these models do not understand how code works and often generate nonsense code. If you use them, you have to check that the code does what you want, you are responsible for it.\n\n\n\n\n\n\nExercise\n\n\n\nAsk Phind to explain the error message from the following code\n\nlenght(1:10)\n\nError in lenght(1:10): could not find function \"lenght\"\n\n\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "0023_objects_names.html#storing-data-in-objects",
    "href": "0023_objects_names.html#storing-data-in-objects",
    "title": "\n8  Objects and names\n",
    "section": "\n8.1 Storing data in objects",
    "text": "8.1 Storing data in objects\nR uses objects to store data in memory. Storing data in an object is referred to as “assigning data”. There are different types of data and objects; we will talk much more about them further below. For now, let’s see why one should assign data to objects, and how to do it.\n\n8.1.1 Why assigning data?\nPutting data into named objects allows you to:\n\nstore massive amounts of data and/or code for later reuse in calculations, analysis, plots and figures,\n\ndivide your code into separate steps, each of which is clearly identifiable by name and thus reusable,\n\nsimplify your code by referring to previous calculations or plots.\n\nLet’s take a look at the following figure. It is made of 3 plots, each of them based on different variables taken from a single data set:\n\n\n\n\n\nBelieve it or not, but the code that builds this figure is as simple as this:\n\nplot1 / (plot2 + plot3)\n\nIn fact, everything that R needed in order to make the figure had been previously stored in the objects plot1, plot2 and plot3.\nThe clear benefit of assigning data into the above-mentioned objects is that it simplified a lot the code for the figure.\n\n8.1.2 Assigning data to an object\nTo assign data to an object, type first the name you want to give it followed by the operator &lt;- and the data to store. In the following example, we will assign the result of the operation sqrt(42) in memory to the object named result:\n\nresult &lt;- sqrt(42)\n\nAt once, the object result and its associated value show up in the Environment tab of RStudio.\n\n\n\n\n\nFrom now on, you can display the content of result simply by typing its name:\n\nresult\n\n[1] 6.480741\n\n\nYou can also reuse the object for other operations:\n\nresult * 3\n\n[1] 19.44222\n\nresult * result\n\n[1] 42\n\n\n\n8.1.3 Modifying object content\nTo modify the content of an object, you simply have to assign new data to it. Here we modify the object result:\n\nresult &lt;- exp(42)\n\nThe content of result is automatically modify, as shown in the Environment tab.\n\n\n\n\n\nNote that the previous content of result is lost as soon as the new data is assigned. To restore the original value, you will have to go back to your script and rerun the original command that assigned the square root of 42 to result. This is one of the many reasons why you should always work with a script and annotate it: it is your life-line in case you make a mistake, lose objects, modify data elements, etc.\n\n8.1.4 Naming objects\n\n“What’s in a name? That which we call a xx3\nBy any other name would smell as sweet;”\n– not quite Romeo and Juliet\n\n\nThere are only two hard things in Computer Science:\ncache invalidation and naming things.\n– Phil Karlton\n\nNaming an object sounds quite easy if you are creative, but there is a set of rules to respect:\n\nnames must start with a letter (lower or upper case) or a dot ., nothing else!\nnames may include letters (lower and/or upper case), numbers, underscores _ and dots .\n\nyou cannot use reserved names, i.e. names of existing functions or words already used in R (TRUE, FALSE, break, function, if, for, NA, function, see the complete list by running ?Reserved in the console)\n\nBeside these rules, you may find the following recommendations useful:\n\nbe consistent and use a word convention when writing names, such as snake_case where words are written in lowercase and separated using an underscore symbol _\n\ngive your object a meaningful name such as norwegian_seabirds, alpine_species_vestland, etc\navoid names which meaning may change with time, such as new_dataset, modified_dataset, last_year_data, etc\navoid very long names\nremember R is case-sensitive\nhave a look at the tidyverse style guide\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWe have prepared a learnr-tutorial that further describes the rules for naming objects, and gives you a chance to test how well you have understood. This tutorial is in the biostats.tutorials package.\nThe tutorial is called Naming objects. Simply click on the button Start Tutorial &gt; to the right to start it.\nSee Section 5.6.4 for how to install biostats.tutorials and run the tutorials.\n\n\n\n8.1.5 Viewing object content\nAs introduced in Section 2.3.5.1, the Environment tab of RStudio lists all the objects stored in memory in a given project. This list comes with a quick summary of both the structure and the content of the objects.\nThe function View() applied to any object opens a new tab which displays the whole object in the form of a table. Figure 8.1 shows a screenshot of the tab that appears after running View() on a large object called tb.\n\nView(tb)\n\n\n\n\n\nFigure 8.1: The function View() opens a tab with the content of the object.\n\n\n\nView() is particularly useful when you want to quickly check entries directly in the data set as it spares you from finding and opening the original data file on your disk via the explorer.\n\n\n\n\n\n\nExercise\n\n\n\nView() the penguins dataset from palmerpenguins. Compare with what you get by printing the penguins dataset. Which do you find most useful?\n\n\n\n8.1.6 Deleting objects\nWhen you are done with a particularly large object that takes a lot of memory, it may be useful to get rid of it. This is done by using the function rm(). Here, we will delete result from the current environment.\n\nrm(result)\n\nTo delete several objects at the same time, use rm() and type their name separated with commas ,.\n\nresult &lt;- exp(42)\nresult2 &lt;- result ^ 2\n\n\nrm(result, result2)\n\nAgain, once it is done, there is only one way back: go to your script and rerun the commands that originally created result and result2.\nTo delete everything, you can use the broom icon in the Environment tab, but it is usually better to restart the R session.\n\n\nSession\n\n\nRestart R"
  },
  {
    "objectID": "0023_objects_names.html#built-in-data-sets",
    "href": "0023_objects_names.html#built-in-data-sets",
    "title": "\n8  Objects and names\n",
    "section": "\n8.2 Built-in data sets",
    "text": "8.2 Built-in data sets\nThere are many datasets and other objects built into R or R packages. If the package is loaded, they can be used by typing their name.\n\npi\n\n[1] 3.141593\n\nmonth.abb # abbreviated month names\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\n\nTo make objects in packages available you can either load the package with library() first, or use data().\n\npenguins # not available yet\n\nError in eval(expr, envir, enclos): object 'penguins' not found\n\ndata(penguins, package = \"palmerpenguins\")\npenguins # available now\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe penguins dataset contains morphological data on three species of penguin. You will meet this dataset repeatedly as it provides a convenient set of variables and observations well-suited for illustrating many purposes."
  },
  {
    "objectID": "0023_objects_names.html#contributors",
    "href": "0023_objects_names.html#contributors",
    "title": "\n8  Objects and names\n",
    "section": "Contributors",
    "text": "Contributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "002_V_is_for_vector.html#the-vector",
    "href": "002_V_is_for_vector.html#the-vector",
    "title": "9  V is for vector",
    "section": "\n9.1 The Vector",
    "text": "9.1 The Vector\nA vector is an object that contains one or several values of the same data type. For example, the object vec.char described below is a vector that contains 3 data elements of the type character.\n\nvec.char &lt;- c(\"one\", \"two\", \"three\")\nvec.char\n\n[1] \"one\"   \"two\"   \"three\"\n\n\nWhen conducting a statistical analysis, a vector is possibly the simplest object in which you may store entries for a single variable. In the following example, 24 data points corresponding to the temperature for a specific location registered over a period of 24 hours have been stored in the vector temperature:\n\ntemperature &lt;- c(8.7, 9.2, 9.4, 9.5, 9.7, 10.1, 10.3, 10.6, 10.7, 10.8, 11.3, 11.9, 12.2, 12.3, 11.7, 10.2, 10.3, 10.3, 10.4, 10.3, 10.1, 9.7, 9.5, 9.4)\n\n\ntemperature\n\n [1]  8.7  9.2  9.4  9.5  9.7 10.1 10.3 10.6 10.7 10.8 11.3 11.9 12.2 12.3 11.7\n[16] 10.2 10.3 10.3 10.4 10.3 10.1  9.7  9.5  9.4\n\n\nNote that the data type of the whole vector is determined by the type of the elements it contains, as shown here:\n\nclass(temperature)\n\n[1] \"numeric\"\n\n\n\n9.1.1 Combining with c\nPerhaps the simplest way to make a vector is with the function c() which combines the elements given between parentheses.\nThe data elements to concatenate must be separated with a comma ,.\n\nresults &lt;- c(42, sqrt(42), 42 ^ 2)\nresults\n\n[1]   42.000000    6.480741 1764.000000\n\n\nThis may be applied not only to numerical values, but also to characters. When storing characters, you must use quotation marks \" \" around the elements.\n\none_two_three &lt;- c(\"one\", \"two\", \"three\")\none_two_three\n\n[1] \"one\"   \"two\"   \"three\"\n\n\nNote that you may combine data elements of various natures. Here we combine and store both numbers and characters, but everything becomes a character:\n\none_2_three_4 &lt;- c(\"one\", 2, \"three\", 4)\none_2_three_4\n\n[1] \"one\"   \"2\"     \"three\" \"4\"    \n\n\n\n9.1.2 Coercion\nIf one tries to store data elements of different types in a single vector, all the elements in this vector will be coerced into the type that is the most general.\nThe ranking from the most specific to the most general is as follows: logical &lt; integer &lt; numeric &lt; character.\nLet’s take the following example where we store a numeric, a character and an integer together:\n\ncoercion &lt;- c(15, \"fifteen\", 15L)\nclass(coercion)\n\n[1] \"character\"\n\n\nAs you see here the type of coercion is character, in other words the type of the most general data element.\n\n9.1.3 Accessing data elements\nIt is possible to extract specific data elements from a vector based on their position. To do so, we use square brackets [ ]. Indicate first the vector name and then the element position(s) between the brackets:\n\ntemperature[c(2, 6)] \n\n[1]  9.2 10.1\n\n\nUse negative indices to remove an element.\n\n\n\n\n\n\nExercise\n\n\n\nFrom the vector month.name\n\nselect the eighth element\nselect the third and ninth elements\ndrop the second and fifth elements"
  },
  {
    "objectID": "002_V_is_for_vector.html#data-types-for-vectors",
    "href": "002_V_is_for_vector.html#data-types-for-vectors",
    "title": "9  V is for vector",
    "section": "\n9.2 Data types for vectors",
    "text": "9.2 Data types for vectors\nHere we will first review the primitive data types, then see a few useful data classes.\n\n9.2.1 Primitive data types\nR lets you manipulate 6 primitive data types: numeric, integer, character, logical (also called Boolean), complex and raw. Only the first four types are relevant to the scope of this website.\nIn the following sections, we will use the function class() to identify the nature of the data stored in objects (mode() and typeof() give related information).\n\n9.2.1.1 numeric\nAny number with a decimal value, whether positive or negative, is of type numeric. The object num created below contains a single decimal value and is thus also numeric.\n\nnum &lt;- -35.2\nclass(num)\n\n[1] \"numeric\"\n\n\n\n9.2.1.2 integer\nIntegers are positive or negative numbers that do not contain a decimal value. The object int below contains a single integer and is thus of type integer.\n\nint &lt;- 35L\nclass(int)\n\n[1] \"integer\"\n\n\nNote that int was assigned the number 35L. The “L” that follows the number forces the object to store it as an integer. If we write 35 instead of 35L, the object is just numeric as shown below.\n\nnot_int &lt;- 35\nclass(not_int)\n\n[1] \"numeric\"\n\n\n\n9.2.1.3 character\nAn object containing a string of letters combined (or not) with numbers, or even a single letter, is of type character. The letters may be upper and/or lower case. The object char below contains a single word and is thus defined as character.\n\nchar &lt;- \"Letters\"\nclass(char)\n\n[1] \"character\"\n\n\nNote that the strings of characters must be stored in objects using \" \".\n\n9.2.1.4 logical\nLogical (or boolean) defines binary objects which contain TRUE or FALSE. This is the case of the object logic below.\n\nlogic &lt;- TRUE\nclass(logic)\n\n[1] \"logical\"\n\n\nNote that TRUE and FALSE are sometimes replaced with “T” or “F”. This is bad coding practice, which may result in weird errors that may compromise your work and the validity of its output.\n\n9.2.2 Modifying data types\nIt is possible to modify the type of an existing object with a series of simple functions like as.numeric(), as.integer(), as.character(), etc.\nLet’s consider the object integ created below.\n\ninteg &lt;- 35L\ninteg\n\n[1] 35\n\n\ninteg contains a single data element (35L) which is defined as an integer:\n\nclass(integ)\n\n[1] \"integer\"\n\n\ninteg may be transformed into a simple numerical value by using the function as.numeric():\n\ninteg_num &lt;- as.numeric(integ)\nclass(integ_num)\n\n[1] \"numeric\"\n\n\nAnd it is possible to reverse this action with as.integer():\n\ninteg_int &lt;- as.integer(integ_num)\nclass(integ_int)\n\n[1] \"integer\"\n\n\nIt is also possible to transform it into a string of characters with as.character():\n\ninteg_char &lt;- as.character(integ)\nclass(integ_char)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nMake a vector that contains a word, a number and a logical value\n\nwhat class is it\ncoerce it to a numeric vector. What happens. Why?\n\n\n\n\n9.2.3 Advanced data classes\nR allows to transform the format of an object from something simple like a number or a string of characters to something more advanced like a date or a factor. Date and factor are not data types per se, but data classes.\n\n9.2.3.1 Dates\nThe data element 1980-02-08 stored in the object birthdate below is nothing more than a string of characters.\n\nbirthday &lt;- \"1980-02-08\"\nbirthday\n\n[1] \"1980-02-08\"\n\nclass(birthday)\n\n[1] \"character\"\n\n\nTo make it a date object, one must use the function as.Date():\n\nbirthdate &lt;- as.Date(birthday)\nbirthdate\n\n[1] \"1980-02-08\"\n\nclass(birthdate)\n\n[1] \"Date\"\n\n\nEven though this does not seem to affect the way the data element is displayed, such a conversion is determining with regard to how th element is going to be handled in calculations. The calculation below displays the date that occurs 10 days before birthdate:\n\nten_days_before_my_birthdate &lt;- birthdate - 10\nten_days_before_my_birthdate\n\n[1] \"1980-01-29\"\n\n\nSuch a calculation would not have been possible without the conversion from character to date, as demonstrated by this error message:\n\nten_days_before_my_birthday &lt;- birthday - 10\n\nError in birthday - 10: non-numeric argument to binary operator\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThere is a tutorial for handling dates with the lubridate package in biostats.tutorials.\n\n\n\n9.2.3.2 Factors\nA factor is an object that only contains predefined values. These predefined values are called the levels of the factor. Factors are especially useful in the context of statistical analysis where categorical data are involved (like ANOVA, etc), and for forcing the order of categories on a plot. Categories often appear as “text labels”, and may thus look like simple strings of characters.\nIn the following example, the object scandinavian_countries is a factor that contains 7 elements and three levels: Norway, Sweden and Denmark.\n\nscandinavian_countries \n\n[1] Norway  Denmark Sweden  Denmark Sweden  Norway  Denmark\nLevels: Norway Denmark Sweden\n\nclass(scandinavian_countries)\n\n[1] \"factor\"\n\n\nOne way to build such a factor consists in converting a character object such as scandinavia with the function factor(). However, one must not forget to set the levels correctly with the argument levels =.\n\nscandinavia &lt;- c(\"Norway\", \"Denmark\", \"Sweden\", \"Denmark\", \"Sweden\", \"Norway\", \"Denmark\")\nscandinavian_kingdoms &lt;- factor(scandinavia, levels = c(\"Norway\", \"Denmark\", \"Sweden\"))\nscandinavian_kingdoms\n\n[1] Norway  Denmark Sweden  Denmark Sweden  Norway  Denmark\nLevels: Norway Denmark Sweden"
  },
  {
    "objectID": "002_V_is_for_vector.html#creating-sequences-and-series",
    "href": "002_V_is_for_vector.html#creating-sequences-and-series",
    "title": "9  V is for vector",
    "section": "\n9.3 Creating sequences and series",
    "text": "9.3 Creating sequences and series\nThroughout this website, we will use examples that include random series of numbers, sequences of characters or numbers, etc. These sequences and series are often created by a bunch of functions or expressions, some of which are described below.\n\n9.3.1 Repetitions\nThe function rep() comes handy when you wish to repeat data elements n times in a row, or to repeat a sequence of elements n times. Using various arguments, you can decide how many times and/or in which manner the elements or sequences have to be repeated.\nThe simplest form of usage of rep() is rep(x, times = n) where x is what you want to repeat (string, number(s), etc) and n the number of iterations.\n\nrep(c(1, 2, 3), times = 3)\n\n[1] 1 2 3 1 2 3 1 2 3\n\nrep(c(\"One\", \"Two\", \"Three\"), times = 3)\n\n[1] \"One\"   \"Two\"   \"Three\" \"One\"   \"Two\"   \"Three\" \"One\"   \"Two\"   \"Three\"\n\n\nThe argument each = n allows for repeating n times each element at a time.\n\nrep(c(1, 2, 3), each = 3)\n\n[1] 1 1 1 2 2 2 3 3 3\n\nrep(c(\"One\", \"Two\", \"Three\"), each = 3)\n\n[1] \"One\"   \"One\"   \"One\"   \"Two\"   \"Two\"   \"Two\"   \"Three\" \"Three\" \"Three\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWrite code that will\n\nrepeat the letters A – C three times so the output is A B C A…\nrepeat the letters A – C three times so the output is A A A B…\n\n\n\n\n9.3.2 Sequences\nThe following section provides you with expressions or functions that build sequences of numerical or text values.\n\n9.3.2.1 Using the colon operator\nThe colon separator : used in the expression a:b creates a series of consecutive numbers ranging from a to b with an increment of 1.\n\n14:24\n\n [1] 14 15 16 17 18 19 20 21 22 23 24\n\n\nNote that b is not necessarily the last element of the series.\n\n14:24.5\n\n [1] 14 15 16 17 18 19 20 21 22 23 24\n\n14.5:24\n\n [1] 14.5 15.5 16.5 17.5 18.5 19.5 20.5 21.5 22.5 23.5\n\n\n\n9.3.2.2 The function seq()\nSimilar to a:b, seq(a, b) creates a series of consecutive numbers ranging from a to b with an increment of 1.\n\nseq(14, 24)\n\n [1] 14 15 16 17 18 19 20 21 22 23 24\n\n\nAgain, b is not necessarily the last element of the series.\n\nseq(14, 24.5)\n\n [1] 14 15 16 17 18 19 20 21 22 23 24\n\nseq(14.5, 24)\n\n [1] 14.5 15.5 16.5 17.5 18.5 19.5 20.5 21.5 22.5 23.5\n\n\nYou can use a set of additional arguments in seq() to adjust the output. Adding by = allows to tune the incrementation to any value you want (including decimal values). length.out = adjusts the incrementation to provide the desired number of elements ranging precisely from a to b.\n\nseq(14, 24, by = 2.5)\n\n[1] 14.0 16.5 19.0 21.5 24.0\n\nseq(14, 24, length.out = 7)\n\n[1] 14.00000 15.66667 17.33333 19.00000 20.66667 22.33333 24.00000\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nMake a sequence of integers between -5 and 10\nMake a sequence of between 0 and 10 that increment by 1.7\nMake a sequence between 4 and 34 that is 10 elements long\n\n\n\n\n9.3.3 Random series\nThe following section provides you with functions that build series of random, numerical values. It demonstrates functions to make sequences from uniform and normal distributions, but there are many more distributions available in R.\n\n\n\n\nDifferent distributions of 1000 random numbers, with default options\n\n\n\n\n9.3.3.1 The function runif()\nrunif(n) returns a series of n random numbers from a uniform distribution between 0 and 1.\n\nrunif(n = 7)\n\n[1] 0.77754622 0.09860594 0.48448292 0.70357260 0.04673104 0.13528951 0.39894030\n\n\nrunif(n, min = a, max = b) returns a series of n random numbers in the range from a to b:\n\nrunif(n = 7, min = 10, max = 100)\n\n[1] 73.45378 48.30441 80.75696 93.66836 27.05938 45.53991 40.23410\n\n\n\n9.3.3.2 The function rnorm()\nrnorm(n) creates a series of n numbers taken from a normal distribution.\n\nrnorm(n = 10)\n\n [1] -0.9080117 -0.7332665 -0.4944632  0.9108703  0.1242632 -0.1930169\n [7] -0.7077276  1.1407162 -0.9652213  2.3968283\n\n\nBy default, the normally distributed population is set up with a mean of 0 and a standard deviation of 1, but this may be adjusted with mean = and sd =.\n\nrnorm(n = 10, mean = 50, sd = 3)\n\n [1] 48.00924 51.61782 49.75104 49.19227 45.62999 50.24278 47.50642 47.36313\n [9] 50.50498 50.13968\n\n\n\n9.3.3.3 The function sample()\nsample(x, size, replace = TRUE/FALSE) returns a sample of n values randomly taken in the object x (which may be a vector, a series such as 1:100, etc). replace = followed by either TRUE or FALSE defines whether or not a data element can appear repeatedly in the sample.\n\nsample(x = 1:100, size = 10, replace = FALSE)\n\n [1] 62 47  6 48 63 33  8 64 66 86\n\nsample(x = 20:30, size = 7, replace = TRUE)\n\n[1] 24 30 23 30 20 30 22\n\n\nAn interesting property of the function sample() is that it can be used to shuffle the result of an expression or the content of a vector, something which is useful for randomization of data elements. In the following example, sample() shuffles and returns all the values in 1:10:\n\nsample(1:10)\n\n [1]  6  7  3  9  4  2 10  1  5  8\n\n\n\n9.3.3.4 set.seed()\n\nThe sequence of “random” numbers that R generates are not strictly random but pseudo-random. The sequence repeats with a very long period (219937 - 1 for the default Mersenne-Twister algorithm). If you want to get exactly the same sequence again (for reproducibility), you can set the seed for the random numbers with set.seed().\n\nset.seed(300)\nrnorm(n = 5)\n\n[1]  1.37379088  0.86210687  0.47348910  0.70126281 -0.08505527\n\nset.seed(300)\nrnorm(n = 5)\n\n[1]  1.37379088  0.86210687  0.47348910  0.70126281 -0.08505527\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nGenerate 10 random numbers from a uniform distribution between 10 and 20\nGenerate 10 random numbers from a normal distribution with a mean of 4 and a standard deviation of 2\nsample 10 values from the sequence 1:10 with replacement\n\n\n\n\n\n\n\n\n\nFurther Reading\n\n\n\n\nR for data science\nThe tidyverse\n\nAdvanced R chapters 1 – 4\n\n\n\n\n\n\n\n\n\nWhat’s next\n\n\n\nNow that you know the basics of R and that you have all the tools to “manually” create R objects, you will learn how to import a data set from an external source. We will see how to read and fetch data from various file types such as .txt, .csv, .xls, .xlsx, and directly store it in tibbles.\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "0025_data_structures.html#matrices",
    "href": "0025_data_structures.html#matrices",
    "title": "10  Data structures beyond the vector",
    "section": "\n10.1 Matrices",
    "text": "10.1 Matrices\nA matrix is a two-dimensional object that displays data of the same type (numeric, character, etc) in the form of a table. It is built up with the function matrix() in which the data is imported either in the form of concatenated data elements (ex: c(12, 54, 987, 5, ...)), a series or sequence of data elements (ex: 1:25), or a vector (ex: temperature). In addition, one must define the number of rows and columns with nrow = and ncol =.\nIn the following example, the object neo is a matrix made of 4 rows and 6 columns filled with the numeric values stored in the vector temperature that we have previously created.\n\ntemperature &lt;- c(8.7, 9.2, 9.4, 9.5, 9.7, 10.1, 10.3, 10.6, 10.7, 10.8, 11.3, 11.9, 12.2, 12.3, 11.7, 10.2, 10.3, 10.3, 10.4, 10.3, 10.1, 9.7, 9.5, 9.4)\nneo &lt;- matrix(temperature, nrow = 4, ncol = 6)\nneo \n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]  8.7  9.7 10.7 12.2 10.3 10.1\n[2,]  9.2 10.1 10.8 12.3 10.3  9.7\n[3,]  9.4 10.3 11.3 11.7 10.4  9.5\n[4,]  9.5 10.6 11.9 10.2 10.3  9.4\n\n\n\n10.1.1 Accessing data elements\nIn a matrix, each row is numbered [x, ] and each column is numbered [ , y]. Any of the data elements may be retrieved by using its coordinates [x, y] preceded by the name of the matrix:\n\nneo[2, 3]\n\n[1] 10.8\n\n\nA full row or column may be retrieved with the same expression, but we leave empty the coordinate that is not needed:\n\nneo[2, ]\n\n[1]  9.2 10.1 10.8 12.3 10.3  9.7\n\nneo[ , 3]\n\n[1] 10.7 10.8 11.3 11.9\n\n\n\n10.1.2 About the use of matrices\nThe use of matrices on this website is very limited. However, you may meet matrices in other projects, so it is best to know about their existence. You can read more about matrices here.\n\n\n\n\n\n\nExercise\n\n\n\nMake the matix neo as above, then\n\nselect the first two columns\nthe third column. What happened?\nthe second row.\nThe element in the third column second row."
  },
  {
    "objectID": "0025_data_structures.html#arrays",
    "href": "0025_data_structures.html#arrays",
    "title": "10  Data structures beyond the vector",
    "section": "\n10.2 Arrays",
    "text": "10.2 Arrays\nMatrices are two dimensional objects; arrays generalise this to have any number of dimensions. Arrays are an efficient way to store and manipulate high dimensional data (e.g,. latitude * longitude * time), but can be difficult to understand and don’t play well with the tidyververse.\n\narray(data = 1:24, dim = c(2, 4, 3))\n\n, , 1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\n, , 2\n\n     [,1] [,2] [,3] [,4]\n[1,]    9   11   13   15\n[2,]   10   12   14   16\n\n, , 3\n\n     [,1] [,2] [,3] [,4]\n[1,]   17   19   21   23\n[2,]   18   20   22   24"
  },
  {
    "objectID": "0025_data_structures.html#lists",
    "href": "0025_data_structures.html#lists",
    "title": "10  Data structures beyond the vector",
    "section": "\n10.3 Lists",
    "text": "10.3 Lists\nA list is an object that contains values of one or several data types. It can not only contain single data elements, but also other objects such as vectors, matrices, etc.\nLists are created by the function list() that concatenates data elements and objects. list() conveniently allows for naming the elements by the mean of the symbol =.\nIn the example below, we will store 6 elements and name them string, number, temp, boolean, words and matrix. Among these elements to be stored are vec.char, temperature and neo, 3 objects that we have created further above on this page.\n\nmy_list &lt;- list(string = \"one\", \n                number = 2, \n                temp = temperature, \n                boolean = TRUE, \n                words = c(\"dog\", \"cat\", \"fish\"), \n                matrix = neo)\nmy_list \n\n$string\n[1] \"one\"\n\n$number\n[1] 2\n\n$temp\n [1]  8.7  9.2  9.4  9.5  9.7 10.1 10.3 10.6 10.7 10.8 11.3 11.9 12.2 12.3 11.7\n[16] 10.2 10.3 10.3 10.4 10.3 10.1  9.7  9.5  9.4\n\n$boolean\n[1] TRUE\n\n$words\n[1] \"dog\"  \"cat\"  \"fish\"\n\n$matrix\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]  8.7  9.7 10.7 12.2 10.3 10.1\n[2,]  9.2 10.1 10.8 12.3 10.3  9.7\n[3,]  9.4 10.3 11.3 11.7 10.4  9.5\n[4,]  9.5 10.6 11.9 10.2 10.3  9.4\n\n\n\n10.3.1 Retrieving list elements\nYou can access list items by position with [[ notation.\n\nmy_list[[1]] #get first element\n\n[1] \"one\"\n\n\nNaming elements is quite convenient as it allows you to retrieve them rapidly by the mean of the symbol $. The syntax is as follows: list_name$element_name.\nHere we retrieve the element matrix in the list my_list:\n\nmy_list$matrix\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]  8.7  9.7 10.7 12.2 10.3 10.1\n[2,]  9.2 10.1 10.8 12.3 10.3  9.7\n[3,]  9.4 10.3 11.3 11.7 10.4  9.5\n[4,]  9.5 10.6 11.9 10.2 10.3  9.4\n\n\n\n10.3.2 Retrieving single data elements\nEven better, you can retrieve a single data element contained in a list element. Here you will have to write an expression that makes use of both the symbol $ and the brackets [ ]in the proper order. The syntax is as follows: list_name$element_name[data].\nIn this first example, we retrieve the data element located at the third position of the object named words in the list my_list:\n\nmy_list$words[3]\n\n[1] \"fish\"\n\n\nIn the second example, we retrieve the data element located at the second row and third column of the matrix named matrix in the list my_list:\n\nmy_list$matrix[2, 3]\n\n[1] 10.8\n\n\nYou may read more information about lists here.\n\n\n\n\n\n\nExercise\n\n\n\nMake a list with three named elements of different types.\n\nuse square bracket notation to extract the second element\nuse $ notation to extract an element by name."
  },
  {
    "objectID": "0025_data_structures.html#data-frames-and-tibbles",
    "href": "0025_data_structures.html#data-frames-and-tibbles",
    "title": "10  Data structures beyond the vector",
    "section": "\n10.4 Data frames and tibbles",
    "text": "10.4 Data frames and tibbles\nA data frame is a two-dimensional object that stores data of various types in the form of a table. Data frames are a popular way to store research data since the columns are usually associated with single variables (and are thus of a specific data type such as numeric or character) and rows are associated with observations.\nUntil recently, data frames were the main storage objects for research data. Nowadays, tibbles (an evolution of the data frame that appeared in the tidyverse) are replacing data frames as they are more practical for handling data sets (you will understand why further below). Because of this trend, we will focus mainly on tibbles here in this section and further on this website. It is however likely that you will meet data frames in the course of your studies. Do not worry as we will see how to transform data frames into tibbles.\nTibbles are standard introduced in tidyverse, so you must make sure that the package is active before using these objects. Simply run this command first:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIf you have not installed the package yet, have a look at the Section 5.6.2.\n\n10.4.1 Data frames vs. tibbles\nThe object df printed below is a data frame that stores the average temperature recorded monthly in 2017, 2018 and 2019 at Lygra (Vestland, Norway). It is created with the function data.frame().\n\ndf &lt;- data.frame(Year = rep(2017:2019, each = 12), \n                 Month = rep(month.name, 3), \n                 Avg_temperature = c(3.4, 2.8, 4.2, 5.8, 11.4, 12.6, 14.6, 13.9, 13.7, 9.2, 4.3, 3.1, 2.3, 0.5, 0.8, 6.7, 13.5, 13.6, 16.2, 13.8, 11.6, 8.0, 6.6, 3.9, 1.7, 4.6, 4.0, 9.1, 8.8, 13.2, 15.4, 15.8, 11.6, 7.8, 3.6, 4.8))\ndf\n\n   Year     Month Avg_temperature\n1  2017   January             3.4\n2  2017  February             2.8\n3  2017     March             4.2\n4  2017     April             5.8\n5  2017       May            11.4\n6  2017      June            12.6\n7  2017      July            14.6\n8  2017    August            13.9\n9  2017 September            13.7\n10 2017   October             9.2\n11 2017  November             4.3\n12 2017  December             3.1\n13 2018   January             2.3\n14 2018  February             0.5\n15 2018     March             0.8\n16 2018     April             6.7\n17 2018       May            13.5\n18 2018      June            13.6\n19 2018      July            16.2\n20 2018    August            13.8\n21 2018 September            11.6\n22 2018   October             8.0\n23 2018  November             6.6\n24 2018  December             3.9\n25 2019   January             1.7\n26 2019  February             4.6\n27 2019     March             4.0\n28 2019     April             9.1\n29 2019       May             8.8\n30 2019      June            13.2\n31 2019      July            15.4\n32 2019    August            15.8\n33 2019 September            11.6\n34 2019   October             7.8\n35 2019  November             3.6\n36 2019  December             4.8\n\n\nAs you may see, you get at once the whole data set with all 36 rows, the 3 variables, the header with column names and the first column that gives a number to each row.\nThe object tbl below is a tibble that contains exactly the same observations and variables as df. It is built up by the function tibble().\n\ntbl &lt;- tibble(Year = rep(2017:2019, each = 12), \n             Month = rep(month.name, 3), \n             Avg_temperature = c(3.4, 2.8, 4.2, 5.8, 11.4, 12.6, 14.6, 13.9, 13.7, 9.2, 4.3, 3.1, 2.3, 0.5, 0.8, 6.7, 13.5, 13.6, 16.2, 13.8, 11.6, 8.0, 6.6, 3.9, 1.7, 4.6, 4.0, 9.1, 8.8, 13.2, 15.4, 15.8, 11.6, 7.8, 3.6, 4.8))\ntbl\n\n# A tibble: 36 × 3\n    Year Month     Avg_temperature\n   &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1  2017 January               3.4\n 2  2017 February              2.8\n 3  2017 March                 4.2\n 4  2017 April                 5.8\n 5  2017 May                  11.4\n 6  2017 June                 12.6\n 7  2017 July                 14.6\n 8  2017 August               13.9\n 9  2017 September            13.7\n10  2017 October               9.2\n# ℹ 26 more rows\n\n\nHere, you get a more convenient display of the same data:\n\nonly the first 10 rows and the header are displayed,\nthe number of rows not printed is displayed in the present window (# ... with 26 more rows),\nthe dimensions of the tibble appear clearly in the header (# A tibble: 36 x 3),\nthe column names come along with a quick description of the data type (&lt;int&gt; for integer, &lt;chr&gt; for character, &lt;dbl&gt; for double, etc).\n\nAll in all, tibbles print much better and give more information than data frames do! They also have more predictable behaviour when extracting data from them.\n\n10.4.2 Retrieving data elements\nSimilarly to vectors, matrices and lists, one can extract single elements from data frames and tibbles. Here, we use brackets [ ] to do so:\n\ndf[3, \"Avg_temperature\"]\n\n[1] 4.2\n\ntbl[3, \"Avg_temperature\"]\n\n# A tibble: 1 × 1\n  Avg_temperature\n            &lt;dbl&gt;\n1             4.2\n\n\nOne can also retrieve rows or columns:\n\ndf[3, ]\n\n  Year Month Avg_temperature\n3 2017 March             4.2\n\ntbl[3, ]\n\n# A tibble: 1 × 3\n   Year Month Avg_temperature\n  &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n1  2017 March             4.2\n\ndf[ , \"Avg_temperature\"]\n\n [1]  3.4  2.8  4.2  5.8 11.4 12.6 14.6 13.9 13.7  9.2  4.3  3.1  2.3  0.5  0.8\n[16]  6.7 13.5 13.6 16.2 13.8 11.6  8.0  6.6  3.9  1.7  4.6  4.0  9.1  8.8 13.2\n[31] 15.4 15.8 11.6  7.8  3.6  4.8\n\ntbl[ , \"Avg_temperature\"]\n\n# A tibble: 36 × 1\n   Avg_temperature\n             &lt;dbl&gt;\n 1             3.4\n 2             2.8\n 3             4.2\n 4             5.8\n 5            11.4\n 6            12.6\n 7            14.6\n 8            13.9\n 9            13.7\n10             9.2\n# ℹ 26 more rows\n\n\nIt is also possible to use the symbol $ to retrieve the content of specific variables:\n\ndf$Avg_temperature\n\n [1]  3.4  2.8  4.2  5.8 11.4 12.6 14.6 13.9 13.7  9.2  4.3  3.1  2.3  0.5  0.8\n[16]  6.7 13.5 13.6 16.2 13.8 11.6  8.0  6.6  3.9  1.7  4.6  4.0  9.1  8.8 13.2\n[31] 15.4 15.8 11.6  7.8  3.6  4.8\n\ntbl$Avg_temperature\n\n [1]  3.4  2.8  4.2  5.8 11.4 12.6 14.6 13.9 13.7  9.2  4.3  3.1  2.3  0.5  0.8\n[16]  6.7 13.5 13.6 16.2 13.8 11.6  8.0  6.6  3.9  1.7  4.6  4.0  9.1  8.8 13.2\n[31] 15.4 15.8 11.6  7.8  3.6  4.8\n\n\nIn Chapter 14 you will see an alternative way of manipulating tibbles with the dplyr package.\n\n10.4.3 Transforming a data frame into a tibble\nIf you have been previously working with data frames, have been given a data frame to work with, or have imported data using functions that create data frames, you may convert them into tibbles by using as_tibble(). Here we convert the data frame df into a tibble:\n\ndf_as_tibble &lt;- as_tibble(df)\ndf_as_tibble \n\n# A tibble: 36 × 3\n    Year Month     Avg_temperature\n   &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1  2017 January               3.4\n 2  2017 February              2.8\n 3  2017 March                 4.2\n 4  2017 April                 5.8\n 5  2017 May                  11.4\n 6  2017 June                 12.6\n 7  2017 July                 14.6\n 8  2017 August               13.9\n 9  2017 September            13.7\n10  2017 October               9.2\n# ℹ 26 more rows\n\n\nYou may read more about tibbles here.\nYou may read more about data frames here.\n\n\n\n\n\n\nExercise\n\n\n\nMake a tibble with the first column the months of the year, and the second is a sequence of numbers from 1 to 12.\n\nextract the month column using $ notation\n\n\n\n\n\n\n\n\n\nFurther Reading\n\n\n\n\nR for data science\nThe tidyverse\n\nAdvanced R chapters 1 – 4\n\n\n\n\n\n\n\n\n\nWhat’s next\n\n\n\nNow that you know the basics of R and that you have all the tools to “manually” create R objects, you will learn how to import a data set from an external source. We will see how to read and fetch data from various file types such as .txt, .csv, .xls, .xlsx, and directly store it in tibbles.\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "005_Importing_Data_in_R.html#what-are-tabular-data",
    "href": "005_Importing_Data_in_R.html#what-are-tabular-data",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.1 What are tabular data?",
    "text": "11.1 What are tabular data?\nTabular data are data that is organized in the form of a table with rows and columns. A table often has a header, i.e. an additional row that displays variable names. Here is an example of a formatted table with header:\n\n\n\n\nTable 11.1: A simple table with header row\n\nmonth\ntemperature (Celsius)\nprecipitation (mm)\nWind (m/s)\n\n\n\nJanuary\n-3.4\n29.4\n1.3\n\n\nFebruary\n-0.4\n15.4\n0.9\n\n\nMarch\n-1.7\n57.6\n1.7\n\n\napril\n3.8\n3.2\n0.8\n\n\nMay\n5.1\n25.2\n1.4\n\n\nJune\n10.6\n52.4\n1.1\n\n\nJuly\n13.1\n65.0\n1.0\n\n\nAugust\n12.8\n67.4\n0.7\n\n\nSeptember\n6.9\n79.0\n1.2\n\n\nOctober\n2.5\n18.2\n0.8\n\n\nNovember\n-2.2\n7.8\n0.8\n\n\nDecember\n1.5\n92.0\n1.5\n\n\n\n\n\n\nIn this example, the table consists of 4 variables (columns) and 12 observations (rows) in addition to the header (top row). All cell contents are clearly delimited.\nBelow is an example of a non-tabular dataset. This dataset is a list of profiles with recurrent fields (Name, Position, Institution). Each profile contains three lines with a field:value pair.\n\n\nName: Aud Halbritter\nPosition: Researcher\nInstitution: UiB\n-----------------------------\nName: Jonathan Soule\nPosition: Senior Engineer\nInstitution: UiB\n-----------------------------\nName: Richard J. Telford\nPosition: Associate Professor\nInstitution: UiB\n-----------------------------"
  },
  {
    "objectID": "005_Importing_Data_in_R.html#about-tidy-data",
    "href": "005_Importing_Data_in_R.html#about-tidy-data",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.2 About tidy data",
    "text": "11.2 About tidy data\nTidy data is a standard, consistent way to organize tabular data. Briefly, tidy data follows a short series of rules:\n\neach variable in the data set is presented in a specific column,\neach observation in the data set is presented in a specific row,\neach cell at the intersection of a row and a column contains a single value.\n\nThe following figure illustrates these rules.\n\n\n\n\nIn a tidy dataset, variables are in columns, observations are in rows, and values are in cells. — Source: R for Data Science\n\n\n\nThe dataset presented in Table 11.1 respects all three rules, and is thus a tidy dataset.\nOn the contrary, the following dataset is not tidy:\n\n\n\n\n\n\nDate\n      17.06.2016\n      21.06.2016\n      23.06.2016\n      26.06.2016\n      27.06.2016\n      28.06.2016\n      29.06.2016\n      30.06.2016\n      02.07.2016\n      04.07.2016\n      05.07.2016\n      06.07.2016\n      08.07.2016\n      10.07.2016\n      11.07.2016\n      13.07.2016\n      15.07.2016\n      17.07.2016\n      19.07.2016\n      21.07.2016\n      23.07.2016\n      24.07.2016\n      26.07.2016\n      28.07.2016\n      30.07.2016\n      02.08.2016\n      04.08.2016\n      06.08.2016\n      11.08.2016\n    \n\n\nTime\n10:00\n11:00\n11:00\n13:00\n13:00\n09:33\n13:00\n15:00\n09:00\n09:15\n09:30\n09:15\n09:15\n09:15\n09:15\n09:30\n10:00\n13:00\n17:30\n10\n10:00\n09:30\n09:30\n09:30\n09:15\n09:30\n15:00\n11:00\n15:00\n\n\nWeather\nSunny_PartlyCloudy\nCloudy_Fog\nCloudy_Sunny\nCloudy_Rainy_Windy_Fog\nCloudy_Windy_Rainy\nWindy_Rainy_MostlyCloudy\nWindy_Sunny_Cloudy\nWindy_Cloudy\nWindy_Cloudy\nCloudy_Sunny\nCloudy_Sunny\nCloudy_Fog_Rainy\nSunny_PartlyCloudy\nCloudy_Rainy\nCloudy\nCloudy_Sunny\nCloudy\nCloudy_Rainy\nCloudy_Rainy\nCloudy_Sunny\nSunny_Cloudy\nCloudy_Sunny\nCloudy_Rainy\nCloudy_Rainy\nCloudy_Rainy\nCloudy_Rainy\nCloudy_Rainy\nCloudy_Rainyn\nCloudy_Snowy_Sunny\n\n\nObserver\nLV_AH\nLV\nLV\nLV\nLV_SB\nLV_SB\nLV_SB\nLV\nLV_SB\nSB_LV\nSB_LV\nLV_SB\nLV_SB\nLV_SB\nLV\nLV\nLV_SB_AH\nSB_LV\nSB_LV\nSB_LV\nSB_LV\nLV\nLV\nLV\nLV\nLV\nLV\nLV\nLV\n\n\nE01a\n0\nNA\n0\n0\n0\n0\n1\n1\n2\n2\n3\n3\n6\n8\n8\n11\n13\n10\n9\n7\n3\n6\n3\n3\n1\n1\n1\n2\n1\n\n\nE01b\n0\nNA\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n3\n3\n3\n8\n19\n23\n26\n24\n16\n16\n8\n5\n2\n3\n4\n3\n2\n\n\nE01c\n0\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n5\n9\n12\n10\n7\n4\n3\n3\n3\n2\n2\n0\n1\n1\n\n\nE01d\n0\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n2\n4\n3\n2\n4\n1\n1\n1\n2\n2\n1\n1\n1\n0\n\n\nE01e\n0\nNA\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n4\n4\n4\n5\n4\n3\n1\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\nIndeed, at least one of the rules is broken since columns display data matching several variables (Date, time, Weather, etc).\nImporting data from a file containing tidy data is a great way to start your work, but it is not a prerequisite to data import. As long as your data is tabular, you will be able to import it in R, and tidy it later (see Chapter 13)."
  },
  {
    "objectID": "005_Importing_Data_in_R.html#file-formats",
    "href": "005_Importing_Data_in_R.html#file-formats",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.3 File formats",
    "text": "11.3 File formats\nTabular data may be stored in files using various formats, spreadsheets, etc. The most common spreadsheets store data in their own, proprietary file format, e.g. MS Excel which produces .xls and .xlsx files. Such formats may be a limitation to data management in R. Simpler formats such as plain text files with .txt or .csv should always be preferred when saving or exporting data from spreadsheets."
  },
  {
    "objectID": "005_Importing_Data_in_R.html#delimited-files",
    "href": "005_Importing_Data_in_R.html#delimited-files",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.4 Delimited files",
    "text": "11.4 Delimited files\nOne of the most common format for storing tabular data is plain text files with a delimiter between the columns. The delimiter is often a comma or a semi-colon, but other delimiters are possible including tabs.\nComma or semi-colon delimited files are known as CSV files, which stands for Comma-Separated Values, and often have a .csv extension. They may also have a .txt extension.\nIn a CSV-formatted file, the data is stored in a similar manner to this:\n\n\n\n\nFigure 11.1: Contents of a CSV file viewed in the text editor Notepad\n\n\n\nFor information, this file matches the example in Table 11.1. Each line corresponds to a row in the table (including header) and cell contents are separated with a comma ,. Note that the period symbol . is used as decimal separator.\nThe use of commas in the CSV format is however not universal. Other symbols such as a semi-colon ; may be used as a delimiter. This is the case in several European countries where commas are decimal separator. Here is the same data set as above, this time in the European format:\n\n\n\n\nContents of another CSV file"
  },
  {
    "objectID": "005_Importing_Data_in_R.html#know-your-data",
    "href": "005_Importing_Data_in_R.html#know-your-data",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.5 Know your data!",
    "text": "11.5 Know your data!\nThere are several reasons why different symbols are used in CSV files. Among these reasons are:\n\nlocale, i.e. the parameters that define the language and regional settings (currency, time and date, number format setting) in use on your machine,\nsoftware-based preferences, the settings which are defined by default by the software that you have used to punch your data,\nuser-based preferences, the settings that you choose when punching or saving data.\n\nIt is thus very important to know what your CSV file is made of. We therefore recommend to systematically inspect your data file before importing in R. One way to do it is to open the text file in a text editor (for example RStudio), or to read some of the file into R with read_lines('file.txt') (the n_max argument is useful if there is lots of data) and determine:\n\nwhich symbol is used as decimal separator (, or .)\nwhich symbol is used as delimiter (, or ;)\nany extra lines of data that need removing\n\nHere is our previous example:\n\nread_lines('data/weather.csv')\n\n [1] \"month,temperature (Celsius),precipitation (mm),Wind (m/s)\"\n [2] \"January,-3.4,29.4,1.3\"                                    \n [3] \"February,-0.4,15.4,0.9\"                                   \n [4] \"March,-1.7,57.6,1.7\"                                      \n [5] \"april,3.8,3.2,0.8\"                                        \n [6] \"May,5.1,25.2,1.4\"                                         \n [7] \"June,10.6,52.4,1.1\"                                       \n [8] \"July,13.1,65.0,1.0\"                                       \n [9] \"August,12.8,67.4,0.7\"                                     \n[10] \"September,6.9,79.0,1.2\"                                   \n[11] \"October,2.5,18.2,0.8\"                                     \n[12] \"November,-2.2,7.8,0.8\"                                    \n[13] \"December,1.5,92.0,1.5\"                                    \n\n\nIn this file, the decimal separator is . and the delimiter is ,."
  },
  {
    "objectID": "005_Importing_Data_in_R.html#importing-delimited-files",
    "href": "005_Importing_Data_in_R.html#importing-delimited-files",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.6 Importing delimited files",
    "text": "11.6 Importing delimited files\nWe can import delimited files such as csv files with readr::read_delim(). read_delim() will import the data as a tibble.\nIn the following example, we import the file weather.csv located in the subfolder data of the current RStudio project into the object weather.\n\nlibrary(tidyverse)\nweather &lt;- read_delim(file = \"data/weather.csv\")\n\nRows: 12 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): month\ndbl (3): temperature (Celsius), precipitation (mm), Wind (m/s)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen the function is executed, the console shows a short series of messages. In the frame above, the message Column specification tells you that the content of the column month has been recognized as of data type character, and that the three other columns have been recognized as double (which is similar to numeric).\nNow the tibble weather is available in R as you may see in the tab Environment (see Figure 11.2).\n\n\n\n\nFigure 11.2: The tibble weather is now stored in R.\n\n\n\nYou can display the table as follows:\n\nweather\n\n# A tibble: 12 × 4\n   month     `temperature (Celsius)` `precipitation (mm)` `Wind (m/s)`\n   &lt;chr&gt;                       &lt;dbl&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n 1 January                      -3.4                 29.4          1.3\n 2 February                     -0.4                 15.4          0.9\n 3 March                        -1.7                 57.6          1.7\n 4 april                         3.8                  3.2          0.8\n 5 May                           5.1                 25.2          1.4\n 6 June                         10.6                 52.4          1.1\n 7 July                         13.1                 65            1  \n 8 August                       12.8                 67.4          0.7\n 9 September                     6.9                 79            1.2\n10 October                       2.5                 18.2          0.8\n11 November                     -2.2                  7.8          0.8\n12 December                      1.5                 92            1.5\n\n\n\n\n\n\n\n\nRemember to assign!\n\n\n\nIf you don’t assign (&lt;-) the imported data to a name, the tibble will be printed to the screen and then lost.\n\n\n\n11.6.1 File paths\nThe first argument to read_delim() is file. This wants the location of the file on your computer. Before we can import a file, we have to find it!\nYou might be tempted to write the absolute path to the file, something like:\n\"c:/user/bad13/documents/project/my_file.csv\"\nThis would be a bad idea. Why? Because this path only works on your current computer (provided you don’t move the file). This code won’t work for anyone else, so you cannot share the code with your supervisor and have them run it, nor archive it with a manuscript. The code is not reproducible.\nMuch better is to a path relative to your RStudio project (remember to use an RStudio project - for more info about them, read Chapter 3). If the contents of your RStudio project looked like this\n\n\n.\n├── R\n│   ├── 01_import.R\n│   └── 02_analyse.R\n├── data\n│   ├── 2022-3-24_lake-tilo-chemistry.csv\n│   ├── 2022-3-24_lake-tilo-diatoms.csv\n│   └── 2022-8-15_lake-tilo-diatoms.csv\n├── my_project.Rproj\n├── output\n│   └── manuscript.pdf\n└── quarto\n    ├── manuscript.qmd\n    └── references.bib\n\n\nNow we could use\n\"data/2022-3-24_lake-tilo-chemistry.csv\"\nto access the chemistry data. If we move the RStudio project to a different location on your computer, or another computer, the code will still work. You don’t even need to type the full name: just type the quote marks and a few characters and autocomplete will start making suggestions.\nThere is still a problem though. When we use a quarto document, the working directory is the directory where the quarto document is stored. This can cause some confusion, which we can avoid if we use the here package to find the RStudio project root.\nOur import code would now look like this\n\nlibrary(\"here\")\nweather &lt;- read_delim(file = here(\"data/weather.csv\"))\n\nUsing here is highly recommended.\n\n\n\n\n\n\nForward slashes and backslashes\n\n\n\nRemember to use forward slashes / to separate directories in the path. If you use back slashes \\, you will get an error as these are used to escape the following character (e.g., \\t is a tab). If you really want back slashes, use two of them \\\\ as the first will escape the second. If you let autocomplete fill in your path, it will do it correctly\n\n\n\n11.6.2 Delimiters\nThe second argument to read_delim() is the column delimiter delim.\nIt used to be very important to specify the delimiter (or choose a function such as read_csv() that had it set by default), but, after a recent update, read_delim() will guess what the delimiter is and we only need to specify it if it gets it wrong.\n\n\n\n\n\n\nExercise\n\n\n\nImport the “weather.csv” data into R and assign it to an name.\n\n\n\n11.6.3 Review the imported data\nOnce you have imported the data, it is important to inspect it to check that everything has worked as expected.\n\ndoes it have the correct number of columns (may indicate problems with the delimiter)\nare the columns the expected type\nare the values correct.\n\nTo do this, we can print the object or View() it. We can also get details of the column specification\n\nspec(weather)\n\ncols(\n  month = col_character(),\n  `temperature (Celsius)` = col_double(),\n  `precipitation (mm)` = col_double(),\n  `Wind (m/s)` = col_double()\n)\n\n\nAny parsing problems (for example if there text in a column that should be numeric) will be shown with problems()\n\nproblems(weather)\n\n# A tibble: 0 × 5\n# ℹ 5 variables: row &lt;int&gt;, col &lt;int&gt;, expected &lt;chr&gt;, actual &lt;chr&gt;, file &lt;chr&gt;\n\n\nHere, there are no parsing problems so we get a tibble with zero rows.\nLet’s try another example. File weather2.csv has semi-colons as delimiters.\n\nweather2 &lt;- read_delim(file = \"data/weather2.csv\")\n\nRows: 12 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): month, Wind (m/s)\nnum (2): temperature (Celsius), precipitation (mm)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nspec(weather)\n\ncols(\n  month = col_character(),\n  `temperature (Celsius)` = col_double(),\n  `precipitation (mm)` = col_double(),\n  `Wind (m/s)` = col_double()\n)\n\n\nHere, the message Column specification tells you that the content of the columns month and Wind (m/s) has been recognized as of data type character, and that the two other columns have been recognized as number. While read_delim() got things right about the number of variables, something went wrong with the variables as we could expect Wind (m/s) to be recognized as double. To find out about this issue we need to review the imported data in the object weather2 and compare it to the original file weather2.csv.\nThe example above shows the importance of carefully verifying that the imported data in R matches the original data set. The following figure compares the content of the file weather2.csv (Figure 11.3 left) to the content of the object weather2 (Figure 11.3 right):\n\n\n\n\nFigure 11.3: The data in the object does not match the data in the file.\n\n\n\nLooking at the rows in both pictures, one can understand that all commas have simply been ignored, excepted those in the last column. To solve that issue, you must impose the separator using locale = locale(decimal_mark = \",\"):\n\nweather3 &lt;- read_delim(file = \"data/weather2.csv\", \n                       locale = locale(decimal_mark = \",\"))\n\nRows: 12 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): month\ndbl (3): temperature (Celsius), precipitation (mm), Wind (m/s)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe last column is now recognized as double and the data in the object weather3 matches the data in the file:\n\n\n\n\nThe data in the object now matches the data in the file.\n\n\n\n\n\n\n\n\n\nDecimal seperators\n\n\n\nWhile readr can guess the column delimiter, it cannot guess the decimal separator. The English/American standard is to use “.” as the separator. In Norway it is common to use a comma as the decimal separator (but “.” are also common). If you don’t specify the decimal separator, readr assumes that the comma is a thousand separator and ignores it. Then the values can be 10x higher than expected.\n\n\n\n11.6.4 read_csv2()\nA shortcut for files with a “;” as the column delimiter and commas as the decimal separator is read_csv2().\n\nweather_csv2 &lt;- read_csv2(file = \"data/weather2.csv\")\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 12 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): month\ndbl (3): temperature (Celsius), precipitation (mm), Wind (m/s)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote the message above Column specification that indicates which symbols read_csv2() has considered when importing the data. The resulting tibble looks correct:\n\nweather_csv2\n\n# A tibble: 12 × 4\n   month     `temperature (Celsius)` `precipitation (mm)` `Wind (m/s)`\n   &lt;chr&gt;                       &lt;dbl&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n 1 January                      -3.4                 29.4          1.3\n 2 February                     -0.4                 15.4          0.9\n 3 March                        -1.7                 57.6          1.7\n 4 april                         3.8                  3.2          0.8\n 5 May                           5.1                 25.2          1.4\n 6 June                         10.6                 52.4          1.1\n 7 July                         13.1                 65            1  \n 8 August                       12.8                 67.4          0.7\n 9 September                     6.9                 79            1.2\n10 October                       2.5                 18.2          0.8\n11 November                     -2.2                  7.8          0.8\n12 December                      1.5                 92            1.5\n\n\n\n\n\n\n\n\nExercise\n\n\n\nImport the file weather2.csv. Make sure it has imported correctly.\n\n\n\n11.6.5 Useful arguments\nread_delim() and the other functions discussed above have a multitude of arguments that allow for adjusting the way data is read and displayed. Here we review a handful of them.\n\n11.6.5.1 n_max\nn_max sets a limit to the number of observations to be read. Note that n_max does not consider the first row (header) of the data file as an observation.\n\nweather &lt;- read_delim(file = \"data/weather.csv\", \n                      n_max = 6)\n\n\nweather\n\n# A tibble: 6 × 4\n  month    `temperature (Celsius)` `precipitation (mm)` `Wind (m/s)`\n  &lt;chr&gt;                      &lt;dbl&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 January                     -3.4                 29.4          1.3\n2 February                    -0.4                 15.4          0.9\n3 March                       -1.7                 57.6          1.7\n4 april                        3.8                  3.2          0.8\n5 May                          5.1                 25.2          1.4\n6 June                        10.6                 52.4          1.1\n\n\n\n11.6.5.2 skip\nThe argument skip may be used to skip rows when reading the data file.\nBe aware that:\n\nthe header in the original data file counts as one row,\nthe first row that comes after those which have been skipped becomes the header for the resulting tibble.\n\nIn the following example, we read the data file weather.csv and skip the first row:\n\nweather &lt;- read_delim(file = \"data/weather.csv\", \n                      skip = 1)\n\n\nweather\n\n# A tibble: 11 × 4\n   January   `-3.4` `29.4` `1.3`\n   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 February    -0.4   15.4   0.9\n 2 March       -1.7   57.6   1.7\n 3 april        3.8    3.2   0.8\n 4 May          5.1   25.2   1.4\n 5 June        10.6   52.4   1.1\n 6 July        13.1   65     1  \n 7 August      12.8   67.4   0.7\n 8 September    6.9   79     1.2\n 9 October      2.5   18.2   0.8\n10 November    -2.2    7.8   0.8\n11 December     1.5   92     1.5\n\n\nAs expected, the first row (with the header) is skipped, and the data from the observation January have become the header of the tibble. The argument col_names() introduced below will be useful for solving this issue.\n\n11.6.5.3 col_names\nThe argument col_names may be used to define the name of the variables/columns of the tibble.\ncol_names = may also be followed by the actual variable names that you want to use. In that case, write col_names = c() and list the names between the parentheses. Be aware that the first row of the original data file, which would have been the column names, will become the first row of the resulting tibble. This means that if you want to replace existing names, you should also use the skip argument.\nHere is an example:\n\nweather &lt;- read_delim(file = \"data/weather.csv\", \n                      skip = 1,\n                      col_names = c(\"Month\", \"Temp\", \"Precip\", \"Wind\"))\nweather\n\n# A tibble: 12 × 4\n   Month      Temp Precip  Wind\n   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 January    -3.4   29.4   1.3\n 2 February   -0.4   15.4   0.9\n 3 March      -1.7   57.6   1.7\n 4 april       3.8    3.2   0.8\n 5 May         5.1   25.2   1.4\n 6 June       10.6   52.4   1.1\n 7 July       13.1   65     1  \n 8 August     12.8   67.4   0.7\n 9 September   6.9   79     1.2\n10 October     2.5   18.2   0.8\n11 November   -2.2    7.8   0.8\n12 December    1.5   92     1.5\n\n\nIf lots of column names are badly formatted, it may be easier to use janitor::clean_names() to improve them.\n\nweather &lt;- read_delim(file = \"data/weather.csv\") |&gt; \n  janitor::clean_names()\nweather\n\n# A tibble: 12 × 4\n   month     temperature_celsius precipitation_mm wind_m_s\n   &lt;chr&gt;                   &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n 1 January                  -3.4             29.4      1.3\n 2 February                 -0.4             15.4      0.9\n 3 March                    -1.7             57.6      1.7\n 4 april                     3.8              3.2      0.8\n 5 May                       5.1             25.2      1.4\n 6 June                     10.6             52.4      1.1\n 7 July                     13.1             65        1  \n 8 August                   12.8             67.4      0.7\n 9 September                 6.9             79        1.2\n10 October                   2.5             18.2      0.8\n11 November                 -2.2              7.8      0.8\n12 December                  1.5             92        1.5\n\n\n\n11.6.5.4 col_types\nThe argument col_types may be used to modify the data type of the variables. This is useful for example when you need to set a variable as factor whereas R has defined it as character. Here is an example with three simple variables.\n\ncounts &lt;- read_delim(file = \"data/groups.csv\")\n\nRows: 9 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): group\ndbl (2): ID, count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAs the message clearly indicates, the first and last variables are recognized as double (i.e. numeric) while the second one is recognized as character. The tibble in the object counts displays as follows:\n\ncounts\n\n# A tibble: 9 × 3\n     ID group count\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 A         5\n2     2 A         3\n3     3 A         2\n4     4 B         4\n5     5 B         5\n6     6 B         8\n7     7 C         1\n8     8 C         2\n9     9 C         9\n\n\nLet’s use col_types = cols() to manually set the data types to double, factor and integer, respectively.\n\ncounts &lt;- read_delim(file = \"data/groups.csv\",\n                     col_types = cols(col_double(), col_factor(), col_integer()))\n\nNow the tibble displays like this, with the correct data types for each column:\n\ncounts\n\n# A tibble: 9 × 3\n     ID group count\n  &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;\n1     1 A         5\n2     2 A         3\n3     3 A         2\n4     4 B         4\n5     5 B         5\n6     6 B         8\n7     7 C         1\n8     8 C         2\n9     9 C         9\n\n\nIf you only need to modify one or a few variables, you must name it/them when writing the code:\n\ncounts &lt;- read_delim(file = \"data/groups.csv\",\n                     col_types = cols(group = col_factor()))\n\nThe tibble displays like this:\n\ncounts\n\n# A tibble: 9 × 3\n     ID group count\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n1     1 A         5\n2     2 A         3\n3     3 A         2\n4     4 B         4\n5     5 B         5\n6     6 B         8\n7     7 C         1\n8     8 C         2\n9     9 C         9\n\n\nNote that col_types is particularly useful when importing tabular data that includes formatted dates. Dates are usually recognized as character when their format does not match the expected format set as default (locale, etc). In the following example, dates entered as yyyy-mm-dd in the last column are recognized as of type date:\n\ncountsdates &lt;- read_delim(file = \"data/groups-dates1.csv\")\n\nRows: 9 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): group\ndbl  (2): ID, count\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nHowever, in the example below, dates entered as dd-mm-yyyy are converted to character:\n\ncountsdates &lt;- read_delim(file = \"data/groups-dates2.csv\")\n\nRows: 9 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): group, date\ndbl (2): ID, count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTo solve this issue, add the function col_date() in cols() to help R understand how dates are formatted and shall be read.\n\ncountsdates &lt;- read_delim(file = \"data/groups-dates2.csv\", \n                     col_types = cols(date = col_date(\"%d-%m-%Y\")))\n\nThe result is the following tibble now correctly formatted:\n\ncountsdates \n\n# A tibble: 9 × 4\n     ID group count date      \n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;date&gt;    \n1     1 A         5 2021-03-01\n2     2 A         3 2021-03-02\n3     3 A         2 2021-03-03\n4     4 B         4 2021-03-01\n5     5 B         5 2021-03-02\n6     6 B         8 2021-03-03\n7     7 C         1 2021-03-01\n8     8 C         2 2021-03-02\n9     9 C         9 2021-03-03\n\n\nYou will find the whole list of cols() parameters for col_types here.\n\n\n\n\n\n\nExercise\n\n\n\nImport the data from “biomass2015_H.csv”. These data are plant biomass data from an alpine grassland near Mt Gonga, China.\n\n\n\n\n\n\n\n\nVery large files\n\n\n\nreadr imports objects into the computers memory. This is fine for most datasets. But very large datasets (gigabytes) - will not fit into memory and another solution is needed. Here we can use apache arrow with the arrow package. This can work with dplyr functions to process large datasets efficiently.\n\n\n\n11.6.6 White space delimited files\nSome files have white space separating the columns. If a single tab is used then read_delim() will automatically detect it and work correctly. Sometimes multiple spaces are used so the columns line up, making the text file easy for humans to read. read_delim() will not work with these files as it expects a single delimiter. Instead we can use read_table(), shown here with some test data.\n\nread_table(\" Species   Value\n            Navicula       1\n            Cymbella       2\")\n\n# A tibble: 2 × 2\n  Species  Value\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Navicula     1\n2 Cymbella     2\n\n\nAnother type of data you will sometimes see is the fixed width format. There are no delimiters, but each field has the same position in each row. These files can be imported with read_fwf(). Determining the position of each column can be painful unless you have good metadata.\n\n\n\n\n\n\nExercise\n\n\n\nImport part “3a. Clegg et al. 2011 Hudson Lake Midge Temperature Data” from “alaska2011midge-t.txt”\n\nHint\nskip and n_max argument can be useful."
  },
  {
    "objectID": "005_Importing_Data_in_R.html#excel-files",
    "href": "005_Importing_Data_in_R.html#excel-files",
    "title": "\n11  Importing data in R\n",
    "section": "\n11.7 Excel files",
    "text": "11.7 Excel files\nEven though we don’t recommend you use Excel files for your own data, you need to know how to import such data as you may be given Excel files for find them in a data repository. To make your analysis reproducible, it is important to keep the files in their original format rather than converting them to CSV so that all the processing is done with code.\nExcel files can be imported with the readxl package which is installed with tidyverse but not loaded until you run library(readxl). The function read_excel() will import the data; it can be worth using excel_sheets() first to check the names of the sheets.\n\nlibrary(readxl)\nexcel_sheets(path = \"data/biomass2015.xls\")\nbiomass_l &lt;- read_excel(path = \"data/biomass2015.xls\", sheet = \"Site L\")\n\nMany of the arguments for skipping rows at the start of the file, enforcing column types, etc, are similar to those in readr::read_delim()\n\n\n\n\n\n\nExercise\n\n\n\nImport the biomass data from Site A from biomass2015.xls\n\n\n\n\n\n\n\n\nFurther Reading\n\n\n\nYou may find the following links useful:\n\nR for Data Science - Data import\nData Import Cheatsheet - readr/readxl\nreadr\n\n\n\n\n\n\n\nContributors\n\nJonathan Soulé\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "010-pipes.html#a-recipe-for-mashed-potato",
    "href": "010-pipes.html#a-recipe-for-mashed-potato",
    "title": "12  Pipes",
    "section": "\n12.1 A recipe for mashed potato",
    "text": "12.1 A recipe for mashed potato\nHere is a recipe for mashed potato using pipes.\n\nbuy(\"potatoes\", kg = \"1\") |&gt; \n  peel() |&gt; \n  boil(minutes = \"15\") |&gt; \n  drain() |&gt; \n  mash(add = list(\"salt\", \"milk\", \"butter\")) |&gt; \n  serve(decorate = \"parsley\")\n\nThis recipe for mashed potato can be read as buy 1kg potatoes, and then peel them, and then boil them, and so on."
  },
  {
    "objectID": "010-pipes.html#the-native-r-pipe",
    "href": "010-pipes.html#the-native-r-pipe",
    "title": "12  Pipes",
    "section": "\n12.2 The native R pipe |>\n",
    "text": "12.2 The native R pipe |&gt;\n\nThe pipe passes result of code on left of pipe to the function on right, and puts it in the first available argument.\nSo\n\nf &lt;- \"file.csv\"\nread_csv(file = f)\n\nand be rewritten as\n\nf |&gt;\n read_csv()\n\nIf you want to put the object passed through the pipe into the second argument, you need to name the first, so that it is not available. So if we want to pipe penguins into lm to fit a linear model, we need penguins to be put into the data argument, which is the second argument of lm. We can force this by naming the formula argument, so that data is the first available argument.\n\n# un-named argument = fails\npenguins |&gt;\n  lm(bill_length ~ species)\n\n# named first argument, penguins pipes into second argument\npenguins |&gt;\n  lm(formula = bill_length ~ species)\n\nOr we can use the placeholder _\n\n# named first argument, penguins pipes into second argument\npenguins |&gt;\n  lm(bill_length ~ species, data = _) # R 4.2 and newer only\n\nMore complex arrangements, for example using the piped object multiple times, can be done by writing a function, or using the pipebind package. You probably won’t have to do this very often.\n\n# Using a anonymous function\nrnorm(10) |&gt;\n  (function(x){x - mean(x)})() # Result from rnorm is passed to the anonymous function as x \n\n [1] -1.97555714 -0.48218398  0.02953355  1.11727215  0.64242338 -0.66064742\n [7]  1.20709071  0.10471908  2.11306503 -2.09571536\n\n# Using the \\ shortcut for function\nrnorm(10) |&gt;\n  (\\(x){x - mean(x)})()\n\n [1]  0.78215898 -0.07098804 -0.06318266  1.20092523  1.34671048 -2.98568019\n [7]  0.81707960 -1.01027789  0.75633615 -0.77308166\n\n# using pipebind\nlibrary(pipebind)\nrnorm(10) |&gt;\n  bind(x, x - mean(x))\n\n [1] -0.8370634  0.3015608 -0.2920104  1.2031490  0.3592847 -1.1807594\n [7] -0.3339675 -0.1887989  1.9754446 -1.0068395\n\n\n\n\n\n\n\n\nThe magrittr pipe %&gt;%\n\n\n\nThe |&gt; pipe was introduced in R version 4.1. Previously, the magrittr package pipe %&gt;% was widely used, especially with tidyverse functions. You will see the %&gt;% in a lot of code on stackoverflow and other help sites. In most cases the old and new pipes work in exactly the same way. Advantages of the |&gt; pipe are that it is\n\nslightly faster\ndoesn’t need any packages loading\neasier to debug"
  },
  {
    "objectID": "010-pipes.html#making-a-pipe",
    "href": "010-pipes.html#making-a-pipe",
    "title": "12  Pipes",
    "section": "\n12.3 Making a pipe",
    "text": "12.3 Making a pipe\nYou can make a pipe either by typing it directly, or by using the RStudio keyboard short-cut . You may need to set the RStudio options. Go to Tools &gt; Global Options &gt; Code and tick Use native pipe operator, |&gt;. To make your code readable, put a line break after each pipe.\n\n\n\n\n\n\nExercise\n\n\n\nRe-write the following code to use pipes, then check then result is the same.\n\nadelie &lt;- filter(penguins, species == \"Adelie\")\nadelie_grouped &lt;- group_by(adelie, sex)\nadelie_summary &lt;- summarise(adelie_grouped, mean_body_mass = mean(body_mass_g))\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "011-tidyr-pivot.html#tidy-data",
    "href": "011-tidyr-pivot.html#tidy-data",
    "title": "13  Tidying data with tidyr",
    "section": "\n13.1 Tidy data",
    "text": "13.1 Tidy data\nBefore you can start analysing or plotting data, you often need to tidy it. Tidy data is a standardised way to structure a dataset which makes it much easier to process, analyse and plot the data. Functions in the tidyr and dplyr packages, both part of tidyverse, can be very useful for tidying data.\n\nlibrary(tidyr)\n\nIn tidy data\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nThe process of tidying data is to convert the data you have to data that meets this standard."
  },
  {
    "objectID": "011-tidyr-pivot.html#separate-multiple-values",
    "href": "011-tidyr-pivot.html#separate-multiple-values",
    "title": "13  Tidying data with tidyr",
    "section": "\n13.2 separate() multiple values",
    "text": "13.2 separate() multiple values\nIf a cell contains multiple values, we can use tidyr::separate_wider_delim() to separate the values into different columns.\nFor example, in this small dataset, site code and plot number have been combined into one column separated by a hyphen.\n\ndat &lt;- tribble(~id, ~value,\n       \"A-1\", 1,\n       \"A-2\", 2,\n       \"B-1\", 3)\n\ndat\n\n# A tibble: 3 × 2\n  id    value\n  &lt;chr&gt; &lt;dbl&gt;\n1 A-1       1\n2 A-2       2\n3 B-1       3\n\n\nWe can use separate_wider_delim() to split site and plot into separate columns. The delimited is set by the delim argument.\n\ndat |&gt; \n  separate_wider_delim(cols = id, delim = \"-\", names = c(\"site\", \"plot\"))\n\n# A tibble: 3 × 3\n  site  plot  value\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     1         1\n2 A     2         2\n3 B     1         3\n\n\nRelated function, separate_wider_regex(), which uses regular expressions to split the column, can be more flexible."
  },
  {
    "objectID": "011-tidyr-pivot.html#reshaping-data---wide-to-long",
    "href": "011-tidyr-pivot.html#reshaping-data---wide-to-long",
    "title": "13  Tidying data with tidyr",
    "section": "\n13.3 Reshaping data - wide to long",
    "text": "13.3 Reshaping data - wide to long\nIt is very common to need to reshape data to make it tidy. This can be done with the pivot_* functions.\n\n\n\n\nWide data to long data with pivot_longer() and pivot_wider() .\n\n\n\nThese are some Bergen climate data from Wikipedia (NB for demonstration only wikipedia is not a good source of climate data - use seklima for Norwegian data).\n\n\nRows: 4 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): Måned\ndbl (12): Jan, Feb, Mar, Apr, Mai, Jun, Jul, Aug, Sep, Okt, Nov, Des\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 4 × 13\n  Måned    Jan   Feb   Mar   Apr   Mai   Jun   Jul   Aug   Sep   Okt   Nov   Des\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Norma…   3.6   4     5.9   9.1  14    16.8  17.6  17.4  14.2  11.2   6.9   4.7\n2 Døgnm…   1.7   1.7   3.3   5.8  10.4  13.1  14.2  14.2  11.5   8.8   4.8   2.7\n3 Norma…  -0.4  -0.5   0.9   3     7.2  10.2  11.5  11.6   9.1   6.6   2.8   0.6\n4 Nedbø… 190   152   170   114   106   132   148   190   283   271   259   235  \n\n\nThis might be a nice way to present the data but it is not tidy data: each row is not an observation; each column is not a variable.\nWe can use pivot_longer() to reshape the data. The months, selected by the cols argument in the column names (see Section 14.2.1 for more on the syntax used here) will become a new variable with a name set by the names_to, and the data values get put into a column named by the values_to argument.\n\nbergen_klima_long &lt;- bergen_klima |&gt; \n  pivot_longer(cols = Jan:Des, names_to = \"Month\", values_to = \"value\")\nbergen_klima_long\n\n# A tibble: 48 × 3\n  Måned                 Month value\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 Normal maks. temp. °C Jan     3.6\n2 Normal maks. temp. °C Feb     4  \n3 Normal maks. temp. °C Mar     5.9\n# ℹ 45 more rows\n\n\nThe data are now tidier, but it would probably be more useful to reshape the data again, and have a column for each climate variable. We can do this pivot_wider()."
  },
  {
    "objectID": "011-tidyr-pivot.html#reshaping-data---long-to-wide",
    "href": "011-tidyr-pivot.html#reshaping-data---long-to-wide",
    "title": "13  Tidying data with tidyr",
    "section": "\n13.4 Reshaping data - long to wide",
    "text": "13.4 Reshaping data - long to wide\nWe can tell pivot_wider() which column contains what will become the column names and the data with the names_from and values_from, respectively.\n\nbergen_klima_wider &lt;- bergen_klima_long |&gt; \n  pivot_wider(names_from = \"Måned\", values_from = \"value\")\n\nbergen_klima_wider\n\n# A tibble: 12 × 5\n   Month `Normal maks. temp. °C` `Døgnmiddeltemp. °C` `Normal min. temp. °C`\n   &lt;chr&gt;                   &lt;dbl&gt;                &lt;dbl&gt;                  &lt;dbl&gt;\n 1 Jan                       3.6                  1.7                   -0.4\n 2 Feb                       4                    1.7                   -0.5\n 3 Mar                       5.9                  3.3                    0.9\n 4 Apr                       9.1                  5.8                    3  \n 5 Mai                      14                   10.4                    7.2\n 6 Jun                      16.8                 13.1                   10.2\n 7 Jul                      17.6                 14.2                   11.5\n 8 Aug                      17.4                 14.2                   11.6\n 9 Sep                      14.2                 11.5                    9.1\n10 Okt                      11.2                  8.8                    6.6\n11 Nov                       6.9                  4.8                    2.8\n12 Des                       4.7                  2.7                    0.6\n# ℹ 1 more variable: `Nedbør (mm)` &lt;dbl&gt;\n\n\nThe data are now in a convenient format for plotting or analysis.\n\n\n\n\n\n\nExercise\n\n\n\nWith the Mt Gonga data downloaded previously, pivot the data so that the height data (H1-H10) are in one column.\n\nHint\npivot_longer\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\ntidy data vignette\ntidyr cheat sheet\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "012-dplyr-single-table.html#the-penguins-dataset",
    "href": "012-dplyr-single-table.html#the-penguins-dataset",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.1 The penguins dataset",
    "text": "14.1 The penguins dataset\nThis tutorial will use the penguins dataset from the palmerpenguins package. This dataset includes measurements of three species of penguin.\n\n# Load the data\ndata(\"penguins\", package = \"palmerpenguins\")\n# Show the data\npenguins\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "012-dplyr-single-table.html#selecting-columns-with-select",
    "href": "012-dplyr-single-table.html#selecting-columns-with-select",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.2 Selecting columns with select()\n",
    "text": "14.2 Selecting columns with select()\n\nYou can choose which columns of the data frame you want with select().\nThe first argument is the data, which is supplied by the pipe |&gt;, the next arguments are the names of the columns you want. The names do not need quote marks.\n\n#select species, bill_length_mm & bill_depth_mm\npenguins |&gt; \n  select(species, bill_length_mm, bill_depth_mm)\n\nselect: dropped 5 variables (island, flipper_length_mm, body_mass_g, sex, year)\n\n\n# A tibble: 344 × 3\n  species bill_length_mm bill_depth_mm\n  &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 Adelie            39.1          18.7\n2 Adelie            39.5          17.4\n3 Adelie            40.3          18  \n# ℹ 341 more rows\n\n\nThis is equivalent to the base R code\n\n#select species, bill_length_mm & bill_depth_mm\npenguins[, c(\"species\", \"bill_length_mm\", \"bill_depth_mm\")] \n\n# A tibble: 344 × 3\n  species bill_length_mm bill_depth_mm\n  &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 Adelie            39.1          18.7\n2 Adelie            39.5          17.4\n3 Adelie            40.3          18  \n# ℹ 341 more rows\n\n\nRemember that if you want to use the output of this code in a further analysis, you need to assign it to an object name with &lt;-.\n\n\n\n\n\n\nExercise\n\n\n\nFrom the penguins data, select\n\nspecies\n\nspecies and bill_length_mm\n\nall columns except year\n\n\nHint\n\npenguins |&gt; \n  select(___, ___)\n\n\n\n\n\n14.2.1 select() helpers\nSometimes we don’t want to write out the names of all the columns we want to select. We might not even know them all in advance. Fortunately there are some helper functions.\nIf you want to select() adjacent columns, you can use the notation first:last.\n\n#select species to bill_depth_mm\npenguins |&gt; select(species:bill_depth_mm)\n\nselect: dropped 4 variables (flipper_length_mm, body_mass_g, sex, year)\n\n\n# A tibble: 344 × 4\n  species island    bill_length_mm bill_depth_mm\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7\n2 Adelie  Torgersen           39.5          17.4\n3 Adelie  Torgersen           40.3          18  \n# ℹ 341 more rows\n\n\nSometimes it is easier to remove the columns you don’t want. You can do this by putting a - in front of the column name.\n\n#select everything but year and sex\npenguins |&gt; select(-year, -sex)\n\nselect: dropped 2 variables (sex, year)\n\n\n# A tibble: 344 × 6\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n\n\nIf there is a pattern to the column names that we want to select (or remove), there are some helper functions. For example, to select columns that start with “bill”, we can use starts_with().\n\n#select bill_length_mm & bill_depth_mm\" \npenguins |&gt; select(starts_with(\"bill\"))\n\nselect: dropped 6 variables (species, island, flipper_length_mm, body_mass_g, sex, …)\n\n\n# A tibble: 344 × 2\n  bill_length_mm bill_depth_mm\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           39.1          18.7\n2           39.5          17.4\n3           40.3          18  \n# ℹ 341 more rows\n\n\nConversely, if we want to select all columns that end with “mm”, we can use ends_with(). contains() is more flexible and matches() is the most powerful of the helper functions, using regular expressions to identify the columns (see the regular expression tutorial).\nSometimes, you might want to select all the columns of a certain type. For example, to select all the numeric columns we can use the is.numeric function inside select() with the helper where().\n\npenguins |&gt; select(where(is.numeric)) # No brackets on the function\n\nselect: dropped 3 variables (species, island, sex)\n\n\n# A tibble: 344 × 5\n  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\n           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;int&gt;\n1           39.1          18.7               181        3750  2007\n2           39.5          17.4               186        3800  2007\n3           40.3          18                 195        3250  2007\n# ℹ 341 more rows\n\n\nOther is.* functions exist, for example, is.character for text.\nYou can also select columns by number (1 being the first column), but this is generally a bad idea because it makes the code difficult to understand and if a new column is added, or the column order is changed, the code will break.\nWhich of these strategies works best is context dependent.\n\n\n\n\n\n\nExercise\n\n\n\nFrom the penguins data, select\n\nall columns except year\nall non-numeric columns\n\nspecies and columns ending in “mm”\n\n\nHint\n\n# hint 1\npenguins |&gt; \n  select(-___)\n\n# hint 2\n?where\n\n# hint 3\n?ends_with"
  },
  {
    "objectID": "012-dplyr-single-table.html#renaming-columns-with-rename",
    "href": "012-dplyr-single-table.html#renaming-columns-with-rename",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.3 Renaming columns with rename\n",
    "text": "14.3 Renaming columns with rename\n\nYou can use rename() to rename columns\n\npenguins |&gt; rename(Species = species)\n\nrename: renamed one variable (Species)\n\n\n# A tibble: 344 × 8\n  Species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe syntax is new_name = current_name.\nYou can also rename a column when selecting. This is convenient if you are using select() anyway.\n\npenguins |&gt; select(Species = species)\n\nselect: renamed one variable (Species) and dropped 7 variables\n\n\n# A tibble: 344 × 1\n  Species\n  &lt;fct&gt;  \n1 Adelie \n2 Adelie \n3 Adelie \n# ℹ 341 more rows"
  },
  {
    "objectID": "012-dplyr-single-table.html#moving-columns-with-relocate",
    "href": "012-dplyr-single-table.html#moving-columns-with-relocate",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.4 Moving columns with relocate()\n",
    "text": "14.4 Moving columns with relocate()\n\nSometimes it is useful to reorder the columns. This is never necessary for data analysis or plotting, but can be needed when making a table for presentation.\n\npenguins |&gt; relocate(island)\n\nrelocate: columns reordered (island, species, bill_length_mm, bill_depth_mm, flipper_length_mm, …)\n\n\n# A tibble: 344 × 8\n  island    species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Torgersen Adelie            39.1          18.7               181        3750\n2 Torgersen Adelie            39.5          17.4               186        3800\n3 Torgersen Adelie            40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe default is to move the named column first, the .before and .after arguments let you move the column into any position."
  },
  {
    "objectID": "012-dplyr-single-table.html#filtering-rows-with-filter",
    "href": "012-dplyr-single-table.html#filtering-rows-with-filter",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.5 Filtering rows with filter()\n",
    "text": "14.5 Filtering rows with filter()\n\nFiltering rows that meet some condition is a very common task.\nFor example, to filter rows of penguins that have a bill length greater than 40 mm, we can use\n\npenguins |&gt; filter(bill_length_mm &gt; 40)\n\nfilter: removed 102 rows (30%), 242 rows remaining\n\n\n# A tibble: 242 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           40.3          18                 195        3250\n2 Adelie  Torgersen           42            20.2               190        4250\n3 Adelie  Torgersen           41.1          17.6               182        3200\n# ℹ 239 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThis will filter out each row where the condition is TRUE.\nThe base R equivalent of this is\n\npenguins[penguins$bill_length_mm &gt; 40, ]\n\n# A tibble: 244 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           40.3          18                 195        3250\n2 &lt;NA&gt;    &lt;NA&gt;                NA            NA                  NA          NA\n3 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 241 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nGenerally, filter makes it easier to understand, especially with more complex criteria.\nOther tests include\n\n\n== exactly equals. Often a bad idea to use with numeric data\n\nnear safe function for testing equality of numeric data as it has a tolerance for rounding errors.\n\n\nsqrt(2) ^ 2 == 2 # should be true, but rounding errors \n\n[1] FALSE\n\nsqrt(2) ^ 2 - 2 # the difference\n\n[1] 4.440892e-16\n\nnear(sqrt(2) ^ 2, 2) # safe alternative\n\n[1] TRUE\n\n\n\n\n!= not equal to\n\n&lt; less than\n\n&lt;= less than or equal to\n\n&gt; greater than\n\n&gt;= greater than or equal to\n\nis.na() for filtering by missing values.\n\nbetween() for filtering values with a range\n\n%in% is used when you want to test if a value is in a vector\n\n\npenguins |&gt; \n  filter(species %in% c(\"Adelie\", \"Chinstrap\"))\n\nfilter: removed 124 rows (36%), 220 rows remaining\n\n\n# A tibble: 220 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 217 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n#equivalent to \npenguins |&gt; \n  filter(species == \"Adelie\" | species == \"Chinstrap\") # with many alternatives, this gets long\n\nfilter: removed 124 rows (36%), 220 rows remaining\n\n\n# A tibble: 220 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 217 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n14.5.1 Filtering on multiple criteria\nIf we want to filter on multiple criteria, we need to decide whether we want all criteria to be TRUE (AND in Boolean logic), or for one or more to be TRUE (OR in Boolean logic).\nIf we want all criteria to be TRUE, we can separate them by a comma (or by an & if you want to be explicit).\n\npenguins |&gt; \n  filter(bill_length_mm &gt; 40, bill_depth_mm &gt; 18)\n\nfilter: removed 263 rows (76%), 81 rows remaining\n\n\n# A tibble: 81 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           42            20.2               190        4250\n2 Adelie  Torgersen           42.5          20.7               197        4500\n3 Adelie  Torgersen           46            21.5               194        4200\n# ℹ 78 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nIf we want rows where any of the criteria is TRUE, we can separate them by a |.\n\npenguins |&gt; \n  filter(bill_length_mm &gt; 40 | bill_depth_mm &gt; 18)\n\nfilter: removed 53 rows (15%), 291 rows remaining\n\n\n# A tibble: 291 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           40.3          18                 195        3250\n3 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 288 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nWe can negate a criterion by putting ! in front of it. So to filter rows that do not have bills longer than 40 mm we can use\n\npenguins |&gt; filter(!bill_length_mm &gt; 40)\n\nfilter: removed 244 rows (71%), 100 rows remaining\n\n\n# A tibble: 100 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 97 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nOf course, in this example, we could also use &lt;= as the test.\n\n14.5.2 Common errors\nThe commonest error is to use a single = rather than ==. Only the latter is a test of equality. If you do this, the error message is quite helpful.\n\npenguins |&gt; filter(species = \"Chinstrap\")\n\nError in `.fun()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `species == \"Chinstrap\"`?\n\n\nAnother common error is to forget to quote any strings.\n\npenguins |&gt; filter(species == Chinstrap)\n\nError in `.fun()`:\nℹ In argument: `species == Chinstrap`.\nCaused by error:\n! object 'Chinstrap' not found\n\n\n\n\n\n\n\n\nExercise\n\n\n\nFrom the penguins data, filter\n\nGentoo penguins\nGentoo or Adelie penguins\npenguins with a mass greater than or equal to 5000g\npenguins with a bill length between 45 and 50 mm\nGentoo penguins not from from Dream Island\n\n\nHint\n\n#hint 1\npenguins |&gt; filter(___ = ___)\n\n#hint 2\n?`%in%`\n\n#hint 3\npenguins |&gt; filter(___ &gt;= ___)\n\n#hint 4\n?between\n\n#hint 5\n?`!`"
  },
  {
    "objectID": "012-dplyr-single-table.html#slicing-the-data-with-slice",
    "href": "012-dplyr-single-table.html#slicing-the-data-with-slice",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.6 Slicing the data with slice()\n",
    "text": "14.6 Slicing the data with slice()\n\nSometimes it is useful to extract rows by row number.\n\npenguins |&gt; slice(3:7)\n\nslice: removed 339 rows (99%), 5 rows remaining\n\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           40.3          18                 195        3250\n2 Adelie  Torgersen           NA            NA                  NA          NA\n3 Adelie  Torgersen           36.7          19.3               193        3450\n4 Adelie  Torgersen           39.3          20.6               190        3650\n5 Adelie  Torgersen           38.9          17.8               181        3625\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nYou can use negative numbers to remove rows. Be careful using slice() as if the data change, different rows may be returned."
  },
  {
    "objectID": "012-dplyr-single-table.html#distinct-rows-with-distinct",
    "href": "012-dplyr-single-table.html#distinct-rows-with-distinct",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.7 Distinct rows with distinct()\n",
    "text": "14.7 Distinct rows with distinct()\n\nIf there are duplicates in the data, we can remove these with distinct(). distinct() with no extra arguments will remove duplicate rows.\n\npenguins |&gt; distinct()\n\ndistinct: no rows removed\n\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nIf we are only interested in some of the columns, we can supply the names of these columns.\n\npenguins |&gt; distinct(island)\n\ndistinct: removed 341 rows (99%), 3 rows remaining\n\n\n# A tibble: 3 × 1\n  island   \n  &lt;fct&gt;    \n1 Torgersen\n2 Biscoe   \n3 Dream    \n\n\nOther columns will be removed unless the argument .keep_all = TRUE is used.\n\n\n\n\n\n\nExercise\n\n\n\nFrom the penguins data, find distinct values of\n\nspecies\nspecies, island and sex\n\n\nHint\n\npenguins |&gt; distinct(___, ___)"
  },
  {
    "objectID": "012-dplyr-single-table.html#random-rows",
    "href": "012-dplyr-single-table.html#random-rows",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.8 Random rows",
    "text": "14.8 Random rows\nSometimes you want to sample rows at random from a data.frame. This can be done with slice_sample(). This can either sample a constant n rows or constant fraction of the rows depending on whether the n or prop argument is used.\n\npenguins |&gt; slice_sample(n = 10)\n\nslice_sample: removed 334 rows (97%), 10 rows remaining\n\n\n# A tibble: 10 × 8\n   species   island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;     &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie    Dream              40.6          17.2               187        3475\n 2 Gentoo    Biscoe             49            16.1               216        5550\n 3 Chinstrap Dream              53.5          19.9               205        4500\n 4 Gentoo    Biscoe             45.5          14.5               212        4750\n 5 Adelie    Torgers…           36.7          19.3               193        3450\n 6 Adelie    Torgers…           42.5          20.7               197        4500\n 7 Adelie    Dream              36.5          18                 182        3150\n 8 Chinstrap Dream              46.8          16.5               189        3650\n 9 Chinstrap Dream              46.4          17.8               191        3700\n10 Gentoo    Biscoe             50.4          15.7               222        5750\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "012-dplyr-single-table.html#mutating-and-adding-columns-with-mutate",
    "href": "012-dplyr-single-table.html#mutating-and-adding-columns-with-mutate",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.9 Mutating and adding columns with mutate\n",
    "text": "14.9 Mutating and adding columns with mutate\n\nThe function mutate() can add an new column or replace an existing one.\nTo make a new column called body_mass_kg we can use\n\npenguins |&gt; \n  mutate(body_mass_kg = body_mass_g / 1000)\n\nmutate: new variable 'body_mass_kg' (double) with 95 unique values and 1% NA\n\n\n# A tibble: 344 × 9\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, body_mass_kg &lt;dbl&gt;\n\n\nThere are lots of functions that are useful to use with mutate. Any function that returns either a single value or as many values as are in the data can be used.\nmutate() is very useful when cleaning data.\n\nSee text manipulation tutorial for cleaning text with the stringr package.\nSee date and time tutorial for cleaning dates and times with the lubridate package.\n\n\n\n\n\n\n\nExercise\n\n\n\nWith the penguins data,\n\nconvert flipper length to cm\nadd a column with the ratio of bill width to length\n\n\nHint\n\n# hint 1\npenguins |&gt; \n  mutate(___ = ___)"
  },
  {
    "objectID": "012-dplyr-single-table.html#summarising-data-with-summarise",
    "href": "012-dplyr-single-table.html#summarising-data-with-summarise",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.10 Summarising data with summarise()\n",
    "text": "14.10 Summarising data with summarise()\n\nsummarise() lets us summarise data. We can use it if we want to calculate a summary statistic of the data. Remember to separate arguments with a comma.\n\npenguins |&gt; summarise(\n  flipper_len_mean = mean(flipper_length_mm, na.rm = TRUE), \n  flipper_len_sd = sd(flipper_length_mm, na.rm = TRUE)\n  )\n\nsummarise: now one row and 2 columns, ungrouped\n\n\n# A tibble: 1 × 2\n  flipper_len_mean flipper_len_sd\n             &lt;dbl&gt;          &lt;dbl&gt;\n1             201.           14.1\n\n\nOnly the columns created in the summarise() and any grouping columns (see below) will be kept.\n\n\n\n\n\n\nExercise\n\n\n\nWith the penguins data, find\n\nthe maximum and minimum bill length\n\n\nHint\n\npenguins |&gt; \n  summarise(___ = ___(___))\n\n\n\n\n\n14.10.1 Summarising multiple columns\nSometimes you want to summarise multiple columns at the same time. This can be done with the across() helper function. across() needs to be told which columns to process and what function or functions to use.\n\npenguins |&gt;\n   summarise(\n     across(c(bill_length_mm, bill_depth_mm), \n            .fns = \\(x)mean(x, na.rm = TRUE)))\n\nsummarise: now one row and 2 columns, ungrouped\n\n\n# A tibble: 1 × 2\n  bill_length_mm bill_depth_mm\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           43.9          17.2\n\n#using a list of functions\npenguins |&gt;\n  summarise(\n    across(.cols = starts_with(\"bill\"), \n           .fns = list(sd = \\(x)sd(x, na.rm = TRUE), \n                       mean = \\(x)mean(x, na.rm = TRUE))))\n\nsummarise: now one row and 4 columns, ungrouped\n\n\n# A tibble: 1 × 4\n  bill_length_mm_sd bill_length_mm_mean bill_depth_mm_sd bill_depth_mm_mean\n              &lt;dbl&gt;               &lt;dbl&gt;            &lt;dbl&gt;              &lt;dbl&gt;\n1              5.46                43.9             1.97               17.2\n\n\nYou can also use across() with mutate() to mutate several columns at the same time."
  },
  {
    "objectID": "012-dplyr-single-table.html#grouping-data-with-group_by",
    "href": "012-dplyr-single-table.html#grouping-data-with-group_by",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.11 Grouping data with group_by\n",
    "text": "14.11 Grouping data with group_by\n\ngroup_by() changes the way that many of the dplyr functions work. Instead of working on the entire dataset, they now work on each group in the data\nTo find the mean flipper length for each species, we need to group_by() species and then summarise().\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(mean_flipper_length = mean(flipper_length_mm))\n\ngroup_by: one grouping variable (species)\n\n\nsummarise: now 3 rows and 2 columns, ungrouped\n\n\n# A tibble: 3 × 2\n  species   mean_flipper_length\n  &lt;fct&gt;                   &lt;dbl&gt;\n1 Adelie                    NA \n2 Chinstrap                196.\n3 Gentoo                    NA \n\n\nGrouped data can be ungrouped with ungroup(). This can help prevent surprises!\n\n\n\n\n\n\nExercise\n\n\n\nWith the penguins data, find\n\nthe maximum and minimum bill depth of each species\n\n\nHint\n\npenguins |&gt; \n  group_by(___)\n  summarise(___ =  ___(___))"
  },
  {
    "objectID": "012-dplyr-single-table.html#sorting-with-arrange",
    "href": "012-dplyr-single-table.html#sorting-with-arrange",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.12 Sorting with arrange()\n",
    "text": "14.12 Sorting with arrange()\n\nTo sort the data frame by one or more of the variables we can use arrange().\n\npenguins |&gt; arrange(bill_length_mm, bill_depth_mm)\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Dream               32.1          15.5               188        3050\n2 Adelie  Dream               33.1          16.1               178        2900\n3 Adelie  Torgersen           33.5          19                 190        3600\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThis will sort smallest first. To reverse the sort order, use desc()\n\npenguins |&gt; arrange(desc(bill_length_mm), desc(bill_depth_mm))\n\n# A tibble: 344 × 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSort the penguins data by\n\nbody mass\nisland and body mass, with the largest birds first\n\n\nHint\n\n# hint 1\npenguins |&gt; \n  arrange(___, ___)\n\n# hint 2\n?desc"
  },
  {
    "objectID": "012-dplyr-single-table.html#counting-rows-with-count-and-n",
    "href": "012-dplyr-single-table.html#counting-rows-with-count-and-n",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.13 Counting rows with count() and n()\n",
    "text": "14.13 Counting rows with count() and n()\n\nThe function n can count how many rows there are in the each group (or the entire data frame if it is not grouped). It can be used with either mutate() or summarise().\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(n = n())\n\ngroup_by: one grouping variable (species)\n\n\nsummarise: now 3 rows and 2 columns, ungrouped\n\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nOr with count()\n\npenguins |&gt; \n  count(species)\n\ncount: now 3 rows and 2 columns, ungrouped\n\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\ncount() is more concise, but group_by() and summarise() is useful when you need to calculate more variables (for example mean and standard deviation).\n\n\n\n\n\n\nExercise\n\n\n\nFrom the penguins data, find\n\nhow many penguins are there of each species\nhow many penguins are there of each species in each island\n\n\nHint\n\npenguins |&gt; \n  count(___, ___)\n\n# or\npenguins |&gt; \n  group_by(___) |&gt; \n  summarise(___ = n())"
  },
  {
    "objectID": "012-dplyr-single-table.html#common-problems",
    "href": "012-dplyr-single-table.html#common-problems",
    "title": "14  Working with single tables in dplyr",
    "section": "\n14.14 Common problems",
    "text": "14.14 Common problems\n\n14.14.1 Non standard names\nIdeally column names should follow the standard rules for naming objects in R - UPPER and lower case letters, numbers, “.” and “_” with the first character being a letter (or a dot if you want an invisible object). Sometimes when you import data, it has non-standard names with spaces or extra characters. If you need to refer to a column name that doesn’t follow the rules, you need to enclose it with back-ticks.\n\ndf &lt;- tibble(`Region/Country` = \"Norway\", value = 42)\ndf\n\n# A tibble: 1 × 2\n  `Region/Country` value\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Norway              42\n\ndf |&gt; rename(region_country = `Region/Country`)\n\nrename: renamed one variable (region_country)\n\n\n# A tibble: 1 × 2\n  region_country value\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Norway            42\n\n\nIt is sometimes best to rename these columns to make them easier to refer to. janitor::clean_names() is very efficient for making easy-to-use names.\n\n\n\n\n\n\nFurther reading\n\n\n\n\nstat545\nR for data science\ndplyr cheatsheet\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "013-dplyr-multiple-tables.html#merging-data-frames-with-mutating-joins",
    "href": "013-dplyr-multiple-tables.html#merging-data-frames-with-mutating-joins",
    "title": "\n15  Working with multiple tables in dplyr\n",
    "section": "\n15.1 Merging data frames with mutating joins",
    "text": "15.1 Merging data frames with mutating joins\nMutating joins combine two data frames by matching rows according to one or more identifying variables that are in both data frames.\nThe most commonly used mutating join is a left join. Left joins take all rows from the first data set, and the rows from the second data frame where the values of the identifying variable match the first (Figure 15.1).\n\n\n\n\nFigure 15.1: Left join. The coloured column contains the identifiers.\n\n\n\nIf there are duplicate values in the identifying column, this (Figure 15.2) causes the matching rows to be duplicated. If the number of rows in the result increases when you were not expecting it, that can indicate that your identifier are not unique.\n\n\n\n\nFigure 15.2: Left join. The coloured column contains the identifiers.\n\n\n\nLeft joins are implemented in dplyr with left_join().\nLet use left_join() to add the location of each island to the penguin data set.\n\n# location of the three islands in the Palmer Archipelago\n\npenguin_islands &lt;- tribble(\n  ~ island, ~ Latitude, ~ Longitude, # tribble is a convenient way to make small datasets\n  \"Torgersen\", -64.766667,-64.083333,\n  \"Biscoe\", -64.818569, -63.775636,\n  #\"Dream\",  -64.733333, -64.233333, # Dream data missing\n  \"Alpha\", -64.316667, -63)\n\npenguin_islands\n\n# A tibble: 3 × 3\n  island    Latitude Longitude\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1 Torgersen    -64.8     -64.1\n2 Biscoe       -64.8     -63.8\n3 Alpha        -64.3     -63  \n\n\nThe first two arguments to left_join() are the data frames, the third is the by argument which tells the join which column to make the join by with help from the join_by function. Here, we are joining by a single column with the same name in both data frames. It is possible to join by multiple columns and where the columns have different names in each dataset.\n\npenguin_small &lt;- penguins |&gt; \n  group_by(species) |&gt; \n  slice(1:2) # small version of data for easy viewing\n\n\nleft_join(penguin_small, penguin_islands, by = join_by(island))\n\n# A tibble: 6 × 10\n# Groups:   species [3]\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie    Torgersen           39.1          18.7               181        3750\n2 Adelie    Torgersen           39.5          17.4               186        3800\n3 Chinstrap Dream               46.5          17.9               192        3500\n4 Chinstrap Dream               50            19.5               196        3900\n5 Gentoo    Biscoe              46.1          13.2               211        4500\n6 Gentoo    Biscoe              50            16.3               230        5700\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt;\n\n\nOnly three of the four islands in penguin_islands have data in the penguins data set.\nThe join_by() function also lets us join by multiple columns, join by columns with different names (join_by(column1 == column2)), join with an inequality (join_by(column1 &gt; column2)), and use helper functions such as closest() so the join can work even when there is not an exact match.\nDifferent variants of mutating joins will treat this in different ways.\n\n\nleft_join() takes all rows from the first (left) data frame and matching rows from the second (right).\n\nright_join() does the opposite to left_join(), taking all rows from the second (right) data frame and matching rows from the first.\n\ninner_join() will take only rows that match in both data frames.\n\nfull_join() will take all rows from in both data frames.\n\nIn all cases, missing values will are given an NA.\n\n\n\n\n\n\nExercise\n\n\n\nJoin the penguins and penguin_islands datasets to\n\nget all data where there is both penguin and island data\n\n\nHint\n\ninner_join(___, ___, by = join_by(___))"
  },
  {
    "objectID": "013-dplyr-multiple-tables.html#all-possible-combinations",
    "href": "013-dplyr-multiple-tables.html#all-possible-combinations",
    "title": "\n15  Working with multiple tables in dplyr\n",
    "section": "\n15.2 All possible combinations",
    "text": "15.2 All possible combinations\nThe mutating joins described above give you the rows from each data frame where the identifying variables match. Sometimes you want all possible combinations of rows. This is known as the Cartesian product and can be generated with crossing(). crossing() works with data frames as well as vectors as shown here.\n\ncrossing(a = letters[1:3], b = 1:2)\n\n# A tibble: 6 × 2\n  a         b\n  &lt;chr&gt; &lt;int&gt;\n1 a         1\n2 a         2\n3 b         1\n4 b         2\n5 c         1\n6 c         2"
  },
  {
    "objectID": "013-dplyr-multiple-tables.html#filtering-joins",
    "href": "013-dplyr-multiple-tables.html#filtering-joins",
    "title": "\n15  Working with multiple tables in dplyr\n",
    "section": "\n15.3 Filtering joins",
    "text": "15.3 Filtering joins\nFiltering joins let you filter one dataset according to whether rows have a match in the a second dataset.\nsemi_join() finds rows that have a matching row\n\n\n\n\nLeft join. The coloured column contains the identifiers.\n\n\n\n\npenguin_islands |&gt; \n  semi_join(penguins, by = join_by(island))\n\n# A tibble: 2 × 3\n  island    Latitude Longitude\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1 Torgersen    -64.8     -64.1\n2 Biscoe       -64.8     -63.8\n\n\nanti_join() finds rows that do not have a matching row\n\n\n\n\nLeft join. The coloured column contains the identifiers.\n\n\n\n\npenguin_islands |&gt; \n  anti_join(penguins, by = join_by(island))\n\n# A tibble: 1 × 3\n  island Latitude Longitude\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Alpha     -64.3       -63\n\n\nThese can be very useful when cleaning data to find problems."
  },
  {
    "objectID": "013-dplyr-multiple-tables.html#binding-data-frames-together",
    "href": "013-dplyr-multiple-tables.html#binding-data-frames-together",
    "title": "\n15  Working with multiple tables in dplyr\n",
    "section": "\n15.4 Binding data frames together",
    "text": "15.4 Binding data frames together\nIf we have two or more data frames that we want to combine we can one of the bind_* functions.\n\n15.4.1 More columns - bind_cols()\n\nIf the data frames contain information about the same observations, they can be combined with bind_cols().\nSo data1, data2, and data3 can be combined to make one data frame with many columns\n\nbind_cols(data1, data2, data3)\n\nbind_cols() expects that the row order is the same in both datasets, but cannot check this. It only checks that the number of rows is the same in each data frame. If possible, use a join instead.\n\n15.4.2 More rows - bind_rows()\n\nIf the data frame contain more observations (rows), and typically at least some of the same columns, they can be combined with bind_rows(). This is useful if, for example, there are data from two years that need combining.\nOne feature of bind_rows() that I find useful is the .id argument that makes an extra column for an identifier.\n\nsvalbard_islands &lt;-  tribble( ~ island, ~ Latitude, ~ Longitude,\n   \"Nordaustlandet\", 79.558405, 24.017351,\n \"Prins Karls Forland\", 78.554090, 11.256545)\n\nbind_rows(\n  Palmer = penguin_islands, \n  Svalbard = svalbard_islands, \n  .id = \"Archipelago\")\n\n# A tibble: 5 × 4\n  Archipelago island              Latitude Longitude\n  &lt;chr&gt;       &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;\n1 Palmer      Torgersen              -64.8     -64.1\n2 Palmer      Biscoe                 -64.8     -63.8\n3 Palmer      Alpha                  -64.3     -63  \n4 Svalbard    Nordaustlandet          79.6      24.0\n5 Svalbard    Prins Karls Forland     78.6      11.3\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "100_why_data_visualisation.html#data-visualisation-in-r",
    "href": "100_why_data_visualisation.html#data-visualisation-in-r",
    "title": "\n16  Why is data visualization important?\n",
    "section": "\n16.1 Data visualisation in R",
    "text": "16.1 Data visualisation in R\nThere are at least three major systems for making figures in R.\n\nBase R\nThe lattice package\nThe ggplot2 package\n\nWe will focus this tutorial on ggplot2 [@Wickham2011-yw] and associated R packages, as it is generally easier to make nice figures in ggplot2 than the others. We use ggplot2 for figures in our papers.\nggplot2 is a system for ‘declaratively’ creating graphics, based on “The Grammar of Graphics”. You provide the data, tell ‘ggplot2’ how to map variables to aesthetics (x, y, colour, etc), what graphical elements to use, and it takes care of the details.\n\n\n\n\n\n\n\n\n\nContributors\n\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "101_getting_started_with_ggplot.html#the-ggplot2-package",
    "href": "101_getting_started_with_ggplot.html#the-ggplot2-package",
    "title": "\n17  Getting started with ggplot\n",
    "section": "\n17.1 The ggplot2 package",
    "text": "17.1 The ggplot2 package\nggplot2 is part of tidyverse so if you have already installed tidyverse, you already have ggplot2 installed. If not, see Section 5.6.2.\nTo activate ggplot2, you can use\n\nlibrary(ggplot2)\n\nBut most of the time you should use library(tidyverse)."
  },
  {
    "objectID": "101_getting_started_with_ggplot.html#the-basics",
    "href": "101_getting_started_with_ggplot.html#the-basics",
    "title": "\n17  Getting started with ggplot\n",
    "section": "\n17.2 The basics",
    "text": "17.2 The basics\nggplot is based on the grammar of graphics, a terminology describing the components of a figure.\nLet us have a look at these terms.\nTo produce a figure or plot, we take data values and use elements like dots, squares, lines, and colour to convert the data into a visual graphic. There are many different ways to make a figure, but there are some rules that apply in general. A plot is always built on data, and a number of other components called aesthetics, geometry and scales. These different components combined make up a figure."
  },
  {
    "objectID": "101_getting_started_with_ggplot.html#the-code",
    "href": "101_getting_started_with_ggplot.html#the-code",
    "title": "\n17  Getting started with ggplot\n",
    "section": "\n17.3 The code",
    "text": "17.3 The code\nThe code for to make a scatterplot with the penguins dataset from the palmerpenguins package looks something like this:\n\nggplot(data = penguins,\n       mapping = aes(x = body_mass_g, y = bill_length_mm, colour = species)) +\n  geom_point() +\n  labs(x = \"Body mass, g\", y = \"Bill length, mm\", colour = \"Species\") +\n  theme_bw()\n\n\n\n\nThe main function is ggplot() and is used to define the data and the aesthetics. The data is a data frame or tibble containing the variables to produce the figure. The mapping uses aes() to describe how the variables should be mapped onto the aestetics, such as x and y position or colour. Every other component of the plot is added with +. It makes the code easier to read if you put a new line after each + (the + must go at the end of a line, not at the start). These other elements include the graphical elements that display the data, usually created with a geom_*() function, labels created with labs(), and themes (Chapter 19) that change the non-data elements of the plot with themes().\nYou can think of it as different layers that are put on top of each other see Figure 17.1.\n\n\n\n\nFigure 17.1: Visualization of how ggplots are built."
  },
  {
    "objectID": "101_getting_started_with_ggplot.html#building-a-ggplot-figure",
    "href": "101_getting_started_with_ggplot.html#building-a-ggplot-figure",
    "title": "\n17  Getting started with ggplot\n",
    "section": "\n17.4 Building a ggplot figure",
    "text": "17.4 Building a ggplot figure\nNow we will describe the different components a ggplot is made of.\n\n17.4.1 Data\nTo make a figure we use the function ggplot(). The first argument in this function is for the data object containing all the variables that you need to make a figure. Generally, it is advisable to have the data in a long format (Chapter 13).\n\nggplot(data = penguins)\n\n\n\n\nThe ggplot function by itself will produce an empty plot.\n\n17.4.2 Aesthetics\nThe second argument in the ggplot() function, mapping, is where we define the plot’s aesthetics with the function aes(). The different elements from the aesthetics are used to display the data. The most important element is the position which describes the location of the data on the plot, usually by x and y. Other important elements are shape, fill, size, colour and line type, which describe how the data is presented on the plot.\nIn the penguin example, if we want to plot the bill length against the bill depth, we choose these two variables as x and y. As a second aesthetic we have chosen to map species to colour.\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     colour = species))\n\n\n\n\nOne thing that might be confusing about the argument colour is that it only allows to be a variable, for example colour = species or colour = island. So for example colour = \"red\" does not work. If you want to choose a specific colour, this has to be done in geom or in scales (Section 20.1).\nNow the ggplot function has added the x and y axis to the plot.\n\n17.4.3 Geoms\nTo plot the actual data, you need a geom function. There are many different geom functions that you can choose. See Chapter 18 for an overview.\nHere, we will use four different geoms to display aspects of the penguins data in different ways. The legend is automatically plotted on the right side when needed.\n\np1 &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, colour = species)) +\n  geom_point()\np2 &lt;- ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, colour = species)) +\n  geom_density2d()\np3 &lt;- ggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar()\np4 &lt;- ggplot(penguins, aes(x = species, y = bill_depth_mm, fill = species)) +\n  geom_boxplot()\n\np1\np2\np3\np4\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nMake a histogram of the penguins bill length.\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___)) +\n  geom____()\n\n\nMake the histogram red.\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___)) +\n  geom____(fill = \"red\")\n\n\nMake a violin plot of the penguins bill length by species.\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___, y = ___)) +\n  geom____()\n\n\nMake a scatterplot of penguin bill length against flipper length.\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___, y = ___)) +\n  geom____()\n\n\nMake the points in the scatterplot different colours and shapes by species\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___, y = ___, colour = ___, shape = ___)) +\n  geom____()\n\n\n\n\n\n17.4.4 Scales\nScales as the name says is for scaling, converting, inverting. With scales you can manipulate the labels, breaks, transformations and palettes. In other words you can manually change the axis text, labels, ticks, add breaks, make transformations, and manipulate aesthetics like colour, shape, linetype ( Chapter 20).\nHere is just a small selection to show what is possible. We can log transform the y axis, change the axis titles, and change the colours.\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     colour = species)) +\n  geom_point() +\n  scale_y_log10() +\n  scale_x_continuous() +\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nGive your violin plot a colour-blind friendly fill.\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___, y = ___, fill = ___)) +\n  geom____() +\n  scale________()\n\n\n\n\n\n17.4.5 Labs\nlabs() is a useful function to modify the axis labels, titles and legend.\nThe axis titles can be renamed, and a title and tag can be added.\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     colour = species)) +\n  geom_point() +\n  labs(\n    x = \"Bill length mm\", \n    y = \"Bill depth mm\", \n    title = \"Bill length vs. depth in penguins\", \n    tag = \"A\")\n\n\n\n\nTitles can be useful for presentations, but generally not useful for manuscripts, where you can put the information into the caption. Tags are useful when building a multipart figure (Chapter 22).\n\n\n\n\n\n\nExercise\n\n\n\n\nAdd axis & legend labels to your violin plot\n\n\nHint\n\nviolin_plot + \n  labs(x = ___, y = ___, fill = ___)\n\n\n\n\n\n17.4.6 Facets\nFacets can be used to divide the data into different subplots, which can enhance readability of a figure.\nIn the next example, we use facet_wrap() to split the penguin data into 3 panels, one for each island.\n\nggplot(penguins, aes(x = bill_length_mm, \n                     y = bill_depth_mm,\n                     colour = species)) +\n  geom_point() +\n  facet_wrap(facets = vars(island))\n\n\n\n\nIf you want to split the data by two variables, facet_grid() can be useful.\n\nggplot(penguins, aes(x = bill_length_mm, \n                     y = bill_depth_mm,\n                     colour = species)) +\n  geom_point() +\n  facet_grid(rows = vars(island), cols = vars(sex))\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nsplit your scatterplot into facets by sex.\n\n\nHint\n\nscatter_plot +\n  facet_wrap(vars(___))\n\n\n\n\n\n17.4.7 Themes\nThemes is a powerful element that controls the look of the plot. In themes you can change, remove and add the background, gridlines, ticks, text, text size and much more.\nIn our example, we will change the axis tile text size, the colour of the axis text and change the theme to theme_minimal().\nSee Chapter 19 for more about using themes.\n\nggplot(penguins, aes(x = bill_length_mm, \n                     y = bill_depth_mm,\n                     colour = species)) +\n  geom_point() +\n  facet_wrap(facets = vars(island)) +\n  theme_minimal() +\n  theme(axis.title = element_text(size = 14),\n        axis.text = element_text(colour = \"purple\"))\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nChange the theme of your scatterplot\n\n\nHint\n\nscatter_plot +\n  theme___()\n\n\n\n\n\n17.4.8 A ggplots are built with layers\nAs you can see, there are almost no limits to what you can do in a ggplot. The trick is to know which element changes what and to remember all the names (i.e. what is axis.text and axis.ticks etc.).\nThe order in which you code the different components of a plot often does not matter, except that the ggplot() needs to come first, and geoms are plotted in the order they are in the code. You can imagine the different components (geom, scale, stats) of the plot as different layers that are plotted on top of each other.\nFor example, you want to plot the data below and the smoother on top, and not the other way round.\n\npoints_on_top &lt;- ggplot(penguins, aes(x = bill_length_mm,\n                                      y = bill_depth_mm, \n                                      colour = species)) +\n  geom_smooth() +\n  geom_point()\n\nsmooth_on_top &lt;- ggplot(penguins, aes(x = bill_length_mm, \n                                      y = bill_depth_mm,\n                                      colour = species)) +\n  geom_point() +\n  geom_smooth() \n\npoints_on_top\nsmooth_on_top\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nMake a boxplot of bill length by species on top of the jittered bill length data\n\n\nHint\n\nggplot(data = ___, mapping = aes(x = ___, y = ___)) +\n  geom____() +\n  geom____()"
  },
  {
    "objectID": "101_getting_started_with_ggplot.html#trouble-shooting",
    "href": "101_getting_started_with_ggplot.html#trouble-shooting",
    "title": "\n17  Getting started with ggplot\n",
    "section": "\n17.5 Trouble shooting",
    "text": "17.5 Trouble shooting\nIn the beginning you will make mistakes which will result in error messages, warnings or incomplete plots. These mistakes often occur when one of the layers is missing, because a + is forgotten at the end of a line, due to a typo, or the data or other elements are forgotten.\nTo debug ggplot errors and other problems, we need to find where the error is. Run the first line (excluding with + at the end) and see what happens. If it does what you expect that line to run, then run the first two lines. You can also comment lines out (by putting a # in front of them). I recommend typing NULL on the line after the plot code so that if there is a extra + after removing a line, the plot won’t give a strange error by adding the next line of code.\n\nggplot(penguins, aes(x = species, y = bill_length_mm)) +\n  geom_violin() + # extra + after commenting out labs()\n#  labs(x = \"Species\", y = Bill length)\nNULL #This will end the plot code\n\nLet us look at some common mistakes and how the ggplot is displayed or not.\n\n17.5.1 No data\nIf you forget to specify the data ggplot will not be able to make a plot and you will get the following error message:\n\nggplot(aes(x = bill_length_mm, y = bill_depth_mm, colour = species)) +\n  geom_point()\n\nError in `fortify()`:\n! `data` must be a &lt;data.frame&gt;, or an object coercible by `fortify()`,\n  not a &lt;uneval&gt; object.\nℹ Did you accidentally pass `aes()` to the `data` argument?\n\n\n\n17.5.2 Missing aesthetics\nIf you forget to define the aesthetics aes() you will also get an error message and a empty image:\n\nggplot(data = penguins) +\n  geom_point()\n\nError in `geom_point()`:\n! Problem while setting up geom.\nℹ Error occurred in the 1st layer.\nCaused by error in `compute_geom_1()`:\n! `geom_point()` requires the following missing aesthetics: x and y\n\n\n\n17.5.3 Missing geometry\nIf the geometry is missing geom_point(), ggplot will draw a empty plot, with axis labels, but show not data, because you have not defined how to plot the data.\n\nggplot(data = penguins, aes(x = bill_length_mm, \n                            y = bill_depth_mm, \n                            colour = species))\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nI make lots of mistakes and my plots don’t work. Please help me fix them.\n\nggplot(penguins, aes(x = bill_length, y = bill_depth)) |&gt; \n  geom_point() + \n  labs(x = \"Bill length\", y = \"Bill width\")\n\n\nHint\n\nUse + not pipes to add plot elements\n\nggplot(penguins, aes(x = bill_length, y = bill_depth))  \n+  geom_point() \n+  labs(x = \"Bill length\", y = \"Bill width\")\n\n\nHint\n+ must be at the end of the line not the beginning\nWhy is this plot without colour?\n\nggplot(penguins, aes(x = bill_length, y = bill_depth, fill = species)) +  \n  geom_point() + \n  scale_fill_viridis_c() +\n  labs(x = \"Bill length\", y = \"Bill width\")\n\n\nHint\n\nMake sure the aesthetic in aes() match the aesthetics in the scale_\\*_\\*() function. Also note that the c in scale_colour_viridis_c() is for a continuous scale. See the help file for how to change this.\n\n\n\n\n\n\n\n\n\nWhat’s next?\n\n\n\nNext, we will show the essential elements of a plot (title, axes, legend, …) and you can learn how to change and adapt each of these elements. Further you can learn the most common plots types that are commonly used (Chapter 18).\n\n\n\n\n\n\nContributors\n\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "103_different_types_of_vizualization.html#amounts",
    "href": "103_different_types_of_vizualization.html#amounts",
    "title": "18  Choosing your visualisation",
    "section": "\n18.1 Amounts",
    "text": "18.1 Amounts\nYou can use barplots to show amounts. geom_bar() will count how many observations there are of each type.\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\nIf we have already calculated the amount, then we can use geom_col() to get an identical figure.\n\npenguins |&gt; \n  count(species) |&gt; \n  ggplot(aes(x = species, y = n)) +\n  geom_col()"
  },
  {
    "objectID": "103_different_types_of_vizualization.html#distribution-of-a-continuous-variable",
    "href": "103_different_types_of_vizualization.html#distribution-of-a-continuous-variable",
    "title": "18  Choosing your visualisation",
    "section": "\n18.2 Distribution of a continuous variable",
    "text": "18.2 Distribution of a continuous variable\nHistograms and density plots are often used to show the distribution of a continuous variable. These can be made with geom_histogram() and geom_density(), respectively. Histograms split the data into bins and usually show the number of observations in each bin. Density plots use a kernel smoother (often a Gaussian kernel - the normal bell-shaped curve) to give a smooth version of a histogram.\n\nbase &lt;- ggplot(penguins, aes(x = flipper_length_mm))\np_hist &lt;- base + geom_histogram()\np_dens &lt;- base + geom_density() \np_hist\np_dens\n\n\n\n\n\n\nA key decision with histograms is how many bins to use, which can be set with the bins argument. Too few bins and information is lost, too many and the result is very noisy. Always try different values. The placing of the bins can be controlled with the boundary or center.\n\n\n\n\n\n\nExercise\n\n\n\nMake a histogram of the penguins bill length. Change the number of bins. What how many bins seem to work best?\n\nHint\nChange the bins argument in geom_histogram\n\n\n\nDensity plots can fail if there are sharp breaks in the data, and they can extrapolate into impossible regions (e.g. negative ages on a density plot of ages).\n\n\n\n\n\n\nExercise\n\n\n\nMake a density plot of the penguins bill length. Use the adjust argument to make the bandwidth of the smoother wider or narrower than the default.\n\nHint\nChange the adjust argument in geom_density"
  },
  {
    "objectID": "103_different_types_of_vizualization.html#a-few-distributions-of-a-continuous-variable",
    "href": "103_different_types_of_vizualization.html#a-few-distributions-of-a-continuous-variable",
    "title": "18  Choosing your visualisation",
    "section": "\n18.3 A few distributions of a continuous variable",
    "text": "18.3 A few distributions of a continuous variable\nIf we want show the distribution of a continuous variable conditioned by a categorical variable, we can add a fill aesthetic to the histogram or density plot.\n\nbase &lt;- ggplot(penguins, aes(x = flipper_length_mm, fill = species))\np_hist &lt;- base + geom_histogram()\np_dens &lt;- base + geom_density(alpha  = 0.4) # set alpha to make transparent\n\np_hist\np_dens\n\n\n\n\n\n\nBy default, geom_histogram() gives a stacked histogram, while geom_density() plots the curves behind each other, which makes them easier to compare. This behaviour can be changed with the position argument.\nWith more than a few levels of the categorical variable, this becomes unreadable, especially for the histogram, and we need another way to show the data.\n\n\n\n\n\n\nExercise\n\n\n\nMake a histogram of the penguins bill length, showing the different species with different fills. Make the fill semi-transparent with the alpha argument. Change the position argument from \"stack\" to \"identity\". Which position is easiest to interpret?\n\n\n\n\n\n\n\n\nExercise\n\n\n\nMake a density plot of the penguins bill length, showing the different species with different fills. Make the fill semi-transparent with the alpha argument. Change the position argument from \"identity\" to \"stack\". Which position is easiest to interpret?"
  },
  {
    "objectID": "103_different_types_of_vizualization.html#many-distributions-of-a-continuous-variable",
    "href": "103_different_types_of_vizualization.html#many-distributions-of-a-continuous-variable",
    "title": "18  Choosing your visualisation",
    "section": "\n18.4 Many distributions of a continuous variable",
    "text": "18.4 Many distributions of a continuous variable\n\nbase &lt;- ggplot(penguins, aes(x = species, y = flipper_length_mm))\n\np_prange &lt;- base + stat_summary(fun.data = mean_sdl)\np_box &lt;- base + geom_boxplot(aes(fill = species))\np_vio &lt;- base + geom_violin(aes(fill = species))\np_point &lt;- base + geom_point(aes(colour = species))\np_jit &lt;- base + geom_jitter(aes(colour = species))\nlibrary(ggforce)\np_sina &lt;- base + geom_sina(aes(colour = species))\nlibrary(ggbeeswarm)\np_bees &lt;- base + geom_beeswarm(aes(colour = species))\np_quasi &lt;- base + geom_quasirandom(aes(colour = species))\n\n\n\n\n\n\n\n\ngeom_pointrange() is showing the mean \\(\\pm\\) 2 standard deviations. It is a bad choice as it shows nothing of the raw data.\n\ngeom_boxplot() shows the median as the middle black line; the box encloses the central 50 % of the data (from the lower to the upper quantiles). Whiskers stretch out as far as the maximum/minimum value that is within 1.5x the width of the central box. Outliers beyond this are shown as points.\n\ngeom_violin() are like geom_density() curves, turned on their side and reflected. They show the shape of the distribution better than boxplots, and can work better than boxplots, especially for non-unimodal data.\n\ngeom_point() shows the data, but is not very informative because of over-plotting.\n\ngeom_jitter() reduces over-plotting but does not show the distribution very well\n\ngeom_sina(), geom_beeswarm() and geom_quasirandom(), all from extra packages, attempt to minimise over-plotting while showing the shape of the distribution.\n\nIt is possible to use multiple geoms on top of each other, for example, geom_sina() and geom_violin()"
  },
  {
    "objectID": "103_different_types_of_vizualization.html#many-distributions-of-a-continuous-variable-split-by-a-categorical-variable",
    "href": "103_different_types_of_vizualization.html#many-distributions-of-a-continuous-variable-split-by-a-categorical-variable",
    "title": "18  Choosing your visualisation",
    "section": "\n18.5 Many distributions of a continuous variable split by a categorical variable",
    "text": "18.5 Many distributions of a continuous variable split by a categorical variable\n\npenguins |&gt; \n  drop_na(flipper_length_mm, sex) |&gt; \n  ggplot(aes(x = species, y = flipper_length_mm)) +\n  geom_violin(aes(fill = sex))\n\n\n\n\nNeed to decide which variable to have on the x-axis and which to have as fill. Can also use facets with more complex plots."
  },
  {
    "objectID": "103_different_types_of_vizualization.html#association-between-two-continuous-variables",
    "href": "103_different_types_of_vizualization.html#association-between-two-continuous-variables",
    "title": "18  Choosing your visualisation",
    "section": "\n18.6 Association between two continuous variables",
    "text": "18.6 Association between two continuous variables\nThe standard plot for two continuous variables is the scatterplot, which we can get with geom_point().\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm, colour = species)) +\n  geom_point() +\n  labs(x = \"Body mass, g\", y = \"Bill length,  mm\", colour = \"Species\")\n\n\n\n\nThe x-axis should be the predictor (independent) variable, and the y-axis the response (dependent) variable. With observational data, it may not be so obvious which variable should be on which axis.\nWith lots of data, especially if it is of low precision, there can be a problem with over-plotting.\nSeveral solutions, which can be used together\n\ntransparency. Make the points semi-transparent by setting alpha. Now where there are many points the plot will appear darker.\n\njitter, add a small amount of noise to the data by using geom_jitter() instead of geom_point()\n\n\ngeom_count() show bubbles scaled according to how many points there are at each point.\n\ngeom_density2d() contour lines of the density of points.\n\ngeom_bin2d() or geom_hexbin() to make 2-dimensional histograms.\n\n\n18.6.1 2D density\n\nggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, colour = species)) +\n  geom_density2d()"
  },
  {
    "objectID": "103_different_types_of_vizualization.html#association-between-more-than-two-continuous-variables",
    "href": "103_different_types_of_vizualization.html#association-between-more-than-two-continuous-variables",
    "title": "18  Choosing your visualisation",
    "section": "\n18.7 Association between more than two continuous variables",
    "text": "18.7 Association between more than two continuous variables\nSome choices\n\nuse an ordination to reduce the data to two orthogonal dimensions (See BIO303)\nuse a heatmap of the correlations between variables\nplot all possible pairs of variables with GGally::ggpairs()\n\n\n\n18.7.1 GGally::ggpairs\n\nlibrary(GGally)\npenguins |&gt; \n  select(-year) |&gt; \n  ggpairs(mapping = aes(colour = species))\n\n\n\n\n\n18.7.2 Heatmap\nFirst calculate the correlations between the numeric variables, then reshape the data into long format,\n\n# Select only numeric variables and remove all NAs\npenguin_matrix &lt;- penguins |&gt; \n  select(bill_length_mm:body_mass_g) |&gt; \n  drop_na(bill_length_mm)\n\n# Calculate the correlation between all variables and rearrange the table\ncor_matrix &lt;- cor(penguin_matrix)\n\n# rearrange\ncor_long &lt;- cor_matrix |&gt; \n  as.data.frame() |&gt; \n  rownames_to_column() |&gt; \n  pivot_longer(cols = -rowname, names_to = \"colname\", values_to = \"cor\") |&gt; \n  #only upper triangle\n  filter(rowname &lt; colname)\n\nNow we can use the function geom_tile() to plot the data.\n\nggplot(data = cor_long, aes(x = rowname, y = colname, fill = cor)) + \n  geom_tile() +\n  scale_fill_gradient2() +\n  theme(axis.title = element_blank())\n\n\n\n\nAlternatively, we can use geom_point() and use the size aesthetic to scale the points by the absolute value of the correlation to give more visual weight to the larger correlations.\n\nggplot(data = cor_long, aes(x = rowname, y = colname, colour = cor, size = abs(cor))) + \n  geom_point() +\n  scale_colour_gradient2() +\n  scale_size_continuous(range = c(2, 20)) +\n  theme(axis.title = element_blank())\n\n\n\n\n\n18.7.3 Lines\nTemporal data are often plotted with line plots. Time is usually on the x axis.\n\nggplot(economics, aes(x = date, y = unemploy)) +\n  geom_line() +\n  labs(x = \"\", y = \"Unemployment\")\n\n\n\n\ngeom_line() will draw a line from the left to the right of the screen regardless of the order of the data. If the order of the data are important, use geom_path() instead.\n\n\n\n\nContributors\n\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "118_themes.html#complete-themes",
    "href": "118_themes.html#complete-themes",
    "title": "19  Themes",
    "section": "\n19.1 Complete themes",
    "text": "19.1 Complete themes\nYou can change the whole theme to a new pre-built theme by adding one of the theme_*() functions.\n\np1 + \n  theme_classic()\n\n\n\ntheme_classic()\n\n\n\nThere are many pre-built themes, some in ggplot2, others in the ggthemes, cowplot, and other packages. You can also write your own.\n\n\n\n\nVarious themes from ggplot2 and gthemes.\n\n\n\n\n19.1.1 Setting the font\nAll the theme_*() functions have an argument to set the base size of the font. The default (about size 11 for most themes) is normally fine for manuscripts and theses, but too small for presentations. Increase it to 18 or 20 so the audience at the back of the auditorium can read the text.\n\np1 + \n  theme_classic(base_size = 18)\n\n\n\ntheme_classic()"
  },
  {
    "objectID": "118_themes.html#setting-the-default-theme",
    "href": "118_themes.html#setting-the-default-theme",
    "title": "19  Themes",
    "section": "\n19.2 Setting the default theme",
    "text": "19.2 Setting the default theme\nIf you are making several figures and want them all to have the same theme, you can set the default with theme_set(). I do this in the first chunk of quarto and R markdown documents.\n\ntheme_set(theme_classic())"
  },
  {
    "objectID": "118_themes.html#changing-individual-elements-of-the-theme",
    "href": "118_themes.html#changing-individual-elements-of-the-theme",
    "title": "19  Themes",
    "section": "\n19.3 Changing individual elements of the theme",
    "text": "19.3 Changing individual elements of the theme\nEvery non-data element of the plot can be changed with theme. Below are a few examples.\n\n19.3.1 Rotating axis labels\nSometimes long axis labels need rotating to stop them overlapping.\n\np2 &lt;- ggplot(penguins, aes(x = species, y = body_mass_g)) + \n  geom_boxplot()\np2\n\n\n\n\n\np2 + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nReading angled text is hard work, so consider alternative solutions to this problem, such as dodging the axis labels\n\np2 + scale_x_discrete(guide = guide_axis(n.dodge=2))\n\n\n\n\nOr flipping the plot.\n\np2 + coord_flip()\n\n\n\n\n\n19.3.2 Changing the legend position\nBy default, the legend is put to the right of the plot. It can be moved with the legend.position argument to theme().\n\np1 + theme(legend.position = \"bottom\")\n\n\n\n\nIf there is space, the legend can be moved into the plot by giving legend.position the x and y coordinates relative to the plot (0 is left or bottom, 1 is top or right). Use legend.justification to specify which corner of the legend should be in the position set by legend.position justify the legend.\n\np1 + \n  theme(\n    legend.position = c(x = 0.99, y = 0.01),\n    legend.justification = c(x = \"right\", y = \"bottom\"))\n\n\n\n\nThe legend can be removed with\n\np1 + theme(legend.position = \"none\")\n\n\n\n\nThis will remove all legends. If a plot has multiple legends, and you want to keep some of them, you get more control by using the show.legend argument to any of the geoms or by using guides()\n\n19.3.3 Removing an element\nYou can remove non-data elements of the plot by setting them to element_blank().\n\np1 + theme(panel.grid = element_blank())\n\n\n\nRemoving gridlines with element_blank()\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "120_colour_shape_linetypes.html#sec-colours-and-fill",
    "href": "120_colour_shape_linetypes.html#sec-colours-and-fill",
    "title": "20  Colours, shapes and linetypes",
    "section": "\n20.1 Colours and fill",
    "text": "20.1 Colours and fill\nThe colour aesthetic give colour for points and lines, while the fill aesthetic gives colour to areas. It is very easy to forget this.\n\nggplot(penguins, aes(x = bill_length_mm, colour = species)) +\n  geom_histogram()\n\n\n\nUse fill for areas.\n\n\n\nYou can set the colour of points or lines and the fill of areas by setting it in the geom_*() used.\n\nggplot(penguins, aes(x = flipper_length_mm)) +\n  geom_histogram(colour = \"purple\", fill = \"pink\")\n\n\n\n\nIf you map a variable to the colour aesthetic, for points and lines, or the fill aesthetics for areas, ggplot will give you different colours/fills for the different values in the variable. If you don’t like the default colours/fills, and you shouldn’t because they are not colour blind friendly, then you can change them with a scale_colour_*() or scale_fill_*(). First you need to decide what type of colour/fill scale you need.\nThe first decision is whether the scale should be continuous or discrete.\n\n20.1.1 Discrete colour/fill scales\nDiscrete scales are automatically used when the variable mapped to colour or fill is a character or factor variable. If you want to use a discrete scale on a numeric variable, for example, if 0 represents Male and 1 represents Female (this is a bad idea), then you need to coerce it to a factor with factor(). If you don’t do this, you will get an error.\nThere is a choice of four types of discrete colour/fill scales\n\nQualitative for categorical variables\nSequential for ordinal variables\nDiverging for ordinal variables with a natural midpoint.\nHighlights when you want to focus on only some of the data.\n\n\n20.1.1.1 Qualitative\nQualitative palettes have no natural order to the colours. Use them for categorical variables. In the penguins dataset, species, island, and sex are categorical variables.\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density()\n\n\n\n\nYou can change the default colours/fill by either picking your own colours with scale_colour_manual() or scale_fill_manual().\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density() +\n  scale_fill_manual(values = c(Adelie = \"pink\", \n                               Chinstrap = \"purple\", \n                               Gentoo = \"green\"))\n\n\n\n\nPicking your own colours can be hard!\nNormally better to use some built in qualitative palettes, for example these from the RColorBrewer package.\n\nRColorBrewer::display.brewer.all(type = \"qual\")\n\n\n\n\nYou can use these with scale_colour_brewer() or scale_fill_brewer()\n\nggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density() +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n20.1.1.2 Sequential\nSequential colour/fill scales are useful for ordinal variables - for example, high, medium, and low concentrations of a treatment drug.\nHere are some examples from the RColorBrewer package, which can be used as above.\n\nRColorBrewer::display.brewer.all(type = \"seq\")\n\n\n\n\nAnother example of a sequential colour/fill palette is viridis, which can be used with scale_fill_viridis_d().\n\n20.1.1.3 Diverging\nDiverging colour/fill scales are useful for ordinal variables with a natural midpoint, which might be zero, or the mean of the data.\nHere are some examples from the RColorBrewer package, which can be used as above.\n\nRColorBrewer::display.brewer.all(type = \"div\")\n\n\n\n\n\n20.1.1.4 Highlights\nHighlights are useful when you want to focus on some of the data by showing it in colour and setting the remainder to grey. You can do this in several ways, but the easiest is to use the gghighlight package.\ngghighlight takes a logical statement which determines which points or lines get coloured. This plot focuses on the Adelie penguins.\n\nlibrary(gghighlight)\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm, colour = species)) +\n  geom_point() +\n  gghighlight(species == \"Adelie\")\n\n\n\n\n\n20.1.2 Continuous colour/fill scales\nContinuous colour/fill scales are used for continuous variables. They can be directional or diverging.\nYou can make your own continuous colour/fill scales with scale_colour_gradient() with two colours of your choice. scale_fill_gradient2() will make a diverging scale by adding a mid-point colour.\nIt can be better to use existing colour scales. scale_fill_viridis_c() is a popular continuous scale. You can also use interpolated versions of RColorBrewer palettes with scale_fill_distiller().\nContinuous colour/fill scales also can be binned (just a a histogram bins the data on the x-axis) with scale_fill_binned(), scale_fill_viridis_b()for binned viridis palettes, or scale_colour_fermenter() for binned RColorBrewer palettes.\nThere are many examples of colour palettes in the paletteer package\n\n20.1.3 Colour blind friendly colours\nAbout 1/8 men and 1/200 women are colour blind. We need to use colour and fill palettes that are colourblind friendly. Some popular scales are not. For example, we can use the colorBlindness to simulate how this figure is perceived by people with different forms of colour vision deficiency.\n\np3 &lt;- ggplot(penguins, aes(x = flipper_length_mm, fill = species)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_discrete()\np3\n\n\n\nDefault ggplot fill.\n\n\n\n\nlibrary(colorBlindness)\ncvdPlot(p3)\n\n\n\nHow people with different types of colourblindness see the default colour scale.\n\n\n\nThat was hopeless. It won’t even print well in black and white (shown by the Desaturated panel). Let’s try a different palette.\n\np3_v &lt;- p3 + scale_fill_viridis_d()\np3_v\n\n\n\nViridis fill.\n\n\n\n\n\n\n\nHow people with different types of colourblindness see the viridis colour scale.\n\n\n\nBetter. Always test that your colour palette is colourblind friendly, or use one known to be ok."
  },
  {
    "objectID": "120_colour_shape_linetypes.html#transparency",
    "href": "120_colour_shape_linetypes.html#transparency",
    "title": "20  Colours, shapes and linetypes",
    "section": "\n20.2 Transparency",
    "text": "20.2 Transparency\nTransparency is set by the alpha aesthetic, where 0 is completely transparent and 1 is opaque. The overlap between partially transparent objects is more opaque.\n\n\n\n\nAlpha values\n\n\n\nYou can map a variable to alpha in aes(), but it is probably more common to set alpha. This is very useful, for example, when there are many overlapping points in a scatterplot, or you want to see the data behind the confidence interval of a regression line (Section 21.2). Be careful using transparency when different colours overlap, as it can appear to make a third colour."
  },
  {
    "objectID": "120_colour_shape_linetypes.html#shapes",
    "href": "120_colour_shape_linetypes.html#shapes",
    "title": "20  Colours, shapes and linetypes",
    "section": "\n20.3 Shapes",
    "text": "20.3 Shapes\nYou can change the shape of all the points made by, for example, geom_point() by setting the shape.\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(shape = 4)\n\n\n\n\nIf you map a discrete variable to the shape aesthetic, points made by geom_point(), geom_pointrange(), etc will have different shaped points for the different values in the variable. Many of the shapes are difficult to distinguish when small, so it is usually best to use shape with colour to distinguish groups. These are the available shapes.\n\n\n\n\nShapes\n\n\n\nShapes 21-24 take a fill and a colour aesthetic, whereas all the other shapes just take colour.\nIf you want to change the shape from the default shapes, use scale_shape_manual().\n\nggplot(penguins, \n       aes(x = body_mass_g, y = bill_length_mm, colour = species, shape = species)) +\n  geom_point() +\n  scale_shape_manual(values = c(Adelie = 17, Chinstrap = 6, Gentoo = 16))"
  },
  {
    "objectID": "120_colour_shape_linetypes.html#linetypes",
    "href": "120_colour_shape_linetypes.html#linetypes",
    "title": "20  Colours, shapes and linetypes",
    "section": "\n20.4 linetypes",
    "text": "20.4 linetypes\nYou can change the line types of all the lines made by, for example, geom_line() by setting the linetype.\n\nggplot(ChickWeight, aes(x = Time,\n                        y = weight, \n                        group = Chick,\n                        colour = Diet)) +\n  geom_line(linetype = \"dashed\")\n\n\n\n\nIf you map a discrete variable to the linetype aesthetic, lines made by geom_line, geom_path, etc will have different line types or the different values in the variable. Line types can sometimes be used in addition to colour to make it easier to differentiate lines.\n\nggplot(ChickWeight, aes(x = Time, y = weight, group = Chick, colour = Diet, linetype = Diet)) +\n  geom_line()\n\n\n\n\nIf you need to change the linetypes assigned to each value, you can use scale_linetype_manual and specify them by name (Figure 20.1).\n\n\n\n\nFigure 20.1: Some named linetypes\n\n\n\nCustom linetypes can also be made using of up to eight hexadecimal digits (1-9, A-F) that give the length of lines and gaps. \"1FFF\" would draw a dot followed by a long gap, a long line, and another long gap, and then the pattern would repeat.\n\n\n\n\nContributors\n\nAud Halbritter\nRichard Telford"
  },
  {
    "objectID": "125_ggplot_regression.html#regression-lines-with-geom_smooth",
    "href": "125_ggplot_regression.html#regression-lines-with-geom_smooth",
    "title": "\n21  Regression and ggplot\n",
    "section": "\n21.1 Regression lines with geom_smooth()\n",
    "text": "21.1 Regression lines with geom_smooth()\n\ngeom_smooth() adds a regression line to a plot. By default it uses a loess smooth when there are fewer than 1000 observations, and a GAM when there are more. The grey band around the regression line is the confidence interval. It can be turned off with se = FALSE, and changed from the default 95% with the level argument.\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point() + \n  geom_smooth()\n\n\n\n\nYou can change they type of regression model used by geom_smooth() with the method argument. So to show a linear model, use method = \"lm\".\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\nTo show a glm, we need to method = \"glm\" and set the family in the method.args argument.\n\ndata(SWAP, package= \"rioja\")\nswap_data &lt;- bind_cols(pH = SWAP$pH, SWAP$spec)\n\nggplot(swap_data, aes(x = pH, y = sign(TA003A))) + # sign converts data to presence absence\n  geom_jitter(width = 0, height = 0.1) +\n  geom_smooth(\n    method = \"glm\", \n    method.args = list(family = binomial)) +\n  scale_y_continuous(breaks = c(0, 1)) +\n  labs(y = expression(italic(Tabellaria~binalis)))"
  },
  {
    "objectID": "125_ggplot_regression.html#sec-manual-plotting-of-a-linear-model",
    "href": "125_ggplot_regression.html#sec-manual-plotting-of-a-linear-model",
    "title": "\n21  Regression and ggplot\n",
    "section": "\n21.2 Manual plotting of a linear model",
    "text": "21.2 Manual plotting of a linear model\nWe can also fit a regression model and make predictions. This is most useful for more complex models. For example, if we want to fit a model for the relationship between penguin body mass and bill length with species as a second predictor, we can only do it this way.\nFirst fit the model\n\nmod &lt;- lm(bill_length_mm ~ body_mass_g + species, \n          data = penguins)\n\nNow we need to make predictions. We could do this with predict(), but it is often easier to use augment() from the broom package as it takes care of missing values better.\n\n#preds &lt;- predict(mod, interval = \"confidence\", conf.level = 0.95)\n\n# augment with a lm model\npreds &lt;- broom::augment(mod, interval = \"confidence\",  conf.level = 0.95)\n\nNow we can plot them, using geom_ribbon() and geom_line() to recreate what geom_smooth() produces.\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm, fill = species)) +\n  geom_point(aes(colour = species)) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper), data = preds, alpha = 0.3) +\n  geom_line(aes(y = .fitted, colour = species), data = preds) + \n  labs(x = \"Body mass g\", y = \"Bill length mm\")"
  },
  {
    "objectID": "125_ggplot_regression.html#manual-plotting-of-generalised-linear-models",
    "href": "125_ggplot_regression.html#manual-plotting-of-generalised-linear-models",
    "title": "\n21  Regression and ggplot\n",
    "section": "\n21.3 Manual plotting of generalised linear models",
    "text": "21.3 Manual plotting of generalised linear models\nWith a generalised linear model, it is a little more complex as we can get the predictions on the response scale or the transformed link scale. If we want confidence intervals, we need to calculate them on the link scale and then transform them back to the response scale.\nWith a poisson model, we can transform the predictions from the link scale to the response scale with the exponential function exp().\nWith a binomial model, we need to reverse the logit function. The easiest way to do this is with plogis().\n\nmod_glm &lt;- glm(sign(TA003A) ~ pH, data = swap_data, family = binomial)\n\npreds_glm &lt;- broom::augment(mod_glm, type.predict = \"link\", se_fit = TRUE) |&gt; \n  mutate(\n    fitted = plogis(.fitted), \n    lower = plogis(.fitted + .se.fit * 1.96),\n    upper = plogis(.fitted - .se.fit * 1.96),\n  )\n\nNow we can plot the predictions.\n\nggplot(swap_data, aes(x = pH, y = sign(TA003A))) + # sign converts data to presence absence\n  geom_jitter(width = 0, height = 0.1) +\n  geom_ribbon(aes(ymax = upper, ymin = lower, y = NULL),\n              data = preds_glm, alpha = 0.3) +\n  geom_line(aes(y = fitted),\n              data = preds_glm) +\n  scale_y_continuous(breaks = c(0, 1)) +\n  labs(y = expression(italic(Tabellaria~binalis)))"
  },
  {
    "objectID": "125_ggplot_regression.html#mixed-effect-models",
    "href": "125_ggplot_regression.html#mixed-effect-models",
    "title": "\n21  Regression and ggplot\n",
    "section": "\n21.4 Mixed effect models",
    "text": "21.4 Mixed effect models\nComming soon …\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "130_patchwork.html",
    "href": "130_patchwork.html",
    "title": "22  Combining plots",
    "section": "",
    "text": "We often need to combine plots to make a multipart figure in a manuscript or thesis.\nFirst, check you actually need to combine plots and cannot use facets instead. Typically, use facets if the x-axis variable is the same for all plots and the plots use the same geoms.\nPlots can be combined using the patchwork package.\n\nlibrary(patchwork)\n\nStart by making some plots\n\np1 &lt;- ggplot(penguins, aes(x = species, y = bill_length_mm)) +\n  geom_boxplot()\np2 &lt;- ggplot(penguins, aes(x = body_mass_g, y = bill_length_mm, colour = species)) +\n  geom_point()\np3 &lt;- ggplot(penguins, aes(x = body_mass_g, y = bill_length_mm, colour = species)) +\n  geom_point() +\n  facet_wrap(~ species)\np4 &lt;- ggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar()\n\nThe simplest way to use patchwork is to + to combine the plots. patchwork will try to make the combined figure square.\n\np1 + p2 + p3 + p4\n\n\n\n\nWith | (side by side) \\ (over under), you can have more control.\n\n(p1 | p2  | p4) / p3\n\n\n\n\nplot_layout gives you control over the relative size of the plot and whether the legends should be combined if possible.\n\n(p1 | p2  | p4) / p3 + \n  plot_layout(heights = c(2, 1), guides = \"collect\")\n\n\n\n\nIf you want to change all the plots in the combined figure, you can add a ggplot2 function with &.\n\n(p1 | p2  | p4) / p3 + \n  plot_layout(heights = c(2, 1), guides = \"collect\") &\n  theme(panel.grid = element_blank())\n\n\n\n\nYou can also overlay figures, which might be useful to show an inset map.\n\nlibrary(rnaturalearth)\nlibrary(sf)\n\n# map data inset\neurope &lt;- ne_countries(scale = 110, continent = \"Europe\", returnclass = \"sf\")\n\n# map data main map\nsvalbard &lt;- ne_countries(scale = 50, country = \"Norway\", returnclass = \"sf\") |&gt;  \n   st_crop(c(xmin = 0, xmax = 34, ymin = 76, ymax = 81))\n\n# bounding box main map\nbb &lt;- svalbard |&gt; \n  st_bbox()\n\n#inset map\neuro_map &lt;- ggplot() +\n  geom_sf(data = europe) +\n  # annotate bounding box\n  annotate(geom = \"rect\", \n           xmin = bb$xmin, xmax = bb$xmax, ymin = bb$ymin, ymax = bb$ymax, \n           fill = \"red\", alpha = 0.3) +\n  coord_sf(xlim = c(-25, 40), y = c(50, 82)) +\n  ggthemes::theme_map() +\n  theme(\n  #give white background and black border\n    panel.background = element_rect(fill = \"white\", colour = \"black\"), \n    plot.margin = margin() #remove margins\n  )\n\n# main map\nsvalbard_map &lt;- ggplot() +\n  geom_sf(data = svalbard)\n\n# combined map\nsvalbard_map + \n  inset_element(euro_map, \n                left = 0.7, \n                right = 0.99, \n                top = 0.4, \n                bottom = 0.01)\n\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\npatchwork package\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "140_maps.html#vector-base-maps",
    "href": "140_maps.html#vector-base-maps",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.1 Vector base maps",
    "text": "23.1 Vector base maps\n\n23.1.1 rnaturalearth\n\nThe rnaturalearth package makes Natural Earth data available. Natural Earth features include coastlines, rivers, bathymetry, political borders, roads and railways at scales 1:10m, 1:50m, and 1:110 million. The low-resolution (1:110 million) coastline and country data, suitable for world maps, are included in the rnaturalearth package. The rnaturalearthdata package, also on CRAN, contains medium-resolution data. High-resolution (1:10 million) data are in the rnaturalearthhires package, instructions for installing this are below.\n\nlibrary(rnaturalearth)\n\nworld &lt;- ne_countries(scale = 110, returnclass = \"sf\") \nsmall_scale_map &lt;- ggplot() +\n  geom_sf(data = world) +\n  coord_sf(xlim = c(-20, 50), ylim = c(33, 80)) +\n  ggtitle(\"Europe\")\n\neurope &lt;- ne_countries(scale = 50, returnclass = \"sf\", continent = \"Europe\") \nmedium_scale_map &lt;- ggplot() +\n  geom_sf(data = europe) +\n  coord_sf(xlim = c(5, 30), ylim = c(55, 71)) +\n  ggtitle(\"Norden\")\n\n# Need extra package for high resolution data\n# install.packages(\"rnaturalearthhires\", repos = \"https://ropensci.r-universe.dev\")\n\nnorway &lt;- ne_countries(scale = 10, returnclass = \"sf\", country = \"Norway\") \n\nlarge_scale_map &lt;- ggplot() +\n  geom_sf(data = norway) +\n  coord_sf(xlim = c(4, 9), ylim = c(59, 62)) +\n  ggtitle(\"Vestland\")\n\n# combine maps with patchwork\nlibrary(patchwork)\nsmall_scale_map + medium_scale_map + large_scale_map\n\n\n\n\ncoord_sf() is used to show only part of the map.\n\n\n\n\n\n\nsf and sp packages\n\n\n\nsf and sp are both packages for geospatial data. sf is the newer package that supports the “simple features” standard and is what I strongly recommend.\n\n\n\n\n\n\n\n\nRivers and lakes\n\n\n\nSometimes the coastline and national borders are sufficient. Sometimes they aren’t very informative and you want to add more features, such as rivers, lakes and cities. This can be done with data from Natural Earth (or other sources). Natural Earth datasets can be downloaded directly from the website or with ne_download()\n\n# download if needed\nif(!file.exists(\"maps/ne_10m_rivers_europe.shp\")){\n  ne_download(scale = 10, type = \"rivers_lake_centerlines\", category = \"physical\", \n            destdir = \"maps/\", load = FALSE) # major rivers\n  ne_download(scale = 10, type = \"lakes\", category = \"physical\", \n            destdir = \"maps/\", load = FALSE) # major lakes\n}\n\nrivers &lt;- ne_load(scale = 10, type = \"rivers_lake_centerlines\", destdir = \"maps\", returnclass = \"sf\")\nlakes &lt;- ne_load(scale = 10, type = \"lakes\", destdir = \"maps\", returnclass = \"sf\")\n\nggplot() +\n  geom_sf(data = europe) +\n  geom_sf(data = rivers, colour = \"blue\", linewidth = 0.2) + \n  geom_sf(data = lakes, fill = \"lightblue\") + \n  coord_sf(xlim = c(5, 30), ylim = c(55, 71))\n\n\n\nFigure 23.1: Lakes and rivers\n\n\n\nExtra rivers and lakes for Europe and N. America are available from Natural Earth, but for a large-scale map, other data sets may be better, for example from Noregs vassdrags- og energidirektorat.\n\n\n\n23.1.2 ggOceanMaps\n\nggOceanMaps is, as the name suggests, focused on ocean map, with coastlines, bathymetry and also glaciers. ggOceanMaps requires ggOceanMapsData, which needs to be installed separately. You do not need to load ggOceanMapsData wih library()\n\nremotes::install_github(\"MikkoVihtakari/ggOceanMapsData\")\n\nNow ggOceanMaps is ready to use.\n\nlibrary(ggOceanMaps)\n#limits are given longitude min/max, latitude min/max\nbasemap(limits = c(-30, 30, 50, 80),\n        bathymetry = TRUE,\n        glaciers = TRUE)\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nMake a map of Svalbard using either rnaturalearth or ggOceanMaps.\n\n\n\n23.1.3 Other vector files\nThe maps in rnaturalearth and ggOceanMaps are good and the global and regional scale, but lack resolution for local scale maps, and may lack features we are interested in.\nFor such maps we need to find alternative resources. These could be a shapefile, GeoJSON or GeoPackage file, all of which can be imported with sf::st_read().\n\n\n\n\n\n\nShapefiles\n\n\n\nA “shapefile” is not one file but collection of several files in the same directory, only of which has the extension “.shp”.\n\n\nGood sources of data for Norway include:\n\nGeoNorge\nMiljødirektoratet\n\nThis is a map of the fylke of Norway.\n\nlibrary(sf)\n\nLinking to GEOS 3.6.2, GDAL 2.2.3, PROJ 4.9.3; sf_use_s2() is TRUE\n\n# https://kartkatalog.geonorge.no/metadata/norske-fylker-og-kommuner-illustrasjonsdata-2021-klippet-etter-kyst/f08fca3c-33ee-49b9-be9f-028ebba5e460\n# This map will be out of date when fylker are reorganised\nfylker &lt;- st_read(\"data/fylker2021.json\")\n\nReading layer `fylker2021' from data source \n  `/home/gbsrt/Documents/teaching/biostats-1/WorkingInR/data/fylker2021.json' \n  using driver `GeoJSON'\nSimple feature collection with 11 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -77298.97 ymin: 6448400 xmax: 1115097 ymax: 7939977\nProjected CRS: 25833\n\nggplot(fylker) + \n  geom_sf()\n\n\n\n\n\n\n\n\n\n\nCoordinate reference systems\n\n\n\nMost geographic data are given with latitude and longitude, but sometimes, especially for local-regional maps, the data are given as Universal Transverse Mercator (UTM) coordinates instead.\nUTM coordinates are a projection of the spherical Earth onto one of 60 flat surfaces.\nMost modern latitude-longitude data will use the WGS84 geodetic standard. Older data might use other standards.\nYou can find the coordinate system of a sf class object with sf::st_crs().\n\nsf::st_crs(fylker)\n\nCoordinate Reference System:\n  User input: 25833 \n  wkt:\nPROJCS[\"ETRS89 / UTM zone 33N\",\n    GEOGCS[\"ETRS89\",\n        DATUM[\"European_Terrestrial_Reference_System_1989\",\n            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n                AUTHORITY[\"EPSG\",\"7019\"]],\n            TOWGS84[0,0,0,0,0,0,0],\n            AUTHORITY[\"EPSG\",\"6258\"]],\n        PRIMEM[\"Greenwich\",0,\n            AUTHORITY[\"EPSG\",\"8901\"]],\n        UNIT[\"degree\",0.0174532925199433,\n            AUTHORITY[\"EPSG\",\"9122\"]],\n        AUTHORITY[\"EPSG\",\"4258\"]],\n    PROJECTION[\"Transverse_Mercator\"],\n    PARAMETER[\"latitude_of_origin\",0],\n    PARAMETER[\"central_meridian\",15],\n    PARAMETER[\"scale_factor\",0.9996],\n    PARAMETER[\"false_easting\",500000],\n    PARAMETER[\"false_northing\",0],\n    UNIT[\"metre\",1,\n        AUTHORITY[\"EPSG\",\"9001\"]],\n    AXIS[\"Easting\",EAST],\n    AXIS[\"Northing\",NORTH],\n    AUTHORITY[\"EPSG\",\"25833\"]]\n\n\nThis gives a lot of information, the most important is that the coordinate reference systems is UTM zone 33N.\nIf we need to change a coordinate reference systems, we can do that with sf::st_transform(). You need to know the EPSG code of the target reference system, or the wkt. The EPSG code for WGS84 is 4326.\n\nfylker2 &lt;- sf::st_transform(fylker, crs = 4326)\n\ngeom_sf() will automatically transform coordinate systems (if they are specified)."
  },
  {
    "objectID": "140_maps.html#tiled-basemaps",
    "href": "140_maps.html#tiled-basemaps",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.2 Tiled basemaps",
    "text": "23.2 Tiled basemaps\nTiled basemaps can be used with either ggspatial or ggmap packages. I recommend using ggspatial as it is consistent with the other mapping tools used here.\n\n\n\n\n\n\nCopyright\n\n\n\nIf you use a tiled map background, you should attribute the source (e.g., “Copyright OpenStreetMap contributors” when using an OpenStreetMap-based tiles).\n\n\n\n23.2.1 ggspatial\n\nWe can add a tiled-basemap to a plot with annotation_map_tile() (you may need to install some extra packages at this stage - R will tell you). Here, we need to use coord_sf() to set the map extent and coordinate reference system as we have not added any sf layers with geom_sf(). Downloaded tiles will be stored in the maps directory (which you may need to make first).\n\nlibrary(ggspatial)\nggplot() +\n  annotation_map_tile(\n    type = \"osm\", \n    cachedir = \"maps/\", \n    zoomin = -1) + # sets the zoom level relative to the default\n  coord_sf(\n    xlim = c(4.5, 6), \n    ylim = c(60.5, 61),\n    crs = 4326) # EPSG code for WGS84\n\n\n\n\nSeveral different types of maps are available (see rosm::osm.types()) and more can be added.\n\n\n\n\n\n\n23.2.2 ggmap\n\nThe ggmap package lets you use Google Maps and other similar maps as a basemap.\n\n\n\n\n\n\ngooglemaps\n\n\n\nggmap can use maps and satellite image from Google, but you need to register for an API key. You shouldn’t be charged unless you make a lot of maps (thousands per month).\n\n\n\nlibrary(ggmap)\n\nbergen &lt;- get_map(\n  location = c(5.24, 60.37, 5.36, 60.41), #  left/bottom/right/top\n  source = \"stamen\"           \n)\nggmap(bergen)\n\n\n\n\nMaps made with a tiled background can appear cluttered with unnecessary information. They are probably best for small areas.\n\n\n\n\n\n\nExercise\n\n\n\nMake a tiled map that shows your favourite holiday destination."
  },
  {
    "objectID": "140_maps.html#adding-data-to-the-basemap",
    "href": "140_maps.html#adding-data-to-the-basemap",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.3 Adding data to the basemap",
    "text": "23.3 Adding data to the basemap\nAfter deciding what type of base map to draw, we can add the data we want to show with the map. This can be\n\npoints, line, and polygons\nShaded political units (a cloropleth map)\nA grid of values (raster)\n\n\n23.3.1 points/lines/polygons\nPoints lines and polygons can be added to the base map. If the data are already a sf object they can be plotted with geom_sf().\n\n# aquaculture sites downloaded from Barentswatch.no/fiskinfo\naquaculture &lt;- st_read(\"data/flate-ihht-akvakulturregisteret20220928.geojson\")\n\nReading layer `flate-ihht-akvakulturregisteret20220928' from data source \n  `/home/gbsrt/Documents/teaching/biostats-1/WorkingInR/data/flate-ihht-akvakulturregisteret20220928.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1330 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 4.660283 ymin: 58.01472 xmax: 30.41932 ymax: 71.02117\nGeodetic CRS:  4326\n\n# with rnaturalearth\nggplot() +\n  geom_sf(data = europe) +\n  geom_sf(data = aquaculture, colour = \"red\") +\n  coord_sf(xlim = c(5, 30), ylim = c(55, 71))  \n\n\n\n# with ggOceanMaps\n\nbasemap(limits = c(-30, 30, 50, 80)) +\n  geom_sf(data = aquaculture, colour = \"red\")\n\n\n\n# with ggmap\nvestland &lt;- get_map(\n  location = c(4,  59, 8, 62),\n  source = \"stamen\"           \n)\n\n# needs inherit.aes = FALSE\nggmap(vestland) + \n geom_sf(data = aquaculture, colour = \"red\", inherit.aes = FALSE, linewidth = 1) # thicker lines to make visible\n\n\n\n\nAlternatively, you can make/import a tibble with the geographic data and add them to the basemap with the relevant spatially aware geom. So geom_spatial_point() rather than geom_point() and geom_spatial_path() rather than geom_path().\n\nlibrary(ggspatial)\n\n# GPS tracking data of osprey. Data from https://datadryad.org/stash/dataset/doi:10.5061%2Fdryad.w6m905qt2\nosprey &lt;- read_delim(\"maps/osprey/06982.txt\", \n                     locale = locale(decimal_mark = \",\")) |&gt; \n  janitor::clean_names()\n\n# ggOceanMaps\n\nbasemap(data = osprey) +\n  geom_spatial_path(aes(x = longitude_e, y = latitude_n, colour = speed),\n            data = osprey, linewidth = 1) +\n  labs(colour = expression(Speed~km~h^{-1}))\n\n\n\nFigure 23.2: Flight speed of a migrating osprey\n\n\n\ngeom_spatial_point() assumes that the data are latitude-longitude coordinates. It they are UTM, you will need to use the crs argument with the correct EPSG code.\n\n\n\n\n\n\ngeom_path() vs geom_line()\n\n\n\ngeom_path() draws a line from the first point in the dataset to the second and so on. This is useful for plotting on maps with geom_spatial_path().\ngeom_line() draws a line from the left-most point to the next left-most point in the dataset. This is useful for plotting timeseries.\n\n\n\n\n\n\n\n\nDegrees minutes and seconds\n\n\n\nFor latitude-longitude data, we recommend using decimal degrees (Bergen is at 60.3807°N, 5.3323°E). But archived data can be in all sorts of unhelpful formats, such as degrees minutes and seconds (Bergen is at 60° 22’ 50.52” N 5° 19’ 56.28” E). If you get data like this, you need to convert it to decimal degrees. The parzer package can help (it is like lubridate for latitude-longitude data). For example:\n\nparzer::parse_lat(\"60° 22' 50.52''N\")\n\n[1] 60.3807\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nOtters (Lutra lutra) have re-established in Vestland. File ExcelExport_7972978_Page_1a.xlsx, (from https://artsobservasjoner.no, edited to remove an invalid unicode character) shows observations of otters in Vestland. Make a map of the observations. Relevant columns are “East Coord”, “North Coord”. The coordinates are UTM zone 33N, EPSG code 25833.\n\n\n\n23.3.2 Cloropleth maps\nCloropleth maps are useful for plotting data that have been aggregated to a geographic unit (kommune, fylke, country etc). A sf object is a special type of data frame that we can filter(), mutate() or left_join() to other data frames. We need a tibble with the data that we can join to the sf object with the geographic units. Here, I use data on 2021 phosphorous discharge in municipal wastewater from SSB and join it by Fylkesnummer, and plot it by setting fill in the aes.\n\np_discharge &lt;- readxl::read_excel(path = \"data/05280_20230421-012359.xlsx\",\n                                  skip = 4, n_max = 11) |&gt;\n  janitor::clean_names() |&gt; \n  separate_wider_regex(\n    cols = x1, # split fist column\n    patterns = c(Fylkesnummer = \"\\\\d{2}\", \" \", Fylkesnavn = \".*\"))# using regular expressions\n# \\\\d{2} = 2 numbers, \" \" = space, \".*\" = any number of any character, ie everything else\n\n# join to fylker\nfylker_discharge &lt;- fylker |&gt; \n  left_join(p_discharge, by = \"Fylkesnummer\")\n\nggplot(fylker_discharge) +\n  geom_sf(aes(fill = total_discharge)) +\n  labs(fill = \"Wastewater\\nP discharge\\n(tonnes)\")\n\n\n\nFigure 23.3: Total phosphate discharge in municipal wastewater by fylke.\n\n\n\n\n\n\n\n\n\nCartograms\n\n\n\nSometimes cloropleth maps can be misleading. An alternative is to warp space so that the area of each region is proportional to the value. This is a cartogram, which can be made with the cartogram package.\n\nlibrary(cartogram)\n\n# simplify sf object for speed\nfylker_discharge_sim &lt;- sf::st_simplify(fylker_discharge, dTolerance = 1000)\n\n# make cartogram\nkart &lt;- cartogram_cont(fylker_discharge_sim, weight = \"total_discharge\", itermax = 5)\n\n# plot cartogram\nggplot(kart) +\n  geom_sf(aes(fill = total_discharge)) +\n  labs(fill = \"Wastewater\\nP discharge\\ntonnes\") +\n  theme(legend.position = c(.99, .01), \n        legend.justification = c(1, 0))\n\n\n\nFigure 23.4: Cartogram showing total phosphate discharge in municipal wastewater by fylke.\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWith rnaturalearth data, make a world map that shows the population (column pop_est) of each country.\n\n\n\n23.3.3 Rasters\nRasters can be used to show maps of continuous data, for example, elevation or sea surface temperature, or model predictions. Depending on the extent, you might not need a separate basemap.\n\n23.3.4 terra\n\nThe terra package can import raster images in several formats, including GeoTIFF.\n\n\n\n\n\n\nterra vs raster vs stars packages\n\n\n\nThe terra package is an update to the widely-used raster package. It should be faster and easier to use. terra can integrate with ggplot2 with tidyterra.\nstars is designed for spatio-temporal arrays. There are some things it cannot do that terra can (and vice versa). It has good integration with sf and ggplot2.\n\n\nRasters imported with terra are easy to plot with the base R plot() function, but if we want to use ggplot(), it is easiest to use a geom from the tidyterra package.\n\nlibrary(terra)\nlibrary(tidyterra)\n\n# import digital elevation model\n# data from https://topotools.cr.usgs.gov/gmted_viewer/viewer.htm\nnorway_dem &lt;- rast(\"data/50N000E_20101117_gmted_med300.tif\")\n\n# make coastline mask\ncoast_vector &lt;- fylker |&gt; \n  # transfrom to crs of raster\n  st_transform(crs = terra::crs(norway_dem)) |&gt; \n  # convert to spatVector\n  vect()  \n\n# crop to vestland and rename the data layer\nvestland_extent &lt;- ext(4.5, 9, 59, 62)\nvestland_dem &lt;- crop(norway_dem, vestland_extent) |&gt; \n  mask(coast_vector) |&gt; \n  rename(Elevation = `50N000E_20101117_gmted_med300`)\n\n# plot\nggplot() +\n  geom_spatraster(data = vestland_dem) +\n  scale_fill_viridis_c(na.value = \"grey90\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(fill = \"Elevation, m\")"
  },
  {
    "objectID": "140_maps.html#scalebars-north-pointer-etc",
    "href": "140_maps.html#scalebars-north-pointer-etc",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.4 Scalebars, north pointer etc",
    "text": "23.4 Scalebars, north pointer etc\nScalebars and north pointers can be added with the ggspatial package or the ggsn package. North points are not always very useful if the map has gridlines as these already indicate north. A scalebar can be useful, especially for large scale map. On small scale maps, they can be inaccurate as the scale varies.\n\n# with rnaturalearth\nggplot() +\n  geom_sf(data = norway) +\n  coord_sf(xlim = c(4, 9), ylim = c(59, 62)) +\n  annotation_scale(location = \"br\") # br = bottom right\n\nScale on map varies by more than 10%, scale bar may be inaccurate"
  },
  {
    "objectID": "140_maps.html#hints-for-maps",
    "href": "140_maps.html#hints-for-maps",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.5 Hints for maps",
    "text": "23.5 Hints for maps\nKeep it simple. Remove unnecessary features (do you really need to show the bathymetry?) and use appropriate scale data for the base map (too high resolution takes a long time to plot and can look worse).\nUse facets as necessary (different species, different years etc).\nIf you need multiple colour scales, the ggnewscale package can help. Use inset maps (Chapter 22) to show your location in context."
  },
  {
    "objectID": "140_maps.html#projections",
    "href": "140_maps.html#projections",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.6 Projections",
    "text": "23.6 Projections\nThe Earth is an oblate sphere and needs projecting to plot in two dimensions. This inevitably leads to distortions, especially for maps with a large extent. Different projections have different properties and may be suitable for different purposes or regions. ggOceanMaps can automatically select a projection based on the location, otherwise the map projection can be set using coord_sf().\nThe projection wizard can help choose a projection for a given area (copy the PROJ string).\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\ndefault &lt;- ggplot(world) + geom_sf()\n\nmollweide &lt;- ggplot(world) + # Equal-area world map projection\n  geom_sf() + \n  coord_sf(crs = \"+proj=moll\") # projection specified with a 'proj' string\n\nsf_use_s2(FALSE) # might need to turn spherical geometry off for some projections\n\nSpherical geometry (s2) switched off\n\npolar_lambert &lt;-  world |&gt; \n  # !important - don't crop to tightly or crop lines will show in plot\n  st_crop(y = c(xmin = -180, ymin = 50, xmax = 180, ymax = 90)) |&gt; \n  ggplot() + # Transverse cylindrical equal-area\n  geom_sf() +\n  # projection specified with a proj string\n  coord_sf(crs = '+proj=laea +lon_0=14.4140625 +lat_0=90 +datum=WGS84 +units=m +no_defs', \n           ylim = c(100000, -3500000), # xlim/ylim in units of projection\n           xlim = c(-2000000, 2000000)) # here in metres\n\nalthough coordinates are longitude/latitude, st_intersection assumes that they\nare planar\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\ndefault/mollweide/polar_lambert\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nChange the projection of one of the small-scale maps you made previously."
  },
  {
    "objectID": "140_maps.html#interactive-maps",
    "href": "140_maps.html#interactive-maps",
    "title": "\n23  Making maps in R\n",
    "section": "\n23.7 Interactive maps",
    "text": "23.7 Interactive maps\nInteractive maps are traditionally used in theses and papers, but can be very useful on webpages and shiny apps.\nThe leaflet package is good for fully interactive maps.\n\nlibrary(leaflet) # NB uses pipes |&gt; not +\n\nleaflet() |&gt;  # initialise map\n  setView(lng = 5.3, lat = 60.4, zoom = 9) |&gt; # set initial map area\n  addTiles() |&gt; # add background map\n  addPolygons(data = aquaculture, popup = aquaculture$name)  # add fish farms\n\n\nFigure 23.5: leaflet map showing fish farms. You can zoom and pan the map, or click to get the fish farm name.\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nSpatial Data Science\nVisualizing geospatial data\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "050_missing_values.html#data-handling-with-missing-values",
    "href": "050_missing_values.html#data-handling-with-missing-values",
    "title": "\n24  Handling missing values\n",
    "section": "\n24.1 Data handling with missing values",
    "text": "24.1 Data handling with missing values\n\n24.1.1 Detecting missing values\nNA values can be detected with the function is.na() (NB lower case).\n\nx &lt;- c(0, 7, NA)\nis.na(x)\n\n[1] FALSE FALSE  TRUE\n\n\nWe could use this, for example, to find the number of missing values in a column of the penguins data.\n\npenguins |&gt; \n  summarise(n_missing = sum(is.na(bill_length_mm)))\n\n# A tibble: 1 × 1\n  n_missing\n      &lt;int&gt;\n1         2\n\n\n\n24.1.2 Importing data with missing values\nWhen you import a text file (e.g., a csv file) any blank cells, or cells with “NA” will be treated as NA. If you have coded missing values as something else, you can use the na argument to read_delim()\n\n# set blank cells, \"NA\" or \"missing\" to NA  \nread_delim(file = \"my_file.csv\", na = c(\"\", \"NA\", \"missing\"))\n\nIn readxl::read_excel(), the default for the na argument is just for blank cells to be made NA, but other values can be added in the same way as in read_delim().\n\n24.1.3 Removing rows with missing values\nWe can remove rows with NA in particular columns from a data frame using drop_na(). For example, to remove rows in the penguins data set with an NA in the bill_length_mm or bill_depth_mm columns, we could use\n\npenguins |&gt; \n  drop_na(bill_length_mm, bill_depth_mm)\n\n# A tibble: 342 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 339 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nAlternatively, we can use filter() and is.na(). This is most useful when removing NA is one of several arguments to filter.\n\npenguins |&gt; \n  filter(species == \"Gentoo\", !is.na(bill_length_mm))\n\n# A tibble: 123 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo  Biscoe           46.1          13.2               211        4500\n2 Gentoo  Biscoe           50            16.3               230        5700\n3 Gentoo  Biscoe           48.7          14.1               210        4450\n# ℹ 120 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\n\nna.omit\n\n\n\nYou might see some code using na.omit() to remove rows with missing values from a data frame. This can be dangerous as it will remove rows with an NA in any column, not just the columns you are interested in.\n\n\n\n24.1.4 Replacing missing values\nSometimes you want to replace NA with another value. Perhaps you want to make a plot where NA values are labelled unknown, or you know that the NA values are actually zeros, or the NA are values below the detection limit of an instrument and you want to replace these with half the detection limit.\nYou can use tidyr::replace_na() to do this.\nHere, the code replaces missing values for bill length with the mean value for bill length.\n\npenguins |&gt; \n  mutate(\n    bill_length_mm = replace_na(\n      data = bill_length_mm, \n      replace = mean(bill_length_mm, na.rm = TRUE))\n  )\n\n# A tibble: 344 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n24.1.4.1 Replacing NA in factors\nThe code in the previous section won’t work if we try to replace an NA in a factor.\n\npenguins |&gt; \n  mutate(sex = replace_na(sex, \"missing\")) |&gt; \n  distinct(sex)\n\nError in `mutate()`:\nℹ In argument: `sex = replace_na(sex, \"missing\")`.\nCaused by error in `vec_assign()`:\n! Can't convert from `replace` &lt;character&gt; to `data` &lt;factor&lt;8f119&gt;&gt; due to loss of generality.\n• Locations: 1\n\n\nAs the warning indicates, the problem is that “missing” is not one of the levels of the factor sex.\nInstead we need to use the function forcats::fct_explicit_na() (the forcats package is part of tidyverse for manipulating factors).\n\npenguins |&gt; \n  mutate(sex = fct_explicit_na(sex, na_level = \"missing\")) |&gt; \n  count(sex)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `sex = fct_explicit_na(sex, na_level = \"missing\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n\n# A tibble: 3 × 2\n  sex         n\n  &lt;fct&gt;   &lt;int&gt;\n1 female    165\n2 male      168\n3 missing    11\n\n\n\n24.1.4.2 Replacing NA with values from another vector\nSometimes you have a vector with NA and you want to replace the missing values with values from a second vector. The coalesce() can do this.\n\nx &lt;- c(NA, 2, 3, NA)\ny &lt;- c(-1, -2, -3, -4)\ncoalesce(x, y)\n\n[1] -1  2  3 -4\n\n\nHere, the first value of x is NA, so the first value of y is used. The second value of x is not NA, and so can be used. And so on.\n\n24.1.5 Setting mising values\nSome data sets use a number to represent a missing value, for example -9999. Obviously, if you do any calculations with a data set containing -9999 as a missing value, the results could be seriously wrong. Instead we need to replace these values with NA. We can do this with dplyr::na_if().\n\nx &lt;- c(1, 7, -9999)\nna_if(x, y = -9999)\n\n[1]  1  7 NA\n\n\n\n24.1.6 Missing values and dplyr filter()\n\ndplyr::filter() returns rows where the condition is strictly TRUE. This is usually what you want: if we want to filter penguins with long bills from the penguins dataset we don’t want the birds with unknown bill length.\nOccasionally we do want to keep the rows with NA. Perhaps we have a column of comments, many of which are NA, and we only want to remove rows where the non-NA values meet some criterion.\n\npenguins |&gt; \n  filter(sex == \"Female\" | is.na(sex))\n\n# A tibble: 11 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           NA            NA                  NA          NA\n 2 Adelie  Torgersen           34.1          18.1               193        3475\n 3 Adelie  Torgersen           42            20.2               190        4250\n 4 Adelie  Torgersen           37.8          17.1               186        3300\n 5 Adelie  Torgersen           37.8          17.3               180        3700\n 6 Adelie  Dream               37.5          18.9               179        2975\n 7 Gentoo  Biscoe              44.5          14.3               216        4100\n 8 Gentoo  Biscoe              46.2          14.4               214        4650\n 9 Gentoo  Biscoe              47.3          13.8               216        4725\n10 Gentoo  Biscoe              44.5          15.7               217        4875\n11 Gentoo  Biscoe              NA            NA                  NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nHere the | means OR in Boolean logic.\n\n24.1.7 Missing values and dplyr if_else() and case_when()\n\nSometimes is it useful to set values to NA with if_else() (when there is a choice of two outcomes) or case_when() (when there is a choice of two or more outcomes).\nAll possible values returned by if_else() and case_when() need to be of the same type (character, numeric, integer, logical). If the types are inconsistent, an error is produced. This is useful as forcing consistency helps avoid unexpected behaviour.\n\nx &lt;- 0:2\ncase_when(\n  x == 0 ~ NA,\n  x == 1 ~ \"One\",\n  x == 2 ~ \"Two\"\n)\n\n[1] NA    \"One\" \"Two\"\n\n\nThe problem occurs here because NA is treated as a logical vector, while the other values are characters. The solution is to use NA_character_ which is an NA with the correct type.\n\nx &lt;- 0:2\ncase_when(\n  x == 0 ~ NA_character_,\n  x == 1 ~ \"One\",\n  x == 2 ~ \"Two\"\n)\n\n[1] NA    \"One\" \"Two\"\n\n\nOther typed NA include NA_real_ for numeric values and NA_integer for integer values."
  },
  {
    "objectID": "050_missing_values.html#statistics-with-missing-values",
    "href": "050_missing_values.html#statistics-with-missing-values",
    "title": "\n24  Handling missing values\n",
    "section": "\n24.2 Statistics with missing values",
    "text": "24.2 Statistics with missing values\n\n24.2.1 NA arithemetic\nWhat is five plus an unknown number? The answer is, of course, unknown.\n\n5 + NA\n\n[1] NA\n\n\nNA are contagious in calculations: if one value is NA the result is NA. This effects many descriptive statistics.\n\nx &lt;- c(1, 7, NA)\nsum(x)\n\n[1] NA\n\nmean(x)\n\n[1] NA\n\nmin(x)\n\n[1] NA\n\n\nThe solution is to use the na.rm argument to these functions to exclude the NA from the calculation.\n\nsum(x, na.rm = TRUE)\n\n[1] 8\n\nmean(x, na.rm = TRUE)\n\n[1] 4\n\nmin(x, na.rm = TRUE)\n\n[1] 1\n\n\n\n24.2.2 NA in correlations and covariances\nThe functions for calculating correlation, cor(), and covariance, cov(), work a little differently as these functions can work on two vectors or on a matrix or data frame. The use argument is used to control how NA are treated.\nBy default, if any values are NA in either vector, the result is also NA. If you want to find the correlation between two vectors without the NA, then use\n\ncor(x = penguins$bill_length_mm,\n    y = penguins$bill_depth_mm, \n    use = \"pairwise.complete.obs\")\n\n[1] -0.2350529\n\n\nIf you have a matrix (or data frame), and want to calculate a correlation matrix, then use = \"complete.obs\" will calculate this using just the rows that have no NA, and use = \"pairwise.complete.obs\" will calculate the correlation between each pair of variables using all complete pairs of observations on those variables.\n\npenguins |&gt; \n  select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) |&gt; \n  cor(use = \"pairwise.complete.obs\") \n\n                  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\nbill_length_mm         1.0000000    -0.2350529         0.6561813   0.5951098\nbill_depth_mm         -0.2350529     1.0000000        -0.5838512  -0.4719156\nflipper_length_mm      0.6561813    -0.5838512         1.0000000   0.8712018\nbody_mass_g            0.5951098    -0.4719156         0.8712018   1.0000000\n\n\n\n24.2.3 Missing values and regession models\nBy default regression models such as lm(), glm(), and lmer() remove any case that has an NA in either the response or predictors. This behaviour is controlled by the na.action argument. This is great if we are interested in the model coefficients, but it can cause problems if there are NA in the data and we want to add the residuals, fitted values, or predictions into the original data frame for plotting.\n\nmod &lt;- lm(bill_length_mm ~ body_mass_g, data = penguins)\n\npenguins |&gt; mutate(fit = fitted(mod))\n\nError in `mutate()`:\nℹ In argument: `fit = fitted(mod)`.\nCaused by error:\n! `fit` must be size 344 or 1, not 342.\n\n\nThe problem is that there are fewer observation in the model (which omitted the NA) than the original data frame (which still has them).\nWe can make this work by using na.action = na.exclude which will pad the fitted values with NA so that it is the same length as the original data.\n\nmod &lt;- lm(bill_length_mm ~ body_mass_g, data = penguins, na.action = na.exclude)\n\npenguins |&gt; mutate(fit = fitted(mod))\n\n# A tibble: 344 × 9\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n# ℹ 341 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, fit &lt;dbl&gt;\n\n\nWith na.exclude the NA are still excluded from the model fitting - most models do not allow NA values.\nWhen comparing models, for example with anova(), all models need to have been fit to the same dataset. This can cause problems if NA have caused different numbers of observations to be removed.\n\nmod2 &lt;- lm(bill_length_mm ~ body_mass_g + sex, data = penguins, na.action = na.exclude)\n\nanova(mod, mod2)\n\nError in anova.lmlist(object, ...): models were not all fitted to the same size of dataset\n\n\nThe easiest solution is to remove rows with NA in any predictor before fitting any of the models.\n\n24.2.4 Imputing missing values\nAs shown above, observations with missing values are omitted from the model. If a predictor has many missing values, it may be better to exclude the predictor from the model to avoid losing too many observations.\nAn alternative is to impute the missing data. This should be done with caution as it can bias the results, especially if a substantial proportion of the data are imputed. On the other hand, if missing data are not randomly distributed, omitting observations with missing data can also bias the results.\nThere are several ways that can be used to impute missing values.\nThe simplest is to replace a the missing value with the mean or median of the variable as shown in Section 24.1.4.\nMore complex methods use the multivariate relationship between predictors to estimate the missing values. Several R packages can help with this, e.g., mice. Yadav and Roychoudhury (2018) compare the performance of some popular methods."
  },
  {
    "objectID": "050_missing_values.html#missing-values-and-ggplot2",
    "href": "050_missing_values.html#missing-values-and-ggplot2",
    "title": "\n24  Handling missing values\n",
    "section": "\n24.3 Missing values and ggplot2\n",
    "text": "24.3 Missing values and ggplot2\n\nBy default, missing values in the x or y aesthetics are dropped by ggplot() with a warning, whereas missing values in the colour or fill aesthetics are shown in grey. This behaviour can be controlled with the na.value argument to the relevant scale_*_*() function.\n\n#x or y NA\np &lt;- tibble(\n  x = 1:5, \n  y = c(1, 2, NA, 4, 5),\n  colour = c(1, 2, 3, 4, NA)\n) |&gt; \n  ggplot(aes(x = x, y = y, colour = colour)) +\n  geom_point(size = 3)\n\np\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n# change defaults\np + \n  scale_y_continuous(na.value = 0) +\n  scale_colour_continuous(na.value = \"hotpink\")"
  },
  {
    "objectID": "050_missing_values.html#related-concepts",
    "href": "050_missing_values.html#related-concepts",
    "title": "\n24  Handling missing values\n",
    "section": "\n24.4 Related concepts",
    "text": "24.4 Related concepts\nNaN and Inf are related to NA.\n\n24.4.1 NaN\n\nNaN represents Not a Number. NaN can be generated, for example, by taking the log of a negative number. They can be tested for with is.nan()\n\nx &lt;- log(c(1, -1, NA))\n\nWarning in log(c(1, -1, NA)): NaNs produced\n\nx\n\n[1]   0 NaN  NA\n\nis.nan(x)\n\n[1] FALSE  TRUE FALSE\n\n\n\n24.4.2 Inf\nInf and -Inf represent positive and negative infinite numbers respectively. These can be generated, for example, by dividing by zero, and tested for with is.infinite()\n\nx &lt;- c(-Inf, 0, Inf)\nis.infinite(x)\n\n[1]  TRUE FALSE  TRUE\n\n\n\n24.4.3 Comparison of tests\nThe test is.finite() it TRUE if the value is numeric and not NA, NaN, Inf or -Inf.\n\n\n\n\nvalue\nis.na\nis.nan\nis.infinite\nis.finite\n\n\n\n1\nFALSE\nFALSE\nFALSE\nTRUE\n\n\nNA\nTRUE\nFALSE\nFALSE\nFALSE\n\n\nNaN\nTRUE\nTRUE\nFALSE\nFALSE\n\n\nInf\nFALSE\nFALSE\nTRUE\nFALSE\n\n\n-Inf\nFALSE\nFALSE\nTRUE\nFALSE\n\n\n\n\n\n\n\n\n\nContributors\n\nRichard Telford"
  },
  {
    "objectID": "060_bestiary.html#assignment-arrows",
    "href": "060_bestiary.html#assignment-arrows",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.1 Assignment arrows",
    "text": "25.1 Assignment arrows\nThe usual way to assign an object to a name is to use a left-pointing arrow &lt;-.\n\nx &lt;- 42 # This will assign the value 42 to the name x\n\nThe keyboard short-cut for the assign arrow is .\nIt is also possible to use right-pointing arrows -&gt;.\n\n42 -&gt; x # This will assign the value 42 to the name x\n\nThis is not recommended because it makes code difficult to read."
  },
  {
    "objectID": "060_bestiary.html#sec-backslash",
    "href": "060_bestiary.html#sec-backslash",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.2 Backslash",
    "text": "25.2 Backslash\nSome characters cannot be directly represented in character strings so an escape sequence is used instead. Escape sequences always start with the backslash character \\.\n\n\n\\n new line\n\n\\t tab (very useful for importing tab-delimited files with read_delim)\n\n\\\\ backslash\n\n\\U1F600 including Unicode or emoji 😀\n\nIf you want to use a literal backslash in a character string, it needs to be escaped with another backslash. Note that print shows the contents of the string, including the backslashes, while cat shows what would be shows by ggplot etc.\n\nx &lt;- \"Backslash-n gives a newline\\nThis is a literal backslash '\\\\'\"\nprint(x)\n\n[1] \"Backslash-n gives a newline\\nThis is a literal backslash '\\\\'\"\n\ncat(x)\n\nBackslash-n gives a newline\nThis is a literal backslash '\\'"
  },
  {
    "objectID": "060_bestiary.html#brackets",
    "href": "060_bestiary.html#brackets",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.3 Brackets",
    "text": "25.3 Brackets\nThree different types of bracket are used in R.\nThe round brackets () are used to contain all the arguments to a function.\n\nrnorm(n = 10, mean = 10)\n\nRound brackets () are also used to force the order of operations in an calculation or Boolean logic.\n\n9 * 6 + 5 # 59\n\n[1] 59\n\n9 * (6 + 5) # 99\n\n[1] 99\n\n\nSingle square brackets [] are used for sub-setting vectors, matrices and similar objects.\n\nmonth.name[6:7] # extract the 6th and 7th element of month.name\n\n[1] \"June\" \"July\"\n\npenguins[1, \"species\"] # first element of species column (dplyr gives neater ways to do this)\n\n# A tibble: 1 × 1\n  species\n  &lt;fct&gt;  \n1 Adelie \n\n\nDouble square brackets are used to extract elements from a list\n\nx &lt;- list(a = 1, b = TRUE)\nx[1] # single square bracket returns a list - see the $a\n\n$a\n[1] 1\n\nx[[1]] # double square bracket returns element directly\n\n[1] 1\n\n\nCurly brackets or braces {} are used to keep code that needs to be run together as a single expression. This is commonly done when writing a function\n\ncylinder_volume &lt;- function(radius = 1, height){\n  radius ^ 2 * pi * height \n}\n\ncylinder_volume(height = 2)\n\nor when writing an if statement\n\nif(logical_condition){\n  #some code to run if logical_condition is TRUE\n}\n\nCurly brackets are also used in the glue package, an easy to use alternative to paste. The curly brackets demarcate R code to include in the output.\n\nglue::glue(\"The penguins dataset has {nrow(penguins)} rows\")\n\nThe penguins dataset has 344 rows\n\npaste(\"The penguins dataset has\", nrow(penguins), \"rows\") # base R alternative gets clunky fast\n\n[1] \"The penguins dataset has 344 rows\"\n\n\nDouble curly brackets {{}} are used programming with tidyverse. See the dplyr programming vignette for details."
  },
  {
    "objectID": "060_bestiary.html#boolean-operators",
    "href": "060_bestiary.html#boolean-operators",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.4 Boolean operators",
    "text": "25.4 Boolean operators\nBoolean operators are used to combine logical tests.\nIf a and b are logical vectors (i.e. TRUE and FALSE), or vectors that can be coerced to logical vectors, then\n\n\n!a NOT a\n\na & b a AND b\n\na | b a OR b\n\nBoolean operators can be combined to form complex statements. Round brackets can be used to force the order of evaluation\n\nx &lt;- 10\nx &gt; 0 | x &lt; 20  # is x between 0 and 20\n\n[1] TRUE\n\nx &gt; 0 | x &lt; 20  & x %% 2 == 1 # is x an odd number between 0 and 20. Wrong order of evaluation.\n\n[1] TRUE\n\n(x &lt; 20 | x &gt; 0)  & x %% 2 == 1 # Brackets force correct order.\n\n[1] FALSE\n\n\nIt is probably a good idea to always use brackets in statements with multiple Boolean operators to make the order of evaluation clear to the reader.\nYou will also see doubled up || and && operators. These are special Boolean operators that only return the first element of any vector of results. This is useful with if statements which want only a single TRUE or FALSE."
  },
  {
    "objectID": "060_bestiary.html#colons",
    "href": "060_bestiary.html#colons",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.5 Colons",
    "text": "25.5 Colons\nA single colon : is used to get a sequence between two values with a step size of one.\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n#equivalent to \nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nA single colon is also used when detaching a package which is almost, but not quite, the opposite of running library.\n\nlibrary(mgcv) # loads mgcv package\ndetach(\"package:mgcv\") # \n\nBecause detach is not exactly the opposite of library, it is normally better to restart the R session (In Rstudio go to ‘Session’ then ‘Restart R’).\nDouble colons :: let you use a single function from a package without loading the entire package. For example, readxl::read_excel() will run read_excel(). This can prevent conflicts between functions with the same name in different packages, or make code clearer by being explicit where a function comes from.\nTriple colons ::: are used to access a package’s internal functions. This can be useful to access the help file or to view the code, but you should not rely on the internal functions staying the same."
  },
  {
    "objectID": "060_bestiary.html#commas",
    "href": "060_bestiary.html#commas",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.6 Commas",
    "text": "25.6 Commas\nArguments in a function need to be separated by a comma.\n\nx &lt;- rnorm(n = 10, mean = 1, sd = 0.5)\n\nIf you forget to use a comma, you will get a reminder from R, and Rstudio should underline the problem.\n\nx &lt;- rnorm(n = 10, mean = 1 sd = 0.5)\n\nError: &lt;text&gt;:1:29: unexpected symbol\n1: x &lt;- rnorm(n = 10, mean = 1 sd\n                                ^\n\n\n\n\nRstudio puts a cross in the margin and underlines the unexpected text after the missing comma."
  },
  {
    "objectID": "060_bestiary.html#dot",
    "href": "060_bestiary.html#dot",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.7 Dot",
    "text": "25.7 Dot\nThe dot . is used as the decimal separator in R, for example in 3.1415927.\nObject names can have a dot in them. If the name starts with a dot, the object is invisible and won’t show up in the environment tab in Rstudio.\nDots in function names can be decorative, but can also be used by R to determine which function needs to be used for each type of object. For example, there is a summary.lm() and an anova.lm() which process lm class objects generated by the function lm(). There are also glm(), lme(), and many other versions of these functions available to process different classes of objects. When you run summary() or anova(), which are known as a generic functions, R will automatically select the correct version to use based on the class of object given. You can find out the class of an object my using the function class()."
  },
  {
    "objectID": "060_bestiary.html#section",
    "href": "060_bestiary.html#section",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.8 …",
    "text": "25.8 …\nYou will often see three dots ... in a function’s arguments. These are used when the name (and number) of arguments is not known in advance. For example, the functionc() has ... in its arguments, allowing you to put any number of objects with any names into the function to make a vector. The three dots are often used by generic functions because the different versions of the function for different classes of object need different arguments. In dplyr, the dots are used for the column names of the data frame or tibble being processed."
  },
  {
    "objectID": "060_bestiary.html#dollars",
    "href": "060_bestiary.html#dollars",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.9 Dollars",
    "text": "25.9 Dollars\nThe dollar symbol $ is used to subset lists. Many objects in R, including data frames, are special types of lists.\n\nx &lt;- list(a = 1, b = TRUE)\nx$a\n\n[1] 1\n\npenguins$species[1:3] # just the first few elements\n\n[1] Adelie Adelie Adelie\nLevels: Adelie Chinstrap Gentoo"
  },
  {
    "objectID": "060_bestiary.html#equals-sign",
    "href": "060_bestiary.html#equals-sign",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.10 Equals sign",
    "text": "25.10 Equals sign\nOne equals sign = is used to assign a value to an argument in a function\n\nrnorm(n = 10, mean = 0)\n\nOne equals sign can be used instead of the assignment arrow, but the intent of the arrow is clearer.\nTwo equals signs == are used as a test of exact equality. This test is sensitive to numerical impression in floating point numbers (numbers which have a decimal point). It can be safer to use near for numeric values as this has a built in tolerance.\n\n2 == sqrt(2) ^ 2 # see 2 - sqrt(2) ^ 2\n\n[1] FALSE\n\nnear(2, sqrt(2) ^ 2)\n\n[1] TRUE\n\n\nIt is a very common mistake to use one equals sign rather than two. filter in dplyr gives a helpful error message\n\npenguins |&gt; filter(year = 2007)\n\nError in `filter()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `year == 2007`?"
  },
  {
    "objectID": "060_bestiary.html#file-paths",
    "href": "060_bestiary.html#file-paths",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.11 File paths",
    "text": "25.11 File paths\nWhen you want to import data from or save a file to a, a directory (folder) other than the working directory (usually where you RStudio project .rproj file is), you need to specify the path.\nThe directory name need to be separated from the file name by a forwards slash /.\n\n\"my_directory/my_file.csv\"\n\nIf you use a backslash by mistake, you will get an error, because the backslash is the escape character. You will sometimes see a double backslash used as a path separator, but this is not recommended.\nYou can also use the function file.path() to generate paths to files.\n\nfile.path(\"my_directory\", \"my_file.csv\")\n\n[1] \"my_directory/my_file.csv\"\n\n\nIf you want to read a file from the directory above the working directory, you can use ../my_file.csv, where .. means go up one, but you should probably use the here package."
  },
  {
    "objectID": "060_bestiary.html#formula-notation",
    "href": "060_bestiary.html#formula-notation",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.12 Formula notation",
    "text": "25.12 Formula notation\nFormulae are mainly used in regression models, but also in plotting (base plot and facet_wrap()) and some other functions.\nFormula always have a tilde ~. The response (if any) goes to the left of the tilde, and the predictors to the right.\nOther characters that can be used in formula include * + | / : ^ which take on a different meaning from their usual meaning.\nThe following linear model has a formula that has bill length as the response and species, year, and the interaction between year and species as predictors.\n\nlm(bill_length_mm ~ species + year + species:year, data = penguins)\n\n\nCall:\nlm(formula = bill_length_mm ~ species + year + species:year, \n    data = penguins)\n\nCoefficients:\n          (Intercept)       speciesChinstrap          speciesGentoo  \n           -1.268e+02             -1.527e+02             -1.390e+03  \n                 year  speciesChinstrap:year     speciesGentoo:year  \n            8.248e-02              8.106e-02              6.963e-01  \n\n\nThis model can also be run with the following formulae with more concise notation.\n\nlm(bill_length_mm ~ species * year, data = penguins)\nlm(bill_length_mm ~ (species + year) ^ 2, data = penguins)\n\nAll give exactly the same result."
  },
  {
    "objectID": "060_bestiary.html#greater-than-and-less-than",
    "href": "060_bestiary.html#greater-than-and-less-than",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.13 Greater than and less than",
    "text": "25.13 Greater than and less than\nThe greater than &gt; and less than &lt; characters are used in logical tests.\n\npi &gt; 22/7\n\n[1] FALSE\n\n\nTo express greater than or equal, use &gt;=. &lt;=, for less than or equal.\nThe greater than sign is also used in the native pipe |&gt; (and the tidyverse pipe %&gt;%)."
  },
  {
    "objectID": "060_bestiary.html#hash",
    "href": "060_bestiary.html#hash",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.14 Hash",
    "text": "25.14 Hash\nAny text after a # is a comment.\n\n# this is a comment\n\nComments that end with four hashes are treated as section breaks by Rstudio. These are useful for navigating long scripts.\n\n#### this is a section break ####\n# Only needs one leading #, \n# but symmetry makes code more beautiful\n\nIn Rstudio you can use the keyboard short-cut  to comment or uncomment multiple lines of code at the same time.\nHashes are also used to indicate hexadecimal (base 16) numbers. These are most often used for colours, with a hash followed by three pairs of digits (0-9, A-F) representing the intensity of the red, green and blue components of the colour (a option extra pair represents alpha or transparency). Large numbers (towards FF, which is 255 when expressed as a decimal number) are more intense than low numbers.\nHere are five colours from the viridis colour scale\n\nviridisLite::viridis(n = 5)\n\n[1] \"#440154FF\" \"#3B528BFF\" \"#21908CFF\" \"#5DC863FF\" \"#FDE725FF\"\n\n\n\n\n\n\nViridis colours\n\n\n\nIf you want to make your own special colours, you can write the hexadecimal string by hand."
  },
  {
    "objectID": "060_bestiary.html#mathematical-operators",
    "href": "060_bestiary.html#mathematical-operators",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.15 Mathematical operators",
    "text": "25.15 Mathematical operators\nMathematical operators have their usual meaning:\n\n\na + b a plus b\n\n-a minus a\n\na - b a minus b\n\na * b a times b\n\na / b a divided by b\n\na ^ b a to the power b\n\nSome useful but less commonly seen operators\n\n\na %% b a remainder b (13 %% 5 = 3). Also called the modulo operator.\n\na %/% b integer division (13 %/% 5 = 2).\n\nSome of the mathematical operators are used by tidyverse and associated packages for different purposes.\nggplot2 uses + to add elements of the a plot together\n\np_box &lt;- ggplot(penguins, aes(x = species, y = bill_length_mm)) + \n  geom_boxplot() +\n  labs(x = \"Species\", y = \"Bill length mm\")\n\npatchwork uses + and / to arrange separate plots into one combined plot, and uses & to modify all the plots.\n\np_violin &lt;- ggplot(penguins, aes(x = species, y = bill_length_mm)) + \n  geom_violin() +\n  labs(x = \"Species\", y = \"Bill length mm\")\n\nlibrary(patchwork)\np_box + p_violin & \n  theme(axis.text.x = element_text(angle = 45))\n\n\n\nBoxplot and violin plot combined with patchwork"
  },
  {
    "objectID": "060_bestiary.html#percent-signs",
    "href": "060_bestiary.html#percent-signs",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.16 Percent signs",
    "text": "25.16 Percent signs\nPercent signs come in pairs and surround an infix operator. An infix operator is a special type of function that goes between two operands. For example, the integer division operator 13 %/% 5. This can be re-written as a regular function with `%/%`(13, 5)\nSome important infix operators are\n\n\n%% remainder or modulo operator\n\n%/% integer division\n\n%in% matching operator which tests if the elements of the first vector are in the second vector.\n\n\nx &lt;- c(\"January\", \"Wednesday\")\nx %in% month.name # which element of x is a name of a month\n\n[1]  TRUE FALSE\n\n#equivalent to, but much neater than\nx == \"January\" | x == \"February\" | x == \"March\" # etc\n\n[1]  TRUE FALSE\n\n\n\n\n%*% matrix multiplication\n\n%&gt;% the tidyverse pipe\n\nIf you want to get help on any infix operator, you need to surround it in backticks or you get the error unexpected SPECIAL in \"?%in%\"\n\n ?`%in%`"
  },
  {
    "objectID": "060_bestiary.html#quote-marks",
    "href": "060_bestiary.html#quote-marks",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.17 Quote marks",
    "text": "25.17 Quote marks\nStrings in R need to be surrounded by quote marks. You can use single or double quote marks. If your string contains quotes, they either need to be the opposite type from those around the string, or escaped with a backslash (see Section 25.2).\n\nx &lt;- \"cat\" # double quote marks\nx &lt;- 'cat' # single quote marks\n\nx &lt;- \"She said 'The cat.'\" # single quote marks nested in double quotes\nx &lt;- \"She said \\\"The cat.\\\"\" # escaped quote marks\n\nThe backtick ` looks a little bit like a small quote mark. They are used to enclose names that are not legal R names.\n\ntibble(`Standard Deviation` = 2)\n\n# A tibble: 1 × 1\n  `Standard Deviation`\n                 &lt;dbl&gt;\n1                    2"
  },
  {
    "objectID": "060_bestiary.html#question-marks",
    "href": "060_bestiary.html#question-marks",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.18 Question marks",
    "text": "25.18 Question marks\nUse a ? to get help on a function, for example ?lm, which is equivalent to help(lm) Or ?? to get help on a topic, for example ??\"linear models\", which is equivalent to help.search(\"linear models\").\nIf you want help on something that does not start with a letter or dot, you need to surround it in backticks, for example ?`+."
  },
  {
    "objectID": "060_bestiary.html#regular-expressions",
    "href": "060_bestiary.html#regular-expressions",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.19 Regular expressions",
    "text": "25.19 Regular expressions\nSeveral characters take on a special meaning with regular expressions, including ^ $ ? * + () [] {} :. Regular expressions are always enclosed in quote marks. See the tutorial on text manipulation for an introduction into regular expressions."
  },
  {
    "objectID": "060_bestiary.html#semi-colon",
    "href": "060_bestiary.html#semi-colon",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.20 Semi-colon",
    "text": "25.20 Semi-colon\nThe semi-colon ; can optionally be used at the end of a line of code, but there is no advantage to doing this (in other languages it can be compulsory). It can be used to separate two R statements on the same line. This is not recommended as it can make code difficult to read.\n\n# bad\ni &lt;- 7 * 6; print(i)\n\n# good\ni &lt;- 7 * 6\nprint(i)"
  },
  {
    "objectID": "060_bestiary.html#underscore",
    "href": "060_bestiary.html#underscore",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.21 Underscore",
    "text": "25.21 Underscore\nThe underscore _ can be used in object names along with alphanumeric characters and dot. It cannot be the first character of the name. It is useful as a word separator in snake_case."
  },
  {
    "objectID": "060_bestiary.html#white-space",
    "href": "060_bestiary.html#white-space",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.22 White space",
    "text": "25.22 White space\nWhite space is free and usually has no impact on how the code runs. Use lots of it to make your code more readable."
  },
  {
    "objectID": "060_bestiary.html#section-1",
    "href": "060_bestiary.html#section-1",
    "title": "25  Bestiary of Brackets and other R notation",
    "section": "\n25.23 @",
    "text": "25.23 @\nYou will occasionally see an @ in R code. They are used to subset S4 class objects, analogous to the use of $ to subset lists and data frames. Unless you are coding your own S4 classes, you probably won’t see or use @ very often. See Chapter 15 of Advanced R for more information about S4 classes.\n\n\n\n\nContributors\n\nRichard Telford"
  }
]