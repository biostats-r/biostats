[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data life cycle",
    "section": "",
    "text": "1 Introduction\nData often lives longer than a specific project. The life cycle of data includes several steps from creating data, curation to archiving, find and re-use. Researchers typically focus more on some of these stages than others. An important part of the data life cycle is to plan each step from the start.\nIn this book, we discuss what a data management plan is and then go through each of the steps of the data life cycle.\nFigure 1.1: The data life cycle.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#further-reading-and-resources",
    "href": "index.html#further-reading-and-resources",
    "title": "Data life cycle",
    "section": "\n1.1 Further reading and resources",
    "text": "1.1 Further reading and resources\nThe British Ecological Society has a guide for Data management that gives an useful overview of good data management practice and all steps of the data life cycle.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_data_managementplan.html",
    "href": "01_data_managementplan.html",
    "title": "2  Data management plan",
    "section": "",
    "text": "A data management plan (DMP) is a formal document that describes how the data in a research project is going to be collected, handled, and kept safe during and beyond the project. It is becoming more standardized to ask for DMPs in research projects and also PhD projects.\nHere are some useful resources for guides to DMPs.\nUniversity of Bergen DMP guidelines\nNorwegian Research Council DMP guidelines\nEU OpenAIRE DMP guidelines",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data management plan</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html",
    "href": "02_design-spreadsheets.html",
    "title": "3  Design spreadsheets",
    "section": "",
    "text": "3.1 Paper or digital data entry\nSpreadsheets are an important tool to enter and store data and used in every day life in science. As useful as they are, there are also many traps and problems with spreadsheets. Scientists have lost data, because of spreadsheets such as Excel convert names to dates. Being aware of such issues is key when working with spreadsheets.\nIn this chapter, we will show you best practice to design and organize tidy spreadsheets that are readable to humans and machines. We show how to design spreadsheets that makes data collection easy, that are less error-prone, work well in downstream reproducible workflows and are easy to share with others. We will often refer to downstream processing in R, but most of the recommendations given here, are applicable to any data analysis software. We recommend to apply these practices to datasets from the start, which should prevent tedious editing later. Also, we do not recommend to use spreadsheets for data analysis or visualization, because it is not reproducible.\nThe content of this page is heavily adapted from Broman and Woo (2018).\nThere are two ways data is collected. Data that is recorded from a machine and automatically stored. If you have the possibility for that, it is always recommended to make use of digital data collection. It can reduce errors. Alternatively, data is collected manually. There are multiple ways of collecting data by hand such as, on paper, digital on a notepad/phone, or recordings.\nEach of these methods have their advantages and disadvantages. If you are collecting data in remote place with harsh weather conditions, paper might be your only solution. Note that there exists rite in the rain paper. Digital data entry saves you the step of digitizing the data and therefore sources of errors. In addition, you can build in data validation for example drop down menus or a function that checks for the right range of values. This can be very useful for avoiding errors.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#content",
    "href": "02_design-spreadsheets.html#content",
    "title": "3  Design spreadsheets",
    "section": "\n3.2 Content",
    "text": "3.2 Content\nWhat information should your spreadsheet contain? This is not en exhaustive list, but gives guidance on useful information to record:\n\nID (unique ID for each observation, individual)\nDate, time, observation number\nLocation: region/site\nExperimental design: block, plot, replicate, number of observation, treatments\nOrganism: species/population/genet\nresponse variable(s)\npredictors\nrecorder/scribe\nother observations: weather\nnotes",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#data-validation-tools",
    "href": "02_design-spreadsheets.html#data-validation-tools",
    "title": "3  Design spreadsheets",
    "section": "\n3.3 Data validation tools",
    "text": "3.3 Data validation tools\nData validation is a way to reduce errors in the data and can be built in when collecting or digitizing data.\nFor example you can:\n\nset ranges for valid numbers (e.g. only positive, range between two numbers)\nonly allow whole numbers or decimals\nadd a drop down menus for categorical data\ndefine the length of text (e.g. only 8 characters)\ndefine data types (e.g. to avoid conversion to dates)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#rectangular-spreadsheet",
    "href": "02_design-spreadsheets.html#rectangular-spreadsheet",
    "title": "3  Design spreadsheets",
    "section": "\n3.4 Rectangular spreadsheet",
    "text": "3.4 Rectangular spreadsheet\nSpreadsheets should be rectangular. Best practice is to make spreadsheets completely rectangular. They should not have empty cells, rows or columns, titles or double headers.\nIt is however common to leave some rows/columns and cells empty (Figure 3.2). Also adding a title to a spreadsheet is often done. It is not best practice, but also not a big problem for the downstream processing. Contrary, having two headers with different information is more difficult to process later.\n\n\n\n\n\n\n\nFigure 3.2: An almost rectangular and tidy dataset. The note column has empty cells.\n\n\n\n\nSometimes, two datasets are combined in one spreadsheet. For example, table Figure 3.3 shows an example of pollinator observation data, which includes observations about wind. The spreadsheet also contains a separate table on the right side, showing the scale for wind. It can be useful to have the two tables in the same file, for example when entering the data. But this will be far more complicated than needed when importing the data. Here we recommend to keep these two tables in separate spreadsheets.\n\n\n\n\n\n\n\nFigure 3.3: Bad examples of spreadsheets. A) Shows two different datasets merged into one. B) Shows a series of small tables belonging to the same dataset.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#long-or-wide-format",
    "href": "02_design-spreadsheets.html#long-or-wide-format",
    "title": "3  Design spreadsheets",
    "section": "\n3.5 Long or wide format",
    "text": "3.5 Long or wide format\nDatasets can be long or wide and there is often a debate which of these formats are better (Figure 3.4). We do not have a strong opinion on this. As long as the general rules (see above and below) are followed, this does not matter very much. Many analysis require a long format, but for others (e.g. ordinations) a wide format is needed. This means that data often needs to be reshaped from long to wide and vice versa. And this is not very difficult (see reshape section).\n\n\n\n\n\n\n\nFigure 3.4: Wide (A) and long (B) data table.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#single-value-per-cell",
    "href": "02_design-spreadsheets.html#single-value-per-cell",
    "title": "3  Design spreadsheets",
    "section": "\n3.6 Single value per cell",
    "text": "3.6 Single value per cell\nTidy spreadsheets follow the following rules:\n\neach variable should be one specific column,\neach observation should be one specific row,\neach cell at the intersection of a row and a column contains a single value.\n\nImportantly, put only one value per cell (Figure 3.2).\nSometimes values are entered with their units, such as 42 g in one cell (Figure 3.5). It is better to separate the value and the unit into two columns.\nAnother common mistake is to add notes to a column (Figure 3.5). For example if a value is 0 because it is below the detection value, you could write 0 (below threshold). We recommend to only write the number in the first column and add notes on the value in a separate column called notes.\n\n\n\n\n\n\n\nFigure 3.5: Wide (A) and long (B) data table.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#consistency",
    "href": "02_design-spreadsheets.html#consistency",
    "title": "3  Design spreadsheets",
    "section": "\n3.7 Consistency",
    "text": "3.7 Consistency\nConsistency is key. There are many ways of designing a spreadsheet, and there is not always a right or a wrong. Find what works for you and stick to it.\nBe consistent for categorical variables, for example use the same spelling and not variations like: female, Female, F. Latin species names is a common problem and where typos happen very easily (Figure 3.6).\n\n\n\n\n\n\n\nFigure 3.6: Inconsistency in species names\n\n\n\n\nIf you have multiple files or datasets from the same experiment, be consistent with variable names and do not use variations like: site, location, siteID. This will make it more difficult to join datasets downstream.\nBe consistent with missing values. Do not use a mix of leaving the cell blank, NA and making notes like value missing. Also see section below for more details on missing values.\nBe consistent with file names.\nBe consistent with dates. Dates are particularly tricky and get some special attention here (see below). Preferably, use the ISO standard yyyy-mm-dd, for example 2025-12-07.\nBe consistent in notes. We recommend to have a column with notes, which can be used to write down notes about the data or a specific value. For example, why a observation is missing, or something that was unusual during data collection etc. But again, be consistent when making these notes, because it will be easier to make use of the notes downstream. Using different versions for the same information like gone, missing, vanished will make it difficult to quantify how many times a specific problem occured.\nAvoid space in cells before ” female” or after “female ”.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#meaningful-naming",
    "href": "02_design-spreadsheets.html#meaningful-naming",
    "title": "3  Design spreadsheets",
    "section": "\n3.8 Meaningful naming",
    "text": "3.8 Meaningful naming\nUse good and meaningful names. What do we mean by this? Variable names should be easy to use in downstream data analysis. In addition, variable names should be meaningful which means that the name should explain the variable to some extent.\nAvoid spaces in names, and rather use underscore (_) or hyphen (-). There are different styles (see Figure 3.7) and there are debates about which one is preferable. The truth is, it does not really matter, choose one and stick with it. On a second thought, do not use the kebab-case.\n\n\n\n\n\n\n\nFigure 3.7: Different styles for naming objects. Credit: Allison Horst.\n\n\n\n\nDo not use special characters other than underscore and hyphen in names. For example: +, %, &, /, ?, !, $, ,, #, @. Note that letters that might be common for you, for example å, æ and ø, are not so common in other countries and R does not deal very well with them. Instead of nedbør use nedbor. This will make you life a lot easier.\nUse concise and meaningful names (Figure 3.8). The name should be short, but long enough to give a meaning. For example community_composition_2022.csv.\n\n\n\n\n\n\n\nFigure 3.8: Final doc by PhDcomics.com\n\n\n\n\nIf you want to know more about this, we have created a tutorial on naming conventions.\n\n3.8.1 janitor\nOne way to deal with inconsistent variable names is to use the janitor package. The function clean_names() will convert all variables names to a consistent format with snake_case (default). Other formats are also available. In addition it will turn % sign into percent and # to number.\nLet’s look at a dataframe with ugly variable names. And then clean the names.\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ndat\n\n# A tibble: 1 × 3\n  siteID `measurment 2022` `cover%`\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;\n1 A                      1       32\n\ndat |&gt;\n  clean_names()\n\n# A tibble: 1 × 3\n  site_id measurment_2022 cover_percent\n  &lt;chr&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1 A                     1            32",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#standards",
    "href": "02_design-spreadsheets.html#standards",
    "title": "3  Design spreadsheets",
    "section": "\n3.9 Standards",
    "text": "3.9 Standards\nUse global data standards when available.\ngeographic locations\nOne example are geographic locations such as coordinates. They can be written in many different ways:\n\nDecimal degrees: 60.39299 5.32415\nDMS: 60°23’34.76” N 5°19’26.94” E\nUTM: 32V 297477 6700830\n\nWe recommend to use decimal degree (ISO 6709). For example the coordinates for Bergen (Norway) are 60.39299 °N and 5.32415 °E. There are some important rules to follow:\n\nLatitude comes before longitude.\nNorth latitude is positive and south latitude is negative.\nEast longitude is positive and west longitude is negative.\n\nIf your coordinates are UTM that is also fine, but do not forget to report the zone (e.g. 32V).\nWhen entering dates into spreadsheets, add each part in a separate column, meaning separate the degree north and east in two columns. For UTM use three columns.\ndates\nAnother example are dates, that can also be written in many different ways:\n\n3.1.2022\n03/01/2200\n01-03-2022\n\nThis can lead to confusion, especially when the placement of the month and day are switched (Figure 3.9).\nWe therefore strongly recommend to use the global standard ISO 8601 (Houston 1993) for dates, YYYY-MM-DD, such as 2025-12-07.\n\n\n\n\n\n\n\nFigure 3.9: Missunderstandings when not using date standards. Credit: https://xkcd.com\n\n\n\n\nAnother issue with dates is, that programs like Excel can turn names into dates. For example names like “Oct-4”, which is a name of a gene, will be turned into a date. Be aware of such problems and check your dataset for dates that are not supposed to be dates. This is a widely ackowledged problem and there are tools to deal with it, such as the web tool that autocorrects and updates misidentified gene names (Koh et al. 2022).\nTry to avoid names that are turned into dates, or actively prevent it by adding a underscore or another character in front of such names. This can later be removed. Another way is to force a column in excel to be a date or to be text.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#missing-data",
    "href": "02_design-spreadsheets.html#missing-data",
    "title": "3  Design spreadsheets",
    "section": "\n3.10 Missing data",
    "text": "3.10 Missing data\nWe recommend to use NA for missing data and not to leave cells blank. R will automatically fill in NAs in blank cells. The problem with leaving missing data blank, is that there is no way of distinguishing between actual missing data and data that was forgotten to enter.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#point-or-comma-as-decimal-separator",
    "href": "02_design-spreadsheets.html#point-or-comma-as-decimal-separator",
    "title": "3  Design spreadsheets",
    "section": "\n3.11 Point or comma as decimal separator",
    "text": "3.11 Point or comma as decimal separator\nFor the decimal separator it is common to use a point or a comma. There is no general agreement on which one to use, and there are different practises in different countries. For example in Norway, the comma is the standard setting in Excel.\nAgain, it does not matter what you use, but use it consistently. We have guidelines for how to import datasets with different formats (see import chapter).\nImportantly, do not use a point, when Excel is expecting a comma, which can cause problems when importing the data to R. You can change the settings in Excel.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#no-manipulation-or-calculations",
    "href": "02_design-spreadsheets.html#no-manipulation-or-calculations",
    "title": "3  Design spreadsheets",
    "section": "\n3.12 No manipulation or calculations",
    "text": "3.12 No manipulation or calculations\nWe strongly recommend to use datasheets only for data entry and storage. During data entry, the content of the spreadsheet can still be changed to reflect the paper version of the data or to make it consistent. But at some point we suggest to stop data manipulation by hand. From that point, data manipulation is done by code.\nThis is because any manipulation done by hand in Excel, cannot be reversed (at least once the document is saved and closed). Also, if you do a lot of manipulation in Excel, you won’t remember what has been done. Standard excel does not have track change to allow you to go back to older versions. In contrast, if data manipulation is done code-based, all manipulation can be changed and reversed.\nFor example, if you delete a column in Excel, save the document and leave the program. And the next day you realize that this was a mistake, it is not possible to retrieve this column. However if you leave the data file untouched, and do the manipulation in R, you can import the data again, run the code and just delete the command that was wrong.\nWe also do not recommend that you make calculations or summaries in your spreadsheet. Better practice is to use R for this, because it is reproducible.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#no-formatting",
    "href": "02_design-spreadsheets.html#no-formatting",
    "title": "3  Design spreadsheets",
    "section": "\n3.13 No formatting",
    "text": "3.13 No formatting\nIt’s common to format tables, by for example using colours, or bold font. That is fine, as long as the formatting is not containing any information. For example colouring missing data (Figure 3.10). For that make a new column with notes that data is missing.\nData analysis programs do not understand highlighted cells or bold text and such information will simply be ignored and is therefore lost.\n\n\n\n\n\n\n\nFigure 3.10: A spreadsheet with formatting.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "02_design-spreadsheets.html#references",
    "href": "02_design-spreadsheets.html#references",
    "title": "3  Design spreadsheets",
    "section": "\n3.14 References",
    "text": "3.14 References\n\n\n\n\n\n\nBroman, Karl W, and Kara H Woo. 2018. “Data Organization in Spreadsheets.” The American Statistician 72 (1): 2–10.\n\n\nHouston, Gary. 1993. “ISO 8601: 1988 Date/Time Representations.”\n\n\nKoh, Clara WT, Justin SG Ooi, Gabrielle LC Joly, and Kuan Rong Chan. 2022. “Gene Updater: A Web Tool That Autocorrects and Updates for Excel Misidentified Gene Names.” Scientific Reports 12 (1): 1–7.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Design spreadsheets</span>"
    ]
  },
  {
    "objectID": "03_data_collection.html",
    "href": "03_data_collection.html",
    "title": "4  Data collection",
    "section": "",
    "text": "Data collection is the systematic gathering of data for a specific reason and the data is usually used for downstream processing in statistical analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data collection</span>"
    ]
  },
  {
    "objectID": "04_digitizing_import_data.html",
    "href": "04_digitizing_import_data.html",
    "title": "5  Digitize and import data",
    "section": "",
    "text": "5.1 Digitizing data\nThe first step after manual data collection is to digitize the data. This step is not necessary for digital data collected.\nWhen digitizing the data, the digital version of the datasheet should reflect the paper version, to avoid having to flip to different sections of the spreadsheet. You do not need to change the format to a long table, because you will need the data in this format later. It is better to make the data entry as smooth as possible to avoid mistakes. Changing the format of the data frame can easily be changed later using code.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Digitize and import data</span>"
    ]
  },
  {
    "objectID": "04_digitizing_import_data.html#proof-reading",
    "href": "04_digitizing_import_data.html#proof-reading",
    "title": "5  Digitize and import data",
    "section": "\n5.2 Proof reading",
    "text": "5.2 Proof reading\nAfter digitizing your data, the next step is to proof read. Proof reading means that you check that the digital copy of your data reflect the paper copy. At this stage, the digital spreadsheet can still be edited by hand, if you are correcting for typos and similar issues.\nNote that if you discover consistent error (e.g. entering the wrong date for multiple days), it is safer to make these changes using code.\nAfter proof reading we recommend to save your data as raw data, a non-manipulated version of your data. Indicate in file name, that this is the raw version of the data. This will later make the process of data cleaning fully transparent. For example, if you want to share your data later, anybody can see what was done to the data, and if somebody wants to clean your data differently for another purpose, this is still possible.\nIt is recommended to proof read the whole dataset. If the dataset is very large, you can start with randomly proof reading some data sheets. Depending on the number of mistakes you find in a subset of the data, you can decided if you want to proof read everything or not.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Digitize and import data</span>"
    ]
  },
  {
    "objectID": "04_digitizing_import_data.html#import-data",
    "href": "04_digitizing_import_data.html#import-data",
    "title": "5  Digitize and import data",
    "section": "\n5.3 Import data",
    "text": "5.3 Import data\nThe next step is to import the data to R for further processing. See the section on Import data in R in the Working in R book.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Digitize and import data</span>"
    ]
  },
  {
    "objectID": "05_data_cleaning.html",
    "href": "05_data_cleaning.html",
    "title": "6  Data cleaning, vizualizing and analysis",
    "section": "",
    "text": "Data cleaning is the process of detecting and correcting or removing, incomplete, incorrect, irrelevant, duplicated or improperly formatted data from a dataset. Errors and problems in the data can be a problem or limit the downstream data analysis and affect the results. Therefore, data cleaning can solve some of the problems and improve the data, analysis and their outcome.\nThe data cleaning should be done fully code-based, meaning that from now on, there should be no more changing things in the data by hand. Make sure your code is openly available (e.g. on GitHub) to make the data cleaning workflow transparent and reproducible. For more details see section on data cleaning (Chapter 6).\nAfter data cleaning, we recommend to save a clean version of your data and indicate again in the file name that this is the clean version.\nData cleaning is often a circular process…",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data cleaning, vizualizing and analysis</span>"
    ]
  },
  {
    "objectID": "06_communication.html",
    "href": "06_communication.html",
    "title": "7  Data communication",
    "section": "",
    "text": "See the book on reproducible documents.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data communication</span>"
    ]
  },
  {
    "objectID": "07_death.html",
    "href": "07_death.html",
    "title": "8  Data death",
    "section": "",
    "text": "8.1 Loosing data\nInformation contend associated with data and metadata naturally degrades over time. The availability of research data also declines rapidly with article age.\nMichener, W. K. (2006). Meta-information concepts for ecological data management. Ecological informatics, 1(1), 3-7.\nVines, Timothy H. et al. 2014. The Availability of Research Data Declines Rapidly with Article Age. Current Biology, Volume 24, Issue 1, 94 - 97\nWhat would happen if you lost all of your research data?\nHere are two cases where researchers lost all their data.\n“I was focussed on creating high resolution, 3D time lapse videos of developing crustacean embryos, so all of my work was digital-based. When I lost my laptop and backups, I lost 400GB of data and close to four years of work. As a direct result I ended up getting an MPhil rather than the PhD I’d been working towards. I was hoping to have an illustrious career in science and for a time it seemed like everything would be stopped in its tracks.” Billy Hinchen\nThis is another case.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data death</span>"
    ]
  },
  {
    "objectID": "07_death.html#avoid-data-loss",
    "href": "07_death.html#avoid-data-loss",
    "title": "8  Data death",
    "section": "\n8.2 Avoid data loss",
    "text": "8.2 Avoid data loss\n\nKeep raw data\nStore data in multiple places\nUse physical and cloud services\nBe paranoid!\n\nBack up your data in an data repository that is not connected to your computer to avoid data loss. There are many options for this and they often have private or closed repositories, which means that you do not automatically need to share the data.\nTake pictures of paper versions of your data and store them in a save place. Pictures can be useful for proof reading.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data death</span>"
    ]
  },
  {
    "objectID": "08_data_archiving.html",
    "href": "08_data_archiving.html",
    "title": "9  Data archiving",
    "section": "",
    "text": "Make your data FAIR.\nMany research funders and journals demand data archiving.\n\nsubject specific archives\n\nGeneBank\nGBIF\n\n\nGeneralist repositories\n\nDRYAD\nOSF\nZenodo\n\n\nUniversity based\n\nDataverseNO",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Data archiving</span>"
    ]
  }
]